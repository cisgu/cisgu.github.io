<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="rgba(0,0,0,0)"><meta name="generator" content="Hexo 8.1.1">

<link rel="preconnect" href="//fonts.loli.net" crossorigin>
<link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
  <link rel="manifest" href="/manifest.json">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.loli.net/css2?family=Lato:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/themes/blue/pace-theme-center-atom.css">
  <script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous" defer></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"cisgu.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.27.0","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"github","dark":"github"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":true,"style":"mac"}},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"buttons","active":"disqus","storage":true,"lazyload":false,"nav":{"disqus":{"text":"Load Disqus","order":-1}},"activeClass":"disqus"},"stickytabs":false,"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="数据采集01整体相关学习的内容  安装Python解释器 安装PyChara开发工具 自己要抽时间去回顾蓝桥云课《Python程序设计基础》内容 网络爬虫的基本概念以及浏览器的基本应用 回顾HTML的相关标签和属性（为数据采集的必要性内容） 回顾CSS标签的基本样式的规则选择器写法（数据采集会使用） 请求库Requests库(基本应用、解决反爬机制应用) 网页内容的解析库Beautiful Sou">
<meta property="og:type" content="blog">
<meta property="og:title" content="数据采集">
<meta property="og:url" content="https://cisgu.github.io/2023-12-29-data-collection.html">
<meta property="og:site_name" content="Cisgu&#39;s blog">
<meta property="og:description" content="数据采集01整体相关学习的内容  安装Python解释器 安装PyChara开发工具 自己要抽时间去回顾蓝桥云课《Python程序设计基础》内容 网络爬虫的基本概念以及浏览器的基本应用 回顾HTML的相关标签和属性（为数据采集的必要性内容） 回顾CSS标签的基本样式的规则选择器写法（数据采集会使用） 请求库Requests库(基本应用、解决反爬机制应用) 网页内容的解析库Beautiful Sou">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281002774.png">
<meta property="og:image" content="e:/typora%E5%9B%BE%E7%89%87/image-20231018081118509.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281003542.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281003876.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281003146.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281003580.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281004166.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281004358.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281004981.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281004858.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281004586.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281004419.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281004932.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281005393.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281005328.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281005524.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281005863.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281005807.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281006106.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281006737.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281006756.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281006111.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281007764.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281007251.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281007415.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281007006.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281007693.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281007281.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281008671.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281008664.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281008912.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281008988.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281008604.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281008079.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281008029.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281009935.png">
<meta property="og:image" content="e:/typora%E5%9B%BE%E7%89%87/image-20240102103356381.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281009191.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281009446.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281009107.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281009884.png">
<meta property="article:published_time" content="2023-12-28T16:00:00.000Z">
<meta property="article:modified_time" content="2023-12-28T16:00:00.000Z">
<meta property="article:author" content="Cisgu">
<meta property="article:tag" content="BeautifulSoup">
<meta property="article:tag" content="python">
<meta property="article:tag" content="requests">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281002774.png">


<link rel="canonical" href="https://cisgu.github.io/2023-12-29-data-collection.html">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://cisgu.github.io/2023-12-29-data-collection.html","path":"2023-12-29-data-collection.html","title":"数据采集"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>数据采集 | Cisgu's blog</title>
  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Cisgu's blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/about.html" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%8601"><span class="nav-number">1.</span> <span class="nav-text">数据采集01</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E3%80%81Python%E8%A7%A3%E9%87%8A%E5%99%A8%E5%92%8C%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7%E5%AE%89%E8%A3%85"><span class="nav-number">1.1.</span> <span class="nav-text">一、Python解释器和开发工具安装</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C%E3%80%81%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="nav-number">1.2.</span> <span class="nav-text">二、网络爬虫的基本概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%89%E3%80%81%E7%BD%91%E9%A1%B5%E8%AF%B7%E6%B1%82%E5%BA%93requests%E7%9A%84%E5%9F%BA%E6%9C%AC%E8%BF%90%E7%94%A8"><span class="nav-number">1.3.</span> <span class="nav-text">三、网页请求库requests的基本运用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%9B%E3%80%81%E7%BD%91%E9%A1%B5%E7%9A%84%E8%A7%A3%E6%9E%90%E5%BA%93-Beautiful-Soup"><span class="nav-number">1.4.</span> <span class="nav-text">四、网页的解析库 Beautiful Soup</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%94%E3%80%81%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98"><span class="nav-number">1.5.</span> <span class="nav-text">五、数据采集项目实战</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E7%94%9F%E4%BA%A7%E5%BA%93Faker"><span class="nav-number">1.6.</span> <span class="nav-text">数据生产库Faker</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%8602"><span class="nav-number">2.</span> <span class="nav-text">数据采集02</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E3%80%81%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%9C%80%E6%B1%82"><span class="nav-number">2.1.</span> <span class="nav-text">一、开发环境需求</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C%E3%80%81%E5%AE%89%E8%A3%85%E7%9B%B8%E5%85%B3%E5%BA%93"><span class="nav-number">2.2.</span> <span class="nav-text">二、安装相关库</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%89%E3%80%81%E7%BD%91%E7%BB%9C%E8%AF%B7%E6%B1%82%E6%A1%86%E6%9E%B6"><span class="nav-number">2.3.</span> <span class="nav-text">三、网络请求框架</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%9B%E3%80%81%E7%BD%91%E9%A1%B5%E8%A7%A3%E6%9E%90%E6%A1%86%E6%9E%B6"><span class="nav-number">2.4.</span> <span class="nav-text">四、网页解析框架</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%94%E3%80%81%E9%98%B6%E6%AE%B5%E6%80%A7%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE"><span class="nav-number">2.5.</span> <span class="nav-text">五、阶段性实战项目</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Cisgu"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Cisgu</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">5</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/cisgu" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;cisgu" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:ugycc@qq.com" title="E-Mail → mailto:ugycc@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/cisgu" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;cisgu" rel="noopener" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://t.me/cisgu" title="Telegram → https:&#x2F;&#x2F;t.me&#x2F;cisgu" rel="noopener" target="_blank"><i class="fa-brands fa-telegram fa-fw"></i>Telegram</a>
      </span>
      <span class="links-of-author-item">
        <a href="/atom.xml" title="RSS → &#x2F;atom.xml"><i class="fa-solid fa-square-rss fa-fw"></i>RSS</a>
      </span>
  </div>



        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://cisgu.github.io/2023-12-29-data-collection.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Cisgu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Cisgu's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="数据采集 | Cisgu's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          数据采集
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-12-29 2023-12-29T00:00:00+08:00" itemprop="dateCreated datePublished" datetime="2023-12-29T00:00:00+08:00">2023-12-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">笔记</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2023-12-29-data-collection.html#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2023-12-29-data-collection.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>68k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1:02</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h2 id="数据采集01"><a href="#数据采集01" class="headerlink" title="数据采集01"></a>数据采集01</h2><p><strong>整体相关学习的内容</strong></p>
<ul>
<li>安装Python解释器</li>
<li>安装PyChara开发工具</li>
<li>自己要抽时间去回顾蓝桥云课《Python程序设计基础》内容</li>
<li>网络爬虫的基本概念以及浏览器的基本应用</li>
<li>回顾HTML的相关标签和属性（为数据采集的必要性内容）</li>
<li>回顾CSS标签的基本样式的规则选择器写法（数据采集会使用）</li>
<li>请求库Requests库(基本应用、解决反爬机制应用)</li>
<li>网页内容的解析库Beautiful Soup(基本应用到高级应用)</li>
<li>如何使用网络爬虫技术去采集文本内容和多媒体内容</li>
</ul>
<h3 id="一、Python解释器和开发工具安装"><a href="#一、Python解释器和开发工具安装" class="headerlink" title="一、Python解释器和开发工具安装"></a>一、Python解释器和开发工具安装</h3><h5 id="1-1-Python-解释器的安装"><a href="#1-1-Python-解释器的安装" class="headerlink" title="1.1 Python 解释器的安装"></a>1.1 Python 解释器的安装</h5><p>安装的要求：</p>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281002774.png" alt="image-20260128100240651"></p>
<p>等待安装完成：</p>
<img data-src="E:/typora%E5%9B%BE%E7%89%87/image-20231018081118509.png" alt="image-20231018081118509" style="zoom:50%;" />

<p>安装完成并进行Close关闭</p>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281003542.png" alt="image-20260128100303444"></p>
<p>验证Python版本及安装情况，进入终端输入 Python -V</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\dengqiang&gt;python -V</span><br><span class="line">Python 3.8.8</span><br></pre></td></tr></table></figure>







<p><strong>Python关于下载的相关扩展(国内镜像源配置)</strong></p>
<p>默认情况下Python下载一些第三方库都在国外的地址下载，其下载的速度很慢，而且有时无法下载，所有我们尽量使用国内镜像源进行下载相关内容，以下会进行讲解国内的配置。</p>
<ol>
<li><p>有哪些国内镜像源下载地址：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">清华：https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line"></span><br><span class="line">阿里云：https://mirrors.aliyun.com/pypi/simple/</span><br><span class="line"></span><br><span class="line">中国科技大学：https://pypi.mirrors.ustc.edu.cn/simple/</span><br><span class="line"></span><br><span class="line">山东理工大学：</span><br><span class="line"></span><br><span class="line">豆瓣：https://pypi.douban.com/simple/</span><br></pre></td></tr></table></figure>

<p>这些镜像源国内会每5分钟进行更新。</p>
<p>在C盘用户目录新建一个pip文件夹。</p>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281003876.png" alt="image-20260128100323793"></p>
<p>再在pip文件夹中新建一个pip.ini文件，并打开编辑以下相关内容后保存。</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[global]</span></span><br><span class="line"><span class="attr">index-url</span>=https://mirrors.aliyun.com/pypi/simple/</span><br><span class="line"><span class="section">[install]</span></span><br><span class="line"><span class="attr">trusted-host</span>=mirrors.aliyun.com</span><br></pre></td></tr></table></figure></li>
</ol>
<p>验证镜像源的情况(终端打开)：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip config <span class="built_in">list</span></span><br></pre></td></tr></table></figure>



<h5 id="1-2-pip简单命令的使用-使用终端操作"><a href="#1-2-pip简单命令的使用-使用终端操作" class="headerlink" title="1.2  pip简单命令的使用(使用终端操作)"></a>1.2  pip简单命令的使用(使用终端操作)</h5><h6 id="1-2-1-查看已安装的软件包的信息"><a href="#1-2-1-查看已安装的软件包的信息" class="headerlink" title="1.2.1 查看已安装的软件包的信息"></a>1.2.1 查看已安装的软件包的信息</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip <span class="built_in">list</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Package                       Version</span><br><span class="line">----------------------------- --------------------</span><br><span class="line">alabaster                     0.7.12</span><br><span class="line">anaconda-client               1.11.0</span><br><span class="line">anaconda-navigator            2.3.1</span><br><span class="line">anaconda-project              0.11.1</span><br><span class="line">anyio                         3.5.0</span><br><span class="line">.....</span><br></pre></td></tr></table></figure>



<h6 id="1-2-2-更新pip命令"><a href="#1-2-2-更新pip命令" class="headerlink" title="1.2.2 更新pip命令"></a>1.2.2 更新pip命令</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m pip install --upgrade pip</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\14949&gt;python -m pip install --upgrade pip</span><br><span class="line">Looking in indexes: https://mirrors.aliyun.com/pypi/simple/</span><br><span class="line">Requirement already satisfied: pip in d:\ops\anaconda\lib\site-packages (22.2.2)</span><br><span class="line">Collecting pip</span><br><span class="line">  Downloading https://mirrors.aliyun.com/pypi/packages/e0/63/b428aaca15fcd98c39b07ca7149e24bc14205ad0f1c80ba2b01835aedde1/pip-23.3-py3-none-any.whl (2.1 MB)</span><br><span class="line">     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 757.9 kB/s eta 0:00:00</span><br><span class="line">Installing collected packages: pip</span><br><span class="line">  Attempting uninstall: pip</span><br><span class="line">    Found existing installation: pip 22.2.2</span><br><span class="line">    Uninstalling pip-22.2.2:</span><br><span class="line">      Successfully uninstalled pip-22.2.2</span><br><span class="line">Successfully installed pip-23.3</span><br></pre></td></tr></table></figure>



<p>pip卸载</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m pip uninstall pip</span><br></pre></td></tr></table></figure>





<h6 id="1-2-3-使用pip安装文本转语音的库"><a href="#1-2-3-使用pip安装文本转语音的库" class="headerlink" title="1.2.3 使用pip安装文本转语音的库"></a>1.2.3 使用pip安装文本转语音的库</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pyttsx3</span><br></pre></td></tr></table></figure>

<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281003146.png" alt="image-20260128100346075"></p>
<p>进入Python使用代码实现语音播报</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\dengqiang&gt;python</span><br><span class="line">Python 3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit</span><br><span class="line">(AMD64)] on win32</span><br><span class="line">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</span><br><span class="line">&gt;&gt;&gt; import pyttsx3</span><br><span class="line">&gt;&gt;&gt; engine = pyttsx3.init()</span><br><span class="line">&gt;&gt;&gt; engine.say(&#x27;How Do You Do&#x27;)</span><br><span class="line">&gt;&gt;&gt; engine.runAndWait()</span><br><span class="line">&gt;&gt;&gt; engine.say(&#x27;你好！这是中国人民广播电台，现在播报今日的天气情况，小雨转中雨，中雨转多</span><br><span class="line">云。&#x27;)</span><br><span class="line">&gt;&gt;&gt; engine.runAndWait()</span><br><span class="line">&gt;&gt;&gt; exit()</span><br><span class="line"></span><br></pre></td></tr></table></figure>









<h6 id="1-2-4-使用pip更新已有的第三方库"><a href="#1-2-4-使用pip更新已有的第三方库" class="headerlink" title="1.2.4 使用pip更新已有的第三方库"></a>1.2.4 使用pip更新已有的第三方库</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -U package-name(第三方库名字)</span><br></pre></td></tr></table></figure>

<h6 id="1-2-5-使用pip删除不需要的第三方库"><a href="#1-2-5-使用pip删除不需要的第三方库" class="headerlink" title="1.2.5 使用pip删除不需要的第三方库"></a>1.2.5 使用pip删除不需要的第三方库</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip uninstall package-name(第三方库名字)</span><br></pre></td></tr></table></figure>



<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281003580.png" alt="image-20260128100356451"></p>
<p>下载库：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install requests</span><br></pre></td></tr></table></figure>



<p>百度文库复制方法：</p>
<p>Edge –&gt;  read:网址</p>
<h5 id="1-3-安装Python开发工具"><a href="#1-3-安装Python开发工具" class="headerlink" title="1.3 安装Python开发工具"></a>1.3 安装Python开发工具</h5><p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281004166.png" alt="image-20260128100403103"></p>
<p>根据自己的路径进行修改</p>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281004358.png" alt="image-20260128100414295"></p>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281004981.png" alt="image-20260128100423926"></p>
<p><strong>新建Python项目</strong></p>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281004858.png" alt="image-20260128100430784"></p>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281004586.png" alt="image-20260128100436517"></p>
<p><strong>代码体验</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pyttsx3</span><br><span class="line">engine = pyttsx3.init() <span class="comment"># 初始化语音引擎</span></span><br><span class="line">text = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">第一章 惊蛰</span></span><br><span class="line"><span class="string">二月二，龙抬头。</span></span><br><span class="line"><span class="string">暮色里，小镇名叫泥瓶巷的僻静地方，有位孤苦伶仃的清瘦少年，此时他正按照习俗，一手持蜡烛，一</span></span><br><span class="line"><span class="string">手持桃枝，照耀房梁、墙壁、木床等处，用桃枝敲敲打打，</span></span><br><span class="line"><span class="string">试图借此驱赶蛇蝎、蜈蚣等，嘴里念念有词，是这座小镇祖祖辈辈传下来的老话：二月二，烛照梁，桃</span></span><br><span class="line"><span class="string">打墙，人间蛇虫无处藏。</span></span><br><span class="line"><span class="string">少年姓陈，名平安，爹娘早逝。小镇的瓷器极负盛名，本朝开国以来，就担当起“奉诏监烧献陵祭器”的</span></span><br><span class="line"><span class="string">重任，有朝廷官员常年驻扎此地，监理官窑事务。</span></span><br><span class="line"><span class="string">无依无靠的少年，很早就当起了烧瓷的窑匠，起先只能做些杂事粗活，跟着一个脾气糟糕的半路师傅，</span></span><br><span class="line"><span class="string">辛苦熬了几年，刚刚琢磨到一点烧瓷的门道，结果世事无常，</span></span><br><span class="line"><span class="string">小镇突然失去了官窑造办这张护身符，小镇周边数十座形若卧龙的窑炉，一夜之间全部被官府勒令关闭</span></span><br><span class="line"><span class="string">熄火。</span></span><br><span class="line"><span class="string">陈平安放下新折的那根桃枝，吹灭蜡烛，走出屋子后，坐在台阶上，仰头望去，星空璀璨。</span></span><br><span class="line"><span class="string">少年至今仍然清晰记得，那个只肯认自己做半个徒弟的老师傅，姓姚，在去年暮秋时分的清晨，被人发</span></span><br><span class="line"><span class="string">现坐在一张小竹椅子上，正对着窑头方向，闭眼了。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 需要播放的文字</span></span><br><span class="line">engine.say(text)</span><br><span class="line"><span class="comment"># 启动开始进行语音读取</span></span><br><span class="line">engine.runAndWait()</span><br></pre></td></tr></table></figure>







<h3 id="二、网络爬虫的基本概念"><a href="#二、网络爬虫的基本概念" class="headerlink" title="二、网络爬虫的基本概念"></a>二、网络爬虫的基本概念</h3><h5 id="2-1-网络爬虫的标准"><a href="#2-1-网络爬虫的标准" class="headerlink" title="2.1 网络爬虫的标准"></a>2.1 网络爬虫的标准</h5><p>在实际开发过程中网络爬虫程序基本分为三个阶段：</p>
<ul>
<li>获取网页(明确目标)</li>
<li>提取信息(获取数据)</li>
<li>保存数据</li>
</ul>
<h5 id="2-2-常见浏览器有哪些"><a href="#2-2-常见浏览器有哪些" class="headerlink" title="2.2 常见浏览器有哪些"></a>2.2 常见浏览器有哪些</h5><p>问题1：请问全世界一共有多少个浏览器内核？分别是哪些浏览器？</p>
<p>答1：5种内核， IE浏览器、谷歌浏览器、火狐浏览器、Safar浏览器、Opera浏览器</p>
<h5 id="2-3-如何使用浏览器"><a href="#2-3-如何使用浏览器" class="headerlink" title="2.3  如何使用浏览器"></a>2.3  如何使用浏览器</h5><p>使用F12启动开发者模式，我们可以在里面查看其相关的HTML代码。</p>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281004419.png" alt="image-20260128100445326"></p>
<p><strong>代码体验</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pyttsx3</span><br><span class="line">engine = pyttsx3.init() <span class="comment"># 初始化语音引擎</span></span><br><span class="line">text = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">第一章 惊蛰</span></span><br><span class="line"><span class="string">二月二，龙抬头。</span></span><br><span class="line"><span class="string">暮色里，小镇名叫泥瓶巷的僻静地方，有位孤苦伶仃的清瘦少年，此时他正按照习俗，一手持蜡烛，一</span></span><br><span class="line"><span class="string">手持桃枝，照耀房梁、墙壁、木床等处，用桃枝敲敲打打，</span></span><br><span class="line"><span class="string">试图借此驱赶蛇蝎、蜈蚣等，嘴里念念有词，是这座小镇祖祖辈辈传下来的老话：二月二，烛照梁，桃</span></span><br><span class="line"><span class="string">打墙，人间蛇虫无处藏。</span></span><br><span class="line"><span class="string">少年姓陈，名平安，爹娘早逝。小镇的瓷器极负盛名，本朝开国以来，就担当起“奉诏监烧献陵祭器”的</span></span><br><span class="line"><span class="string">重任，有朝廷官员常年驻扎此地，监理官窑事务。</span></span><br><span class="line"><span class="string">无依无靠的少年，很早就当起了烧瓷的窑匠，起先只能做些杂事粗活，跟着一个脾气糟糕的半路师傅，</span></span><br><span class="line"><span class="string">辛苦熬了几年，刚刚琢磨到一点烧瓷的门道，结果世事无常，</span></span><br><span class="line"><span class="string">小镇突然失去了官窑造办这张护身符，小镇周边数十座形若卧龙的窑炉，一夜之间全部被官府勒令关闭</span></span><br><span class="line"><span class="string">熄火。</span></span><br><span class="line"><span class="string">陈平安放下新折的那根桃枝，吹灭蜡烛，走出屋子后，坐在台阶上，仰头望去，星空璀璨。</span></span><br><span class="line"><span class="string">少年至今仍然清晰记得，那个只肯认自己做半个徒弟的老师傅，姓姚，在去年暮秋时分的清晨，被人发</span></span><br><span class="line"><span class="string">现坐在一张小竹椅子上，正对着窑头方向，闭眼了。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 需要播放的文字</span></span><br><span class="line">engine.say(text)</span><br><span class="line"><span class="comment"># 启动开始进行语音读取</span></span><br><span class="line">engine.runAndWait()</span><br></pre></td></tr></table></figure>







<h3 id="三、网页请求库requests的基本运用"><a href="#三、网页请求库requests的基本运用" class="headerlink" title="三、网页请求库requests的基本运用"></a>三、网页请求库requests的基本运用</h3><h5 id="3-1-安装requests库"><a href="#3-1-安装requests库" class="headerlink" title="3.1 安装requests库"></a>3.1 安装requests库</h5><p>打开终端，在终端中输入命令</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install requests</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\14949&gt;pip install requests</span><br><span class="line">Looking <span class="keyword">in</span> indexes: https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">Collecting requests</span><br><span class="line">  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl (62 kB)</span><br><span class="line">     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.6/62.6 kB 844.1 kB/s eta 0:00:00</span><br><span class="line">Collecting charset-normalizer&lt;4,&gt;=2 (from requests)</span><br><span class="line">  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d1/47/148eae656ac376938afc97ed288893c6089038180c9e0782e5423ac0307d/charset_normalizer-3.3.0-cp312-cp312-win_amd64.whl (98 kB)</span><br><span class="line">     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 98.3/98.3 kB 1.9 MB/s eta 0:00:00</span><br><span class="line">Collecting idna&lt;4,&gt;=2.5 (from requests)</span><br><span class="line">  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/fc/34/3030de6f1370931b9dbb4dad48f6ab1015ab1d32447850b9fc94e60097be/idna-3.4-py3-none-any.whl (61 kB)</span><br><span class="line">     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.5/61.5 kB 3.4 MB/s eta 0:00:00</span><br><span class="line">Collecting urllib3&lt;3,&gt;=1.21.1 (from requests)</span><br><span class="line">  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/26/40/9957270221b6d3e9a3b92fdfba80dd5c9661ff45a664b47edd5d00f707f5/urllib3-2.0.6-py3-none-any.whl (123 kB)</span><br><span class="line">     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 123.8/123.8 kB 3.7 MB/s eta 0:00:00</span><br><span class="line">Collecting certifi&gt;=2017.4.17 (from requests)</span><br><span class="line">  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/4c/dd/2234eab22353ffc7d94e8d13177aaa050113286e93e7b40eae01fbf7c3d9/certifi-2023.7.22-py3-none-any.whl (158 kB)</span><br><span class="line">     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 158.3/158.3 kB 2.4 MB/s eta 0:00:00</span><br><span class="line">Installing collected packages: urllib3, idna, charset-normalizer, certifi, requests</span><br><span class="line">Successfully installed certifi-2023.7.22 charset-normalizer-3.3.0 idna-3.4 requests-2.31.0 urllib3-2.0.6</span><br></pre></td></tr></table></figure>



<p>使用命令查看</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip list</span><br></pre></td></tr></table></figure>

<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281004932.png" alt="image-20260128100457880"></p>
<h5 id="3-2-requests基本使用-请求网页"><a href="#3-2-requests基本使用-请求网页" class="headerlink" title="3.2 requests基本使用-请求网页"></a>3.2 requests基本使用-请求网页</h5><p>请求获取HTML</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入请求库</span></span><br><span class="line">import requests</span><br><span class="line"><span class="comment"># 定义需要请求网址的变量</span></span><br><span class="line">webUrl = <span class="string">&#x27;http://www.baidu.com/&#x27;</span></span><br><span class="line"><span class="comment"># 向指定网页进行发送请求，它返回一个响应对象response</span></span><br><span class="line">rep = requests.get(webUrl)</span><br><span class="line"><span class="comment"># 先来看一下，百度的编码是什么？</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;百度的编码方式为：&#x27;</span> + rep.encoding)</span><br><span class="line"><span class="comment"># 响应回来过程中会出现乱码问题，是编码方式造成的结果，以下方式我们将进行处理</span></span><br><span class="line"><span class="comment"># rep.encoding 表示获取或者设置从HTTP header中响应内容的编码方式</span></span><br><span class="line"><span class="comment"># rep.apparent_encoding 表示从内容中分析出响应内容编码方式</span></span><br><span class="line">rep.encoding = rep.apparent_encoding</span><br><span class="line"><span class="comment"># HTTP请求的返回状态，200表示连接成功，404表示失败</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;当前的连接状态为：&quot;</span> + str(rep.status_code))</span><br><span class="line"><span class="comment"># 输入响应回来的HTML代码</span></span><br><span class="line"><span class="comment"># rep.text 表示HTTP响应内容的字符串形式。即url的HTML内容</span></span><br><span class="line"><span class="built_in">print</span>(rep.text)</span><br><span class="line"><span class="comment"># 给大家20分钟时间，分别去请求自己想请求的相关网站(至少3个及以上)。</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>请求获取多媒体数据并进行写入</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">imgUrls = [<span class="string">&#x27;http://kaolapop.oss.kaolacdn.com/7a46a26d64e3426a8b1ae019507a980b_800_800.jpg&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;http://kaolahaitao.oss.kaolacdn.com/aba5088f577be7e9c52d9cbe0f68f3c3.jpg&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;http://kaolapop.oss.kaolacdn.com/db10a747d7f648fcafc5ab7f68d97540_800_800.jpg&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;http://kaolahaitao.oss.kaolacdn.com/d0f6cbd905c7dc0e4c77183665d3b25b.jpg&#x27;</span>]</span><br><span class="line"><span class="comment"># 模拟请求1张图片的地址</span></span><br><span class="line"><span class="comment"># testImgUrl = &#x27;http://kaolapop.oss.kaolacdn.com/7a46a26d64e3426a8b1ae019507a980b_800_800.jpg&#x27;</span></span><br><span class="line">headers = &#123;</span><br><span class="line"><span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64)</span></span><br><span class="line"><span class="string">AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> url <span class="keyword">in</span> imgUrls:</span><br><span class="line">rep = requests.get(url, headers=headers)</span><br><span class="line">imgName = url.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>] <span class="comment"># 获取当前超链接的图片名字+后缀名</span></span><br><span class="line"><span class="comment"># print(imgName)</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;D:/Images/&#x27;</span> + imgName, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">f.write(rep.content)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;图片全部采集完成！&quot;</span>)</span><br><span class="line"><span class="comment"># rep.content 表示HTTP响应内容的二进制形式</span></span><br><span class="line"><span class="comment"># print(rep.content)</span></span><br></pre></td></tr></table></figure>

<p><strong>复习巩固</strong></p>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281005393.png" alt="image-20260128100507330"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">webUrl = <span class="string">&#x27;http://www.baidu.com&#x27;</span></span><br><span class="line"><span class="comment"># 请求百度网站首页，返回Response对象(响应)</span></span><br><span class="line">rep = requests.get(webUrl)</span><br><span class="line"><span class="comment"># 解决乱码问题</span></span><br><span class="line">rep.encoding = rep.apparent_encoding</span><br><span class="line"><span class="comment"># 输出响应得到的HTML内容。获取其字符串</span></span><br><span class="line"><span class="built_in">print</span>(rep.text)</span><br><span class="line"><span class="comment"># 当我们需要获取的是多媒体文件，请使用rep.content。获取二进制数</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h5 id="3-3-获取12306网站所有站点"><a href="#3-3-获取12306网站所有站点" class="headerlink" title="3.3 获取12306网站所有站点"></a>3.3 获取12306网站所有站点</h5><p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281005328.png" alt="image-20260128100513246"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">webUrl =</span><br><span class="line"><span class="string">&#x27;https://www.12306.cn/index/script/core/common/station_name_new_v10018.js&#x27;</span></span><br><span class="line">rep = requests.get(webUrl)</span><br><span class="line"><span class="comment"># 获取12306站点的相关文件文本数据</span></span><br><span class="line">data = rep.text</span><br><span class="line"><span class="comment"># 将文本进行分割处理，它们有一个共同的分隔符为 |</span></span><br><span class="line">datas = data.split(<span class="string">&#x27;|&#x27;</span>)</span><br><span class="line"><span class="comment"># print(datas) # 通过查看发现中文站点的第一个地名的起始索引为1，后续分别为：11、21、</span></span><br><span class="line"><span class="number">31.</span>..，其规律为 间隔<span class="number">10</span>的步长</span><br><span class="line">chinaNames = datas[<span class="number">1</span>::<span class="number">10</span>]</span><br><span class="line"><span class="comment"># print(chinaNames)</span></span><br><span class="line"><span class="comment"># 大家将中文点名字 写入文本文档中。</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;D:/Images/test.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(chinaNames)):</span><br><span class="line">f.write(chinaNames[i] + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;文件写入完毕！&#x27;</span>)</span><br></pre></td></tr></table></figure>



<p><strong>HTML状态码说明</strong></p>
<p>1开头状态码：请求收到，继续处理 </p>
<p>2开头状态码：操作成功收到，分析、接受 </p>
<p>3开头状态码：完成此请求必须进一步处理 </p>
<p>4开头状态码：请求包含一个错误语法或不能完成 </p>
<p>5开头状态码：服务器执行一个完全有效请求失败 </p>
<p>100——客户必须继续发出请求 </p>
<p>101——客户要求服务器根据请求转换HTTP协议版本</p>
<p> 200——交易成功 </p>
<p>201——提示知道新文件的URL </p>
<p>202——接受和处理、但处理未完成 </p>
<p>203——返回信息不确定或不完整 </p>
<p>204——请求收到，但返回信息为空 </p>
<p>205——服务器完成了请求，用户代理必须复位当前已经浏览过的文件 </p>
<p>206——服务器已经完成了部分用户的GET请求 </p>
<p>300——请求的资源可在多处得到 import requests webUrl &#x3D; ‘<a target="_blank" rel="noopener" href="http://www.baidu.com/">http://www.baidu.com</a>‘ # 请求百度网站首页，返回Response对象(响应) rep &#x3D; requests.get(webUrl) # 解决乱码问题 rep.encoding &#x3D; rep.apparent_encoding # 输出响应得到的HTML内容。获取其字符串 print(rep.text) # 当我们需要获取的是多媒体文件，请使用rep.content。获取二进制数据 1 2 3 4 5 6 7 8 9 10 11 </p>
<p>301——删除请求数据 </p>
<p>302——在其他地址发现了请求数据 </p>
<p>303——建议客户访问其他URL或访问方式 </p>
<p>304——客户端已经执行了GET，但文件未变化 </p>
<p>305——请求的资源必须从服务器指定的地址得到 </p>
<p>306——前一版本HTTP中使用的代码，现行版本中不再使用 </p>
<p>307——申明请求的资源临时性删除 </p>
<p>400——客户端发起的请求错误，如语法错误 </p>
<p>401——请求授权失败，需要身份认证 </p>
<p>402——保留有效ChargeTo头响应 </p>
<p>403——服务端理解客户端的请求，但是拒接此请求（你说气不气？） </p>
<p>404——没有发现文件、查询或URl </p>
<p>405——用户在Request-Line字段定义的方法不允许 </p>
<p>406——根据用户发送的Accept拖，请求资源不可访问 </p>
<p>407——类似401，用户必须首先在代理服务器上得到授权 </p>
<p>408——客户端没有在用户指定的饿时间内完成请求 </p>
<p>409——对当前资源状态，请求不能完成 </p>
<p>410——服务器上不再有此资源且无进一步的参考地址,410不同于404，如果资源以前有现在被永久删除 了可使用410代码，网站设计人员可通过301代码指定资源的新位置 </p>
<p>411——服务器拒绝用户定义的Content-Length属性请求 </p>
<p>412——一个或多个请求头字段在当前请求中错误 </p>
<p>413——请求的资源大于服务器允许的大小 </p>
<p>414——请求的资源URL长于服务器允许的长度</p>
<p> 415——请求资源不支持请求项目格式 </p>
<p>416——请求中包含Range请求头字段，在当前请求资源范围内没有range指示值，请求也不包含IfRange请求头字段 417——服务器不满足请求Expect头字段指定的期望值，如果是代理服务器，可能是下一级服务器不能满 足请求 </p>
<p>500——服务器内部发生错误，无法完成请求响应 </p>
<p>501——服务器不支持请求的功能 </p>
<p>502——充当网关或代理的服务器，从远端服务器接收到了一个无效的请求 </p>
<p>503——服务器过载或处于维护状态，暂停服务 </p>
<p>504——充当网关或代理的服务器，未及时从远端服务器获得请求 </p>
<p>505——服务器不支持或拒绝请求头中指定的HTTP版本</p>
<h5 id="3-4-解决网站针对爬虫的拒绝访问的方法"><a href="#3-4-解决网站针对爬虫的拒绝访问的方法" class="headerlink" title="3.4 解决网站针对爬虫的拒绝访问的方法"></a>3.4 解决网站针对爬虫的拒绝访问的方法</h5><p>请求豆瓣网会发现的一些问题</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">webUrl = <span class="string">&#x27;https://www.douban.com/&#x27;</span></span><br><span class="line">rep = requests.get(webUrl)</span><br><span class="line"><span class="built_in">print</span>(rep.status_code) <span class="comment"># 访问豆瓣网的时候，返回一个418状态码，它服务器拒绝我们访问。应</span></span><br><span class="line">该它知道你是爬虫</span><br><span class="line"><span class="built_in">print</span>(rep.request.headers) <span class="comment"># 查看响应回来的请求头部信息，豆瓣网就通过我们的请求的头部信</span></span><br><span class="line">息判别出来我是一个爬虫程序。</span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">418</span><br><span class="line">&#123;&#x27;User-Agent&#x27;: &#x27;python-requests/2.31.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip,</span><br><span class="line">deflate&#x27;, &#x27;Accept&#x27;: &#x27;/&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;&#125;</span><br></pre></td></tr></table></figure>



<p>解决豆瓣网的拒绝访问</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果进行浏览器的伪装</span></span><br><span class="line">headers = &#123;</span><br><span class="line"><span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36</span></span><br><span class="line"><span class="string">(KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">rep = requests.get(webUrl, headers=headers)</span><br><span class="line"><span class="built_in">print</span>(rep.status_code)</span><br><span class="line"><span class="built_in">print</span>(rep.request.headers)</span><br><span class="line"><span class="built_in">print</span>(rep.text)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">200</span><br><span class="line">&#123;&#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64)</span><br><span class="line">AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36&#x27;,</span><br><span class="line">&#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;/&#x27;, &#x27;Connection&#x27;: &#x27;keepalive&#x27;&#125;</span><br><span class="line">下列省略....</span><br></pre></td></tr></table></figure>





<h5 id="3-5-非200响应状态通用处理框架"><a href="#3-5-非200响应状态通用处理框架" class="headerlink" title="3.5 非200响应状态通用处理框架"></a>3.5 非200响应状态通用处理框架</h5><p><strong>第一种为了验证</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getHTMLTesxt</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        rep = requests.get(url)</span><br><span class="line">        rep.raise_for_status()  <span class="comment"># rep.raise_for_status()当请求响应回来的状态码为200就正确执行后面的代码，如果非200就抛出异常</span></span><br><span class="line">        rep.encoding = rep.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> rep.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;产生非200响应状态异常，当前响应状态为&#123;&#125;，请进行及时修改代码&#x27;</span>.<span class="built_in">format</span>(rep.status_code)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证首页</span></span><br><span class="line"><span class="comment"># print(getHTMLTesxt(&#x27;http://www.baidu.com&#x27;))  # 访问百度能正常7返回HTML字符串数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证豆瓣网</span></span><br><span class="line"><span class="built_in">print</span>(getHTMLTesxt(<span class="string">&#x27;https://www.douban.com/&#x27;</span>))  <span class="comment"># 访问豆瓣网是出现418的情况，所有就调用了异常处理</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>





<p><strong>第二种标准写法</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:</span><br><span class="line">        <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 &#x27;</span></span><br><span class="line">        <span class="string">&#x27;Safari/537.36 Edg/118.0.2088.46 &#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getHTMLText</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        rep = requests.get(url, headers=headers)</span><br><span class="line">        rep.raise_for_status()</span><br><span class="line">        rep.encoding = rep.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> rep.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;产生非200响应状态异常，当前响应状态为&#123;&#125;，请进行及时修改代码&#x27;</span>.<span class="built_in">format</span>(rep.status_code)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 看一下标准的通用框架，访问豆瓣网是否正常</span></span><br><span class="line"><span class="built_in">print</span>(getHTMLText(<span class="string">&#x27;https://www.douban.com/&#x27;</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h5 id="3-6-理解-关于爬虫的法律风险-Robots协议"><a href="#3-6-理解-关于爬虫的法律风险-Robots协议" class="headerlink" title="3.6  (理解) 关于爬虫的法律风险 Robots协议"></a>3.6  (理解) 关于爬虫的法律风险 Robots协议</h5><p>什么是Robots协议？ Robots协议也称为爬虫协议，机器人协议，它的全称叫做：网络爬虫排除标准</p>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281005524.png" alt="image-20260128100529453"></p>
<p><strong>Robots协议的遵守建议</strong></p>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281005863.png" alt="image-20260128100536803"></p>
<h5 id="3-7-如何进行模拟登录"><a href="#3-7-如何进行模拟登录" class="headerlink" title="3.7 如何进行模拟登录"></a>3.7 如何进行模拟登录</h5><p>有很多网址需要用户进行登录后才能看到里面的具体内容！如果我们使用网络爬虫技术，我们就需要进行登录。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">headers =&#123;</span><br><span class="line"><span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36</span></span><br><span class="line"><span class="string">(KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;Cookie&#x27;</span>: <span class="string">&#x27;_zap=42591f45-01f6-42c2-82b4-9c363a5dbd35; _xsrf=15d1b41d-08b1-</span></span><br><span class="line"><span class="string">4c5d-ba4f-5203514cee4c;</span></span><br><span class="line"><span class="string">d_c0=ASDTSVnckRePToPiYblJ0K6hLCZ3rDk5Mis=|1697705539;</span></span><br><span class="line"><span class="string">Hm_lvt_98beee57fd2ef70ccdd5ca52b9740c49=1697705530;</span></span><br><span class="line"><span class="string">SESSIONID=vZJ9cymGnP2kpGsgOR115H4l6JnlI7euLWuMqqNDCl4;</span></span><br><span class="line"><span class="string">JOID=UV4XAEm6Q76UgtquKrsnbBbYBjs8yR31rOCmx2zVFoj-85zYSfojvGG26sqrQFbZLpD4BrkOwMKoChTwSvLWGU=; osd=VVERAEqTLiUgd6hLLskaBneBjg4xhv1rSpwWzWEof485_cRvmojfWJ3aspqQ5dZLlH7xzkOAcFpihQxSTNWGY=;</span></span><br><span class="line"><span class="string">__snaker__id=vRIwwb88xv1fpUq2;</span></span><br><span class="line"><span class="string">gdxidpyhxdE=LJDkMB3i5e3beq46s7xO8JJJ%2BMXzLl2mToUhBphpU0awv9RuaVfhXG393QAwKt</span></span><br><span class="line"><span class="string">M96%5CWvPxw%2FA%2F0cmmpC84KyydvW3nuUW%2FvOJaDSvrwIPsMBQ%2FMBoMhq%2FlOYVR3n0W</span></span><br><span class="line"><span class="string">9o3GmxrnSwTiL3TK47tlJQbvMyYjTEDEnWm2askaOlvxBLfcCA%3A1697706431778;</span></span><br><span class="line"><span class="string">YD00517437729195%3AWM_NI=gRxwSOXvOmHXKLLi6XdtgNec4D0%2F8bv1RWY7Gsl5%2BC4vYVp</span></span><br><span class="line"><span class="string">H%2BosIib8fti4yVzNkCbGabUEmWqg0Wjm0vbs5cECN6XzshHbUYa%2FvfSEvHvkV8HxM2e72Knv</span></span><br><span class="line"><span class="string">94%2B2kFFRwN3Q%3D;</span></span><br><span class="line"><span class="string">YD00517437729195%3AWM_NIKE=9ca17ae2e6ffcda170e2e6eea9aa7bf1bfbcb5d972888e8ba</span></span><br><span class="line"><span class="string">7c14b978e9fadd539f28afaa8d539b0979cb2c42af0fea7c3b92aa58eb898d2459caa818ecb5</span></span><br><span class="line"><span class="string">48994848ab554a8aca9afe869f89c00d0bb6ab6ef9eb8dc3d85ada4d6aa49f8aa97b7f344e9b</span></span><br><span class="line"><span class="string">1bdaaec6afcbabc8ab77396a6828cc26a85bfaeb6c86795afa9d1d662aff0ba83f23fa19b8da</span></span><br><span class="line"><span class="string">fb554baada8a9e15f9bbfe197e55987aa8897ea5efc98b8aeb16ff5ee858ff533f8f5fe8cc54</span></span><br><span class="line"><span class="string">e92a982d4d437e2a3;</span></span><br><span class="line"><span class="string">YD00517437729195%3AWM_TID=ugxMx3nQpppBRVRQFVeEymV%2BTQ2wZCFQ;</span></span><br><span class="line"><span class="string">q_c1=120f7e5110904fdf97a70cffe0de56cd|1697705582000|1697705582000;</span></span><br><span class="line"><span class="string">captcha_session_v2=2|1:0|10:1697705772|18:captcha_session_v2|88:UXNOS1IrRmho</span></span><br><span class="line"><span class="string">cXBRaFFjajFHOG9WeVNPd0VzdWdmc0NDM3ZUQlJTeVVreXBJSGFxVDQ2YzVYTnlJVVZQMVc4Qw==</span></span><br><span class="line"><span class="string">|2d51d01d060a743b9b71453661778f2a08954df28c285f6e2771fdfb9b805950;</span></span><br><span class="line"><span class="string">captcha_ticket_v2=2|1:0|10:1697705782|17:captcha_ticket_v2|728:eyJ2YWxpZGF0Z</span></span><br><span class="line"><span class="string">SI6IkNOMzFfYlVvZSo4WEZEKkNXVzZmT2pxM2RKb0JxR3hrOVMzbnNjYWhMRVEyUWtVYTU4Lm9mc</span></span><br><span class="line"><span class="string">HguelVXNU8xLnN6Y2pmX2xzX3F0QnlaWUdvS2JraDVyX0o5S3pMUlczcE00VVU5Nm1TWmNnWllWc</span></span><br><span class="line"><span class="string">1YweHR2KkFBQVFtS2FKTlAuYnQzX1FxRlJaR29sWXVIX2pHblhQcWZESHh3dWU1YVdQbGdXOWZwa</span></span><br><span class="line"><span class="string">3VGaXd2WFh4d1RHSDZlbzFTYzI5Y2NEWU1ySUN5ZkJpdXNqMG5BSS4qd3pNTVRPS1dOSVNpcXNvc</span></span><br><span class="line"><span class="string">UtQM1FtZDZaTnVTTF9CRFRRSFczOFhDRXRXS2ZGTDkwYllCMVcqZ2o4VUZRSE1UdFV4eWVZdFBPb</span></span><br><span class="line"><span class="string">V9aX0owQmxyNl90VGZSNnJ3bXJPVUJtRm9CbFNFU1dDZU5mdHFOOWdURE00ek1aOW4wdXNYejJDQ</span></span><br><span class="line"><span class="string">2NQNFdqcllRRTFqZ0VhdkZ0KlJiSk45UGRjSUhjQVZlcVNBYXRHcGRheGE2cF9vcEtYWFUuKmtwa</span></span><br><span class="line"><span class="string">EVJRUNZUThOTUh5RG9EUEZmNkk2UVVwNF9jQWFEcVFIOGY0Y3VhbFJtdFpEUEdta21BZVFWa09RQ</span></span><br><span class="line"><span class="string">TZBc1NTQmxrUHBYUnh3QTRXb0pwejNCS0tidEN2ZGZOU1JNSThmOWhHU1dJZTFvLkRtU1FhazhZV</span></span><br><span class="line"><span class="string">G1EcUpzZDIwWTRqT1g3N192X2lfMSJ9|c5334ef8ec29d8ab14211ee82a746da4606d64ec664d</span></span><br><span class="line"><span class="string">b91bda3731dd0f060305;</span></span><br><span class="line"><span class="string">z_c0=2|1:0|10:1697705782|4:z_c0|92:Mi4xbVNKNkJ3QUFBQUFCSU5OSldkeVJGeVlBQUFCZ</span></span><br><span class="line"><span class="string">0FsVk5OajBlWmdCcElGd1Fpc0hObWVOdHdDZF9uUGZyekx4MGdB|eafeea9cd537816920e6db67</span></span><br><span class="line"><span class="string">3871a1ff49aefe027eeb7c31f1132035a104705d; tst=r;</span></span><br><span class="line"><span class="string">KLBRSID=81978cf28cf03c58e07f705c156aa833|1697705786|1697705538;</span></span><br><span class="line"><span class="string">Hm_lpvt_98beee57fd2ef70ccdd5ca52b9740c49=1697705777Sec-ChUa:&quot;Chromium&quot;;v=&quot;118&quot;, &quot;Google Chrome&quot;;v=&quot;118&quot;, &quot;Not=A?Brand&quot;;v=&quot;99&quot;&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getHTMLText</span>(<span class="params">url</span>):</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">rep = requests.get(url, headers=headers)</span><br><span class="line">rep.raise_for_status()</span><br><span class="line">rep.encoding = rep.apparent_encoding</span><br><span class="line"><span class="keyword">return</span> rep.text</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line"><span class="keyword">return</span> <span class="string">&#x27;产生非200响应状态异常，当前响应状态为&#123;&#125;，请进行及时修改代</span></span><br><span class="line"><span class="string">码&#x27;</span>.<span class="built_in">format</span>(rep.status_code)</span><br><span class="line"><span class="built_in">print</span>(getHTMLText(<span class="string">&#x27;https://www.zhihu.com/&#x27;</span>)</span><br></pre></td></tr></table></figure>





<h3 id="四、网页的解析库-Beautiful-Soup"><a href="#四、网页的解析库-Beautiful-Soup" class="headerlink" title="四、网页的解析库 Beautiful Soup"></a>四、网页的解析库 Beautiful Soup</h3><h5 id="4-1-Beautiful-Soup的简介"><a href="#4-1-Beautiful-Soup的简介" class="headerlink" title="4.1 Beautiful Soup的简介"></a>4.1 Beautiful Soup的简介</h5><p>它主要的功能是从网页抓取数据。它可以解析HTML和XML。现今在使用玩转网页的解析库Beautiful Soup是使用率最高的。</p>
<h5 id="4-2-安装快速解析支持库lxml"><a href="#4-2-安装快速解析支持库lxml" class="headerlink" title="4.2 安装快速解析支持库lxml"></a>4.2 安装快速解析支持库lxml</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install lxml </span><br></pre></td></tr></table></figure>



<h5 id="4-3-安装Beautiful-Soup库"><a href="#4-3-安装Beautiful-Soup库" class="headerlink" title="4.3 安装Beautiful Soup库"></a>4.3 安装Beautiful Soup库</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install beautifulsoup4</span><br></pre></td></tr></table></figure>

<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281005807.png" alt="image-20260128100547653"></p>
<h5 id="4-4-Beautiful-Soup基础使用体验"><a href="#4-4-Beautiful-Soup基础使用体验" class="headerlink" title="4.4 Beautiful Soup基础使用体验"></a>4.4 Beautiful Soup基础使用体验</h5><p>请大家编写一下HTML代码</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">&quot;UTF-8&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">title</span>&gt;</span>文献网<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">&quot;title&quot;</span> <span class="attr">name</span>=<span class="string">&quot;dromouse&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">b</span>&gt;</span>睡鼠的故事<span class="tag">&lt;/<span class="name">b</span>&gt;</span><span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">&quot;story&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/elsie&quot;</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">id</span>=<span class="string">&quot;linkl&quot;</span>&gt;</span>&lt;!-</span><br><span class="line">- 注释的内容 --&gt;<span class="tag">&lt;/<span class="name">a</span>&gt;</span>,</span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/lacie&quot;</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link2&quot;</span>&gt;</span>蕾西</span><br><span class="line"><span class="tag">&lt;/<span class="name">a</span>&gt;</span>和</span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/tillie&quot;</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link3&quot;</span>&gt;</span>蒂</span><br><span class="line">莉<span class="tag">&lt;/<span class="name">a</span>&gt;</span>;</span><br><span class="line">他们住在井底。</span><br><span class="line"><span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">&quot;story&quot;</span>&gt;</span>其他内容隐藏...<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup <span class="comment"># 导入beautifulsoup解析库</span></span><br><span class="line">html = <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;title&gt;文献网&lt;/title&gt;&lt;/head&gt;</span></span><br><span class="line"><span class="string">&lt;body&gt;&lt;p class=&quot;title&quot; name=&quot;dromouse&quot;&gt;&lt;b&gt;睡鼠的故事&lt;/b&gt;&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p class=&quot;story&quot;&gt;&lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot;</span></span><br><span class="line"><span class="string">id=&quot;linkl&quot;&gt;&lt;!-- 注释的内容 --&gt;&lt;/a&gt;,</span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;蕾西&lt;/a&gt;和</span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;蒂莉&lt;/a&gt;;</span></span><br><span class="line"><span class="string">他们住在井底。&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p class=&quot;story&quot;&gt;其他内容隐藏...&lt;/p&gt;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># &#x27;lxml&#x27; 必须要下载这个三方库，不然会报错</span></span><br><span class="line">soup = BeautifulSoup(html, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="comment"># 输入我们读取到HTML数据</span></span><br><span class="line"><span class="built_in">print</span>(soup.prettify())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;-&#x27;</span> * <span class="number">50</span>) <span class="comment"># 分割线</span></span><br><span class="line"><span class="comment"># 如何获取当前页面的标题内容</span></span><br><span class="line"><span class="built_in">print</span>(soup.title.string)</span><br><span class="line"><span class="comment"># 需要获取 里面有个内容为：睡鼠的故事</span></span><br><span class="line"><span class="built_in">print</span>(soup.b.string)</span><br></pre></td></tr></table></figure>





<h5 id="4-5-Beatiful-Soup基本元素及其运用"><a href="#4-5-Beatiful-Soup基本元素及其运用" class="headerlink" title="4.5 Beatiful Soup基本元素及其运用"></a>4.5 Beatiful Soup基本元素及其运用</h5><table>
<thead>
<tr>
<th>基本元素</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>tag</td>
<td>标签，最基本的信息组织单位，分别用&lt;&gt;和&lt;&#x2F;&gt;标明开头和结尾</td>
</tr>
<tr>
<td>name</td>
<td>标签的名字，<p>…..&lt;</p>的名字‘p’，其格式为：<tag>.name</td>
</tr>
<tr>
<td><strong>Attributes</strong></td>
<td>标签的属性，字典形式组成，其格式为：<tag>.attrs</td>
</tr>
<tr>
<td><strong>MavigableString</strong></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody></table>
<p><strong>选择元素</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.导入相关的第三方库</span></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup  <span class="comment"># 导入BeautifulSoup解析库</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.获取到网页HTML的字符串内容</span></span><br><span class="line">html = <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;title&gt;文献网&lt;/title&gt;&lt;/head&gt;</span></span><br><span class="line"><span class="string">&lt;body&gt;&lt;p class=&quot;title&quot; name=&quot;dromouse&quot;&gt;&lt;b&gt;睡鼠的故事&lt;/b&gt;&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p class=&quot;story&quot;&gt;&lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;&lt;/a&gt;  &lt;!--注释的内容--&gt;</span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;雷西&lt;/a&gt;和</span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;蒂莉&lt;/a&gt;</span></span><br><span class="line"><span class="string">他们住在进底。&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p class=&quot;story&quot;&gt;其他内容隐藏...&lt;/p&gt;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 3.实例化 BeautifulSoup 对象并将网页HTML的字符串内容放入对象中进行解析</span></span><br><span class="line"><span class="comment"># &#x27;lxml&#x27; 必须要下载这个三方库，不然会报错</span></span><br><span class="line">soup = BeautifulSoup(html, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup.title)  <span class="comment"># 获取标签为title的整体内容，其包含标签的开始，结尾以及其内部内容</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(soup.title))  <span class="comment"># 查看当前属性是什么类型 bs4.element.Tag 表示文档中标签</span></span><br><span class="line"><span class="built_in">print</span>(soup.p.b)  <span class="comment"># 获取标签p的整体内容</span></span><br><span class="line"><span class="built_in">print</span>(soup.p.string)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p><strong>提取信息</strong></p>
<p>分别获取节点元素名称、提取属性、文本内容、注释</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.导入相关的第三方库</span></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup  <span class="comment"># 导入BeautifulSoup解析库</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.获取到网页HTML的字符串内容</span></span><br><span class="line">html = <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;title&gt;文献网&lt;/title&gt;&lt;/head&gt;</span></span><br><span class="line"><span class="string">&lt;body&gt;&lt;p class=&quot;title&quot; name=&quot;dromouse&quot;&gt;&lt;b&gt;睡鼠的故事&lt;/b&gt;&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p class=&quot;story&quot;&gt;&lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;&lt;!--注释的内容--&gt;&lt;/a&gt;  </span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;雷西&lt;/a&gt;和</span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;蒂莉&lt;/a&gt;</span></span><br><span class="line"><span class="string">他们住在进底。&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p class=&quot;story&quot;&gt;其他内容隐藏...&lt;/p&gt;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 3.实例化 BeautifulSoup 对象并将网页HTML的字符串内容放入对象中进行解析</span></span><br><span class="line"><span class="comment"># &#x27;lxml&#x27; 必须要下载这个三方库，不然会报错</span></span><br><span class="line">soup = BeautifulSoup(html, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如何提取元素名称：可以利用 name 属性获取节点名字</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;节点的名字为：&#x27;</span> + soup.title.string)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如何提取属性， 回顾HTML标签的属性，HTML的属性是由0~N个组成， 一个标签中不存在相同属性的原则</span></span><br><span class="line"><span class="built_in">print</span>(soup.p.attrs)</span><br><span class="line"><span class="built_in">print</span>(soup.a.attrs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取某个具体的值，我们就可以使用字典的规则，通过键得到值</span></span><br><span class="line"><span class="built_in">print</span>(soup.a.attrs[<span class="string">&#x27;href&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取内容(具体的文本内容(字符串))</span></span><br><span class="line"><span class="built_in">print</span>(soup.p.string)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取注释内容</span></span><br><span class="line"><span class="built_in">print</span>(soup.a.string)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(soup.a.string))</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>课堂练习与课后提升学习</p>
<p>1.练习Beautiful Soup 相关基本元素的应用和总结其作用</p>
<p>2.思考并练习：如何利用Requests和Beautiful Soup 配合使用。（靶向7网站：<a target="_blank" rel="noopener" href="http://python123.io/ws/demo.html%EF%BC%89">http://python123.io/ws/demo.html）</a></p>
<h5 id="4-6-利用Requests和Beautiful-Soup-配合使用"><a href="#4-6-利用Requests和Beautiful-Soup-配合使用" class="headerlink" title="4.6 利用Requests和Beautiful Soup 配合使用"></a>4.6 利用Requests和Beautiful Soup 配合使用</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通用的请求框架</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:</span><br><span class="line">        <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 &#x27;</span></span><br><span class="line">        <span class="string">&#x27;Safari/537.36 Edg/118.0.2088.46 &#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getHTMLText</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        rep = requests.get(url, headers=headers)</span><br><span class="line">        rep.raise_for_status()</span><br><span class="line">        rep.encoding = rep.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> rep.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;产生非200响应状态异常，当前响应状态为&#123;&#125;，请进行及时修改代码&#x27;</span>.<span class="built_in">format</span>(rep.status_code)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 看一下标准的通用框架，访问豆瓣网是否正常</span></span><br><span class="line"><span class="comment"># &#x27;http://python123.io/ws/demo.html</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建bs4</span></span><br><span class="line">webUrl = <span class="string">&#x27;http://python123.io/ws/demo.html&#x27;</span></span><br><span class="line"></span><br><span class="line">soup = BeautifulSoup(getHTMLText(webUrl), <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup.prettify())  <span class="comment"># 查看请求的网页信息</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;-&#x27;</span> * <span class="number">80</span>)</span><br><span class="line"><span class="comment"># 获取当前网页超链接数据</span></span><br><span class="line"><span class="built_in">print</span>(soup.a)</span><br><span class="line"><span class="comment"># 获取当前网页超链接文本内容</span></span><br><span class="line"><span class="built_in">print</span>(soup.a.string)</span><br><span class="line"><span class="comment"># 获取当前网页超链接的属性</span></span><br><span class="line"><span class="built_in">print</span>(soup.a.attrs)</span><br><span class="line"><span class="comment"># 获取当前网页超链接的地址</span></span><br><span class="line"><span class="built_in">print</span>(soup.a.attrs[<span class="string">&#x27;href&#x27;</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure>







<h5 id="4-7-Selector-简介与获取"><a href="#4-7-Selector-简介与获取" class="headerlink" title="4.7 Selector 简介与获取"></a>4.7 Selector 简介与获取</h5><p>什么是Selector？ 它是当前元素定义的CSS样式，它的返回值可能是id选择器、class选择器、标签(元素)选择器。我们再大一学过CSS层叠样式表的原理和方式。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#FourBoxNav &gt; div:nth-child(2) &gt; div:nth-child(1) &gt; div.FourBox0122 &gt; a &gt; img</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#center &gt; div.centerFive &gt; div.FiveLeft &gt; div.FiveBoxLeft01.bodyBorderShadow.bodyBorderBody &gt; div.FiveBoxLeft011 &gt; div:nth-child(1) &gt; div.FiveImg &gt; a &gt; img</span><br></pre></td></tr></table></figure>





<p><strong>数据采集时，整体工作流程：</strong></p>
<ol>
<li>明确采集的目标</li>
<li>分析采集目标的数据组成的结构以及它的规则</li>
<li>反爬机制的分析(测试，该目标有哪些反爬技术，，需要使用哪些方法来处理)</li>
<li>编写采集代码</li>
<li>先测试小量数据(发现问题，修改问题)</li>
<li>进行最终批量采集(保存文本内容或多媒体数据)</li>
</ol>
<p><strong>示列：采取小说网分析过程</strong></p>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281006106.png" alt="image-20260128100607868"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># 首先我们先观察每个小说类别有哪些规则</span><br></pre></td></tr></table></figure>





<p>通过分析我们可以使用循环来</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">xsUrl = &#x27;https://b.faloo.com/Rank_&#x27;</span><br><span class="line"></span><br><span class="line">for i in range(1, 5):</span><br><span class="line">    url = xsUrl + str(i) + &#x27;.html&#x27;</span><br><span class="line">    print(url)</span><br><span class="line"></span><br></pre></td></tr></table></figure>







<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下列地址为缩略图</span></span><br><span class="line">urls = [<span class="string">&#x27;https://img.ivsky.com/img/tupian/t/202108/25/lingyang-014.jpg&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;https://img.ivsky.com/img/tupian/t/202108/25/lingyang-015.jpg&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;https://img.ivsky.com/img/tupian/t/202108/25/lingyang-016.jpg&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;https://img.ivsky.com/img/tupian/t/202108/25/lingyang-017.jpg&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;https://img.ivsky.com/img/tupian/t/202108/25/lingyang-018.jpg&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如何将缩略图改为高清图</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">    newUrl = url.replace(<span class="string">&#x27;/t/&#x27;</span>, <span class="string">&#x27;/pre/&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(newUrl)</span><br></pre></td></tr></table></figure>



<h5 id="4-8-Beautiful-Soup-关联元素选择"><a href="#4-8-Beautiful-Soup-关联元素选择" class="headerlink" title="4.8 Beautiful Soup 关联元素选择"></a>4.8 Beautiful Soup 关联元素选择</h5><p>我们再做选择的时候，有时候不能做到一步就选到需要的节点元素，需要先选取一个节点元素，然后以它为基准再选择它的子节点，父节点，兄弟节点等。</p>
<table>
<thead>
<tr>
<th>属性</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>.contents</td>
<td>子节点的列表，将<tag>所有节点存入列表</td>
</tr>
<tr>
<td>.children</td>
<td>子节点的迭代类型，用于循环遍历子节点</td>
</tr>
<tr>
<td>.descendants</td>
<td>子节点的迭代类型，包含所有子孙节点，，用于循环遍历子孙节点</td>
</tr>
</tbody></table>
<p><strong>.contents属性，示列：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.导入相关的第三方库</span></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup  <span class="comment"># 导入BeautifulSoup解析库</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.获取到网页HTML的字符串内容</span></span><br><span class="line">html =  <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&lt;html lang=&quot;en&quot;&gt;</span></span><br><span class="line"><span class="string">    &lt;head&gt;</span></span><br><span class="line"><span class="string">        &lt;meta charset=&quot;UTF-8&quot;&gt;</span></span><br><span class="line"><span class="string">        &lt;title&gt;文献网&lt;/title&gt;</span></span><br><span class="line"><span class="string">    &lt;/head&gt;</span></span><br><span class="line"><span class="string">    &lt;body&gt;</span></span><br><span class="line"><span class="string">        &lt;p class=&quot;title&quot; name=&quot;dromouse&quot;&gt;</span></span><br><span class="line"><span class="string">            &lt;b&gt;睡鼠的故事&lt;/b&gt;</span></span><br><span class="line"><span class="string">            &lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;&lt;span&gt;塔尔希&lt;/span&gt;&lt;/a&gt; , </span></span><br><span class="line"><span class="string">            &lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;雷西&lt;/a&gt;和</span></span><br><span class="line"><span class="string">            &lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;蒂莉&lt;/a&gt;他们住在进底。</span></span><br><span class="line"><span class="string">        &lt;/p&gt;</span></span><br><span class="line"><span class="string">        &lt;p class=&quot;story&quot;&gt;其他内容隐藏...&lt;/p&gt;</span></span><br><span class="line"><span class="string">    &lt;/body&gt;</span></span><br><span class="line"><span class="string">&lt;/html&gt;   </span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.实例化 BeautifulSoup 对象并将网页HTML的字符串内容放入对象中进行解析</span></span><br><span class="line">soup = BeautifulSoup(html, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(soup.p)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 子节点列表</span></span><br><span class="line"><span class="built_in">print</span>(soup.p.contents)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通用的请求框架</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:</span><br><span class="line">        <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 &#x27;</span></span><br><span class="line">        <span class="string">&#x27;Safari/537.36 Edg/118.0.2088.46 &#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getHTMLText</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        rep = requests.get(url, headers=headers)</span><br><span class="line">        rep.raise_for_status()</span><br><span class="line">        rep.encoding = rep.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> rep.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;产生非200响应状态异常，当前响应状态为&#123;&#125;，请进行及时修改代码&#x27;</span>.<span class="built_in">format</span>(rep.status_code)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 看一下标准的通用框架，访问豆瓣网是否正常</span></span><br><span class="line"><span class="comment"># &#x27;http://python123.io/ws/demo.html</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建bs4</span></span><br><span class="line">webUrl = <span class="string">&#x27;http://python123.io/ws/demo.html&#x27;</span></span><br><span class="line"></span><br><span class="line">soup = BeautifulSoup(getHTMLText(webUrl), <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># body中有哪些子节点</span></span><br><span class="line"><span class="comment"># print(soup.body.contents)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># p中有哪些子节点</span></span><br><span class="line"><span class="built_in">print</span>(soup.p.contents)</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<h6 id="4-8-1-子节点与子孙节点的基本运用"><a href="#4-8-1-子节点与子孙节点的基本运用" class="headerlink" title="4.8.1 子节点与子孙节点的基本运用"></a>4.8.1 子节点与子孙节点的基本运用</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通用的请求框架</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:</span><br><span class="line">        <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 &#x27;</span></span><br><span class="line">        <span class="string">&#x27;Safari/537.36 Edg/118.0.2088.46 &#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getHTMLText</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        rep = requests.get(url, headers=headers)</span><br><span class="line">        rep.raise_for_status()</span><br><span class="line">        rep.encoding = rep.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> rep.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;产生非200响应状态异常，当前响应状态为&#123;&#125;，请进行及时修改代码&#x27;</span>.<span class="built_in">format</span>(rep.status_code)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 看一下标准的通用框架，访问豆瓣网是否正常</span></span><br><span class="line"><span class="comment"># &#x27;http://python123.io/ws/demo.html</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建bs4</span></span><br><span class="line">webUrl = <span class="string">&#x27;http://python123.io/ws/demo.html&#x27;</span></span><br><span class="line"></span><br><span class="line">soup = BeautifulSoup(getHTMLText(webUrl), <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># body中有哪些子节点</span></span><br><span class="line"><span class="comment"># print(soup.body.contents)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># p中有哪些子节点</span></span><br><span class="line"><span class="comment"># print(soup.p.contents)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># children 迭代类型，遍历所有的子节点</span></span><br><span class="line"><span class="comment"># print(soup.p.children)  # 得到的是一个迭代对象</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取第一个p标签中所有的子节点，通过循环迭代出来</span></span><br><span class="line"><span class="keyword">for</span> child <span class="keyword">in</span> soup.p.contents:</span><br><span class="line">    <span class="built_in">print</span>(child)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;=&#x27;</span> * <span class="number">80</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取第一个p标签中所有的子孙节点，通过循环将其迭代</span></span><br><span class="line"><span class="keyword">for</span> child <span class="keyword">in</span> soup.p.descendants:</span><br><span class="line">    <span class="built_in">print</span>(child)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>





<h6 id="4-8-2-父节点先辈-祖先-节点"><a href="#4-8-2-父节点先辈-祖先-节点" class="headerlink" title="4.8.2 父节点先辈(祖先)节点"></a>4.8.2 父节点先辈(祖先)节点</h6><table>
<thead>
<tr>
<th>属性</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>.parent</td>
<td>节点的父标签</td>
</tr>
<tr>
<td>.parents</td>
<td>节点先辈标签的迭代类型，用于循环遍历先辈节点</td>
</tr>
</tbody></table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">webUrl = <span class="string">&#x27;https://python123.io/ws/demo.html&#x27;</span></span><br><span class="line">rep = requests.get(webUrl)</span><br><span class="line">soup = BeautifulSoup(rep.text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># soup.title.parent.name 的意思为：通过BeautifulSoup对象查询标签为title父节点标签获取其名字</span></span><br><span class="line"><span class="built_in">print</span>(soup.title.parent.name)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;=&#x27;</span> * <span class="number">50</span>)</span><br><span class="line"><span class="keyword">for</span> parent <span class="keyword">in</span> soup.title.parents:</span><br><span class="line">    <span class="built_in">print</span>(parent.name)</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<h6 id="4-8-3-兄弟-同辈-节点"><a href="#4-8-3-兄弟-同辈-节点" class="headerlink" title="4.8.3 兄弟(同辈)节点"></a>4.8.3 兄弟(同辈)节点</h6><table>
<thead>
<tr>
<th>属性</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>.next_sibling</td>
<td>返回按照 HTML 文本顺序的下一个平行节点标签</td>
</tr>
<tr>
<td>.previous_sibling</td>
<td>返回按照 HTML 文本顺序的上一个平行节点标签</td>
</tr>
<tr>
<td>.next_siblings</td>
<td>迭代类型，返回按照 HTML 文本顺序的后续所有平行节点标签</td>
</tr>
<tr>
<td>.previous_siblings</td>
<td>迭代类型，返回按照 HTML 文本顺序的前续所有平行节点标签</td>
</tr>
</tbody></table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">webUrl = <span class="string">&#x27;https://python123.io/ws/demo.html&#x27;</span></span><br><span class="line">rep = requests.get(webUrl)</span><br><span class="line">soup = BeautifulSoup(rep.text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下一同辈元素(and) 字符串</span></span><br><span class="line"><span class="built_in">print</span>(soup.a.next_sibling)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果我想去获取到另一个a标签怎么写？</span></span><br><span class="line"><span class="built_in">print</span>(soup.a.next_sibling.next_sibling)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果我想去获取a标签前面一个字符串数据</span></span><br><span class="line"><span class="built_in">print</span>(soup.a.previous_sibling)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;=&#x27;</span> * <span class="number">50</span>)</span><br><span class="line"><span class="comment"># 如果我想去获取a标签后面所有的兄弟节点</span></span><br><span class="line"><span class="keyword">for</span> sibling <span class="keyword">in</span> soup.a.next_siblings:</span><br><span class="line">    <span class="built_in">print</span>(sibling)</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line"></span><br><span class="line"># 通用的请求框架</span><br><span class="line">headers = &#123;</span><br><span class="line">    &#x27;User-Agent&#x27;:</span><br><span class="line">        &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 &#x27;</span><br><span class="line">        &#x27;Safari/537.36 Edg/118.0.2088.46 &#x27;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def getHTMLText(url):</span><br><span class="line">    try:</span><br><span class="line">        rep = requests.get(url, headers=headers)</span><br><span class="line">        rep.raise_for_status()</span><br><span class="line">        rep.encoding = rep.apparent_encoding</span><br><span class="line">        return rep.text</span><br><span class="line">    except:</span><br><span class="line">        return &#x27;产生非200响应状态异常，当前响应状态为&#123;&#125;，请进行及时修改代码&#x27;.format(rep.status_code)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 创建bs4</span><br><span class="line">webUrl = &#x27;https://b.faloo.com/y_0_0_0_0_2_0_1.html&#x27;</span><br><span class="line"></span><br><span class="line">soup = BeautifulSoup(getHTMLText(webUrl), &#x27;lxml&#x27;)</span><br><span class="line"></span><br><span class="line">bookName = []  # 书名</span><br><span class="line">bookTyep = []  # 书的类型</span><br><span class="line">bookClike = []  # 数的点击量</span><br><span class="line">bookNum = []   # 书的总字数</span><br><span class="line"></span><br><span class="line"># .TwoBox02_08 a</span><br><span class="line"># .fontSize14andHui &gt; a</span><br><span class="line"></span><br><span class="line"># 获取所有数据书名</span><br><span class="line">for tag in soup.select(&#x27;.TwoBox02_08 a&#x27;):</span><br><span class="line">    # print(tag.attrs[&#x27;title&#x27;])</span><br><span class="line">    bookName.append(tag.attrs[&#x27;title&#x27;])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 获取所有数据类型</span><br><span class="line">for tag in soup.select(&#x27;.fontSize14andHui &gt; a&#x27;):</span><br><span class="line">    # print(tag.string)</span><br><span class="line">    bookTyep.append(tag.string)</span><br><span class="line"></span><br><span class="line"># 获取所有数据点击量</span><br><span class="line">for tag in soup.select(&#x27;.fontSize14andHui &gt; a&#x27;):</span><br><span class="line">    # print(tag.next_sibling.next_sibling.string)</span><br><span class="line">    bookClike.append(tag.next_sibling.next_sibling.string)</span><br><span class="line"></span><br><span class="line"># 获取所有数据总字数</span><br><span class="line">for tag in soup.select(&#x27;.fontSize14andHui &gt; a&#x27;):</span><br><span class="line">    # print(tag.next_sibling.next_sibling.next_sibling.next_sibling.string)</span><br><span class="line">    bookNum.append(tag.next_sibling.next_sibling.next_sibling.next_sibling.string)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cjData = zip(bookName, bookTyep, bookClike, bookNum)</span><br><span class="line"></span><br><span class="line"># 循环遍历所有数据</span><br><span class="line">for d in cjData:</span><br><span class="line">    print(d)</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<h5 id="4-9-Beautiful-Soup类selector函数"><a href="#4-9-Beautiful-Soup类selector函数" class="headerlink" title="4.9 Beautiful Soup类selector函数"></a>4.9 Beautiful Soup类selector函数</h5><p>我们要掌握selector函数的运用，前提条件：</p>
<ol>
<li>知道CSS样式的定义</li>
<li>会写CSS相关的样式</li>
<li>能修改CSS相关的样式</li>
</ol>
<h6 id="4-9-1-回顾CSS层叠样式表"><a href="#4-9-1-回顾CSS层叠样式表" class="headerlink" title="4.9.1 回顾CSS层叠样式表"></a>4.9.1 回顾CSS层叠样式表</h6><p><strong>目录相关结构</strong></p>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281006737.png" alt="image-20260128100625683"></p>
<p><strong>web01.html</strong></p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">&quot;en&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">&quot;UTF-8&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">title</span>&gt;</span>巩固CSS层叠样式表<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--导入外部CSS层叠样式表--&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">&quot;stylesheet&quot;</span> <span class="attr">href</span>=<span class="string">&quot;style01.css&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">h1</span>&gt;</span>id选择器用#号<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">h2</span>&gt;</span>class选择器用.<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">h5</span> <span class="attr">id</span>=<span class="string">&quot;myclass&quot;</span>&gt;</span>2022级大数据<span class="tag">&lt;/<span class="name">h5</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span> <span class="attr">id</span>=<span class="string">&quot;conl&quot;</span> <span class="attr">class</span>=<span class="string">&quot;fonts&quot;</span>&gt;</span>大数据3班38人<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span> <span class="attr">id</span>=<span class="string">&quot;con2&quot;</span> <span class="attr">class</span>=<span class="string">&quot;fonts&quot;</span>&gt;</span>大数据4班38人<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span></span><br><span class="line">            How Do You DO</span><br><span class="line">            <span class="tag">&lt;<span class="name">span</span>&gt;</span>Hello HTML And CSS<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">span</span>&gt;</span>Hello Python Study<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>



<p><strong>style01.css</strong></p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">h1</span>&#123;</span><br><span class="line">    <span class="attribute">color</span>: red;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-id">#myclass</span>&#123;</span><br><span class="line">    <span class="attribute">background-color</span>: yellow;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.fonts</span>&#123;</span><br><span class="line">    <span class="attribute">background-color</span>: red;</span><br><span class="line">    <span class="attribute">color</span>: white;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">p</span>&gt;<span class="selector-tag">span</span>&#123;</span><br><span class="line">    <span class="attribute">color</span>: blue;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">h1&#123;....&#125; :通过标签名进行设置</span><br><span class="line">#myclass&#123;....&#125; :通过id名进行设置</span><br><span class="line">.fonts&#123;....&#125; :通过类名(class)进行设置</span><br><span class="line">p &gt; span&#123;....&#125; : 组合设置， &gt;表示它的子元素</span><br><span class="line">p span&#123;....&#125; : 组合设置，空格( )表示它的后代元素</span><br></pre></td></tr></table></figure>





<h6 id="4-9-2-数据采集使用select函数通过标签名查找"><a href="#4-9-2-数据采集使用select函数通过标签名查找" class="headerlink" title="4.9.2 数据采集使用select函数通过标签名查找"></a>4.9.2 数据采集使用select函数通过标签名查找</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line"></span><br><span class="line">webUrl = &#x27;https://python123.io/ws/demo.html&#x27;</span><br><span class="line">rep = requests.get(webUrl)</span><br><span class="line">soup = BeautifulSoup(rep.text, &#x27;lxml&#x27;)</span><br><span class="line"></span><br><span class="line"># select(规则选择器)，返回列表类型。表示能查找到1~N个元素</span><br><span class="line">print(soup.select(&#x27;title&#x27;))</span><br><span class="line">print(soup.select(&#x27;p&#x27;))</span><br><span class="line">print(&#x27;查询到p标签元素一个有：&#123;&#125;个&#x27;.format(len(soup.select(&#x27;p&#x27;))))</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p><strong>练习：使用标签进行查找</strong></p>
<ol>
<li>查找a标签，并将a标签中的超链接地址进行打印输出</li>
<li>查找b标签，并将b标签中的文本内容进行打印输出</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">webUrl = <span class="string">&#x27;https://python123.io/ws/demo.html&#x27;</span></span><br><span class="line">rep = requests.get(webUrl)</span><br><span class="line">soup = BeautifulSoup(rep.text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># select(规则选择器)，返回列表类型。表示能查找到1~N个元素</span></span><br><span class="line"><span class="comment"># print(soup.select(&#x27;title&#x27;))</span></span><br><span class="line"><span class="comment"># print(soup.select(&#x27;p&#x27;))</span></span><br><span class="line"><span class="comment"># print(&#x27;查询到p标签元素一个有：&#123;&#125;个&#x27;.format(len(soup.select(&#x27;p&#x27;))))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找所有a标签</span></span><br><span class="line"><span class="comment"># a = soup.find_all(&#x27;a&#x27;)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># # 打印a标签的属性</span></span><br><span class="line"><span class="comment"># for i in a:</span></span><br><span class="line"><span class="comment">#     print(i[&#x27;href&#x27;])</span></span><br><span class="line"><span class="comment"># print(soup.select(&#x27;a&#x27;))</span></span><br><span class="line"><span class="keyword">for</span> tag <span class="keyword">in</span> soup.select(<span class="string">&#x27;a&#x27;</span>):</span><br><span class="line">    <span class="built_in">print</span>(tag.attrs[<span class="string">&#x27;href&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(soup.a.attrs[&#x27;href&#x27;])</span></span><br><span class="line"><span class="keyword">for</span> tag <span class="keyword">in</span> soup.select(<span class="string">&#x27;b&#x27;</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;b标签的内容为：&#x27;</span> + tag.string)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;b标签的内容为：&#x27;</span> + soup.b.string)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h6 id="4-9-3-数据采集使用select函数通过类名和ID查找"><a href="#4-9-3-数据采集使用select函数通过类名和ID查找" class="headerlink" title="4.9.3 数据采集使用select函数通过类名和ID查找"></a>4.9.3 数据采集使用select函数通过类名和ID查找</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">webUrl = <span class="string">&#x27;https://python123.io/ws/demo.html&#x27;</span></span><br><span class="line">rep = requests.get(webUrl)</span><br><span class="line">soup = BeautifulSoup(rep.text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用类名查找</span></span><br><span class="line"><span class="built_in">print</span>(soup.select(<span class="string">&#x27;.py1&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用ID查找</span></span><br><span class="line"><span class="built_in">print</span>(soup.select(<span class="string">&#x27;#link2&#x27;</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p><strong>练习：使用类名或ID进行查找</strong></p>
<ol>
<li>查找类名为title，并将文本内容打印输出</li>
<li>查找id为link1，并将其超链接打印输出</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line"></span><br><span class="line">webUrl = &#x27;https://python123.io/ws/demo.html&#x27;</span><br><span class="line">rep = requests.get(webUrl)</span><br><span class="line">soup = BeautifulSoup(rep.text, &#x27;lxml&#x27;)</span><br><span class="line"></span><br><span class="line"># # 使用类名查找</span><br><span class="line"># print(soup.select(&#x27;.py1&#x27;))</span><br><span class="line">#</span><br><span class="line"># # 使用ID查找</span><br><span class="line"># print(soup.select(&#x27;#link2&#x27;))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># soup.select(&#x27;.title&#x27;)</span><br><span class="line"></span><br><span class="line">for tag in soup.select(&#x27;.title&#x27;):</span><br><span class="line">    print(&#x27;类名为title的内容为：&#x27; + tag.string)</span><br><span class="line"></span><br><span class="line">for tag in soup.select(&#x27;#link1&#x27;):</span><br><span class="line">    print(&#x27;id为link1的超链接为：&#x27; + tag.attrs[&#x27;href&#x27;])</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h6 id="4-9-4-数据采集使用select函数通过组合和属性查找"><a href="#4-9-4-数据采集使用select函数通过组合和属性查找" class="headerlink" title="4.9.4 数据采集使用select函数通过组合和属性查找"></a>4.9.4 数据采集使用select函数通过组合和属性查找</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">webUrl = <span class="string">&#x27;https://python123.io/ws/demo.html&#x27;</span></span><br><span class="line">rep = requests.get(webUrl)</span><br><span class="line">soup = BeautifulSoup(rep.text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 组合查找</span></span><br><span class="line"><span class="built_in">print</span>(soup.select(<span class="string">&#x27;p &gt; b&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(soup.select(<span class="string">&#x27;.title &gt; b&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(soup.select(<span class="string">&#x27;.course a&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 属性查找</span></span><br><span class="line"><span class="built_in">print</span>(soup.select(<span class="string">&#x27;p[class]&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(soup.select(<span class="string">&#x27;a[id *= link]&#x27;</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p><strong>练习：使用组合或属性查找</strong></p>
<ol>
<li>查找类名以py开头的数据，并将文本内容打印输出</li>
<li>查找a标签有class属性的数据，并将其id的值打印输出</li>
</ol>
<h3 id="五、数据采集项目实战"><a href="#五、数据采集项目实战" class="headerlink" title="五、数据采集项目实战"></a>五、数据采集项目实战</h3><h5 id="5-1-文字数据采集"><a href="#5-1-文字数据采集" class="headerlink" title="5.1 文字数据采集"></a>5.1 文字数据采集</h5><ol>
<li>获取网页(明确目标)</li>
</ol>
<ul>
<li><p>需要采集网站为(飞卢小说)，本站强推：<a target="_blank" rel="noopener" href="https://b.faloo.com/Re_91_1.html">https://b.faloo.com/Re_91_1.html</a></p>
</li>
<li><p>​	需要采集哪些数据：小说的名字、作者的名字、小说类型、推荐时间、小说简介、具体小说的阅读连接地址</p>
</li>
<li><p>分析我们需要采集的网页基本结构</p>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下面CSS样式，能获取当前小说标题的元素</span></span><br><span class="line">.c_c_d_data1 &gt; .c_c_d_da_title</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面CSS样式，能获取当前小说作者及类型</span></span><br><span class="line">.c_c_d_data1 &gt; .c_c_d_da_author &gt; a</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面CSS样式，能获取当前小说推荐时间</span></span><br><span class="line">.c_c_d_data1 &gt; .c_c_d_da_time</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面CSS样式，能获取当前小说的简介和链接地址</span></span><br><span class="line">.c_c_d_data1 &gt; .c_c_d_da_data &gt; a</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li><p><strong>请求和响应的测试</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通用的请求框架</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:</span><br><span class="line">        <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 &#x27;</span></span><br><span class="line">        <span class="string">&#x27;Safari/537.36 Edg/118.0.2088.46 &#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getHTMLText</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        rep = requests.get(url, headers=headers)</span><br><span class="line">        rep.raise_for_status()</span><br><span class="line">        rep.encoding = rep.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> rep.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;产生非200响应状态异常，当前响应状态为&#123;&#125;，请进行及时修改代码&#x27;</span>.<span class="built_in">format</span>(rep.status_code)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">webUrl = <span class="string">&#x27;https://b.faloo.com/Re_91_1.html&#x27;</span></span><br><span class="line"></span><br><span class="line">soup = BeautifulSoup(getHTMLText(webUrl), <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试读取结果</span></span><br><span class="line"><span class="built_in">print</span>(soup.prettify())</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281006756.png" alt="image-20260128100638660"></p>
</li>
<li><p>追加下列代码，提取小说名、作者、小说类型的存储与测试</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通用的请求框架</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:</span><br><span class="line">        <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 &#x27;</span></span><br><span class="line">        <span class="string">&#x27;Safari/537.36 Edg/118.0.2088.46 &#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getHTMLText</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        rep = requests.get(url, headers=headers)</span><br><span class="line">        rep.raise_for_status()</span><br><span class="line">        rep.encoding = rep.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> rep.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;产生非200响应状态异常，当前响应状态为&#123;&#125;，请进行及时修改代码&#x27;</span>.<span class="built_in">format</span>(rep.status_code)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">webUrl = <span class="string">&#x27;https://b.faloo.com/Re_91_1.html&#x27;</span></span><br><span class="line"></span><br><span class="line">soup = BeautifulSoup(getHTMLText(webUrl), <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试读取结果</span></span><br><span class="line"><span class="comment"># print(soup.prettify())</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取我们需要的相关数据</span></span><br><span class="line"><span class="comment"># 下面CSS样式，能获取当前小说标题的元素</span></span><br><span class="line"><span class="comment"># print(soup.select(&#x27;.c_c_d_data1 &gt; .c_c_d_da_title&#x27;))</span></span><br><span class="line"></span><br><span class="line">bookName = []</span><br><span class="line"><span class="keyword">for</span> tag <span class="keyword">in</span> soup.select(<span class="string">&#x27;.c_c_d_data1 &gt; .c_c_d_da_title&#x27;</span>):</span><br><span class="line">    bookName.append(tag.string)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面CSS样式，能获取当前小说作者及类型</span></span><br><span class="line"></span><br><span class="line">authorNames = []</span><br><span class="line">bookTypes = []</span><br><span class="line"><span class="keyword">for</span> i, tag <span class="keyword">in</span> <span class="built_in">enumerate</span>(soup.select(<span class="string">&#x27;.c_c_d_data1 &gt; .c_c_d_da_author &gt; a&#x27;</span>)):</span><br><span class="line">    <span class="keyword">if</span>(i % <span class="number">2</span> == <span class="number">0</span>):</span><br><span class="line">        authorNames.append(tag.string)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        bookTypes.append(tag.string)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试数据</span></span><br><span class="line"><span class="comment"># print(authorNames)</span></span><br><span class="line"><span class="comment"># print(bookTypes)</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


</li>
<li><p>追加下列代码，提取小说推荐时间、简介、连接地址、进行组合</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通用的请求框架</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:</span><br><span class="line">        <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 &#x27;</span></span><br><span class="line">        <span class="string">&#x27;Safari/537.36 Edg/118.0.2088.46 &#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getHTMLText</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        rep = requests.get(url, headers=headers)</span><br><span class="line">        rep.raise_for_status()</span><br><span class="line">        rep.encoding = rep.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> rep.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;产生非200响应状态异常，当前响应状态为&#123;&#125;，请进行及时修改代码&#x27;</span>.<span class="built_in">format</span>(rep.status_code)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">webUrl = <span class="string">&#x27;https://b.faloo.com/Re_91_1.html&#x27;</span></span><br><span class="line"></span><br><span class="line">soup = BeautifulSoup(getHTMLText(webUrl), <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试读取结果</span></span><br><span class="line"><span class="comment"># print(soup.prettify())</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取我们需要的相关数据</span></span><br><span class="line"><span class="comment"># 下面CSS样式，能获取当前小说标题的元素</span></span><br><span class="line"><span class="comment"># print(soup.select(&#x27;.c_c_d_data1 &gt; .c_c_d_da_title&#x27;))</span></span><br><span class="line"></span><br><span class="line">bookNames = []</span><br><span class="line"><span class="keyword">for</span> tag <span class="keyword">in</span> soup.select(<span class="string">&#x27;.c_c_d_data1 &gt; .c_c_d_da_title&#x27;</span>):</span><br><span class="line">    bookNames.append(tag.string)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面CSS样式，能获取当前小说作者及类型</span></span><br><span class="line"></span><br><span class="line">authorNames = []</span><br><span class="line">bookTypes = []</span><br><span class="line"><span class="keyword">for</span> i, tag <span class="keyword">in</span> <span class="built_in">enumerate</span>(soup.select(<span class="string">&#x27;.c_c_d_data1 &gt; .c_c_d_da_author &gt; a&#x27;</span>)):</span><br><span class="line">    <span class="keyword">if</span>(i % <span class="number">2</span> == <span class="number">0</span>):</span><br><span class="line">        authorNames.append(tag.string)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        bookTypes.append(tag.string)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试数据</span></span><br><span class="line"><span class="comment"># print(bookNames)</span></span><br><span class="line"><span class="comment"># print(authorNames)</span></span><br><span class="line"><span class="comment"># print(bookTypes)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面CSS样式，能获取当前小说推荐时间</span></span><br><span class="line">bookTime = []</span><br><span class="line"><span class="keyword">for</span> tag <span class="keyword">in</span> soup.select(<span class="string">&#x27;.c_c_d_data1 &gt; .c_c_d_da_time&#x27;</span>):</span><br><span class="line">    bookTime.append(tag.string[<span class="number">5</span>:])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试数据</span></span><br><span class="line"><span class="comment"># print(bookTime)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面CSS样式，能获取当前小说的简介和链接地址</span></span><br><span class="line">bookBrief = []</span><br><span class="line">bookUrl = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> tag <span class="keyword">in</span> soup.select(<span class="string">&#x27;.c_c_d_data1 &gt; .c_c_d_da_data &gt; a&#x27;</span>):</span><br><span class="line">    bookBrief.append(tag.attrs[<span class="string">&#x27;title&#x27;</span>])</span><br><span class="line">    bookUrl.append(<span class="string">&#x27;https:&#x27;</span> + tag.attrs[<span class="string">&#x27;href&#x27;</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试数据</span></span><br><span class="line"><span class="comment"># print(bookBrief)</span></span><br><span class="line"><span class="comment"># print(bookUrl)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 压缩组装数据，二维数组</span></span><br><span class="line">bookInfo = <span class="built_in">zip</span>(bookNames, authorNames, bookTypes, bookTime, bookBrief, bookUrl)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试数据</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(bookInfo))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># enumerate 列：</span></span><br><span class="line"><span class="comment"># s = [1, 2, 3, 4, 5, 6]</span></span><br><span class="line"><span class="comment"># for i, j in enumerate(s, start=200):</span></span><br><span class="line"><span class="comment">#     print(i, j)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># x, y, z = (8, &#x27;abc&#x27;, True)</span></span><br><span class="line"><span class="comment"># print(x)</span></span><br><span class="line"><span class="comment"># print(z)</span></span><br><span class="line"><span class="comment"># print(y)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>知识扩展：zip函数的作用及应用</strong></p>
<p>zip()函数：用于将可迭代(循环处理)的对象作为参数，将对象(列表、元组等)中对应的元素打包成一个元组，然后返回由这些元组组成的列表。</p>
<p>语法：zip(可迭代对象1，可迭代对象2，……, 可迭代对象N)</p>
<p>说明：每一个可迭代对象长度建议一致，，我们可以理解一个列表数据为一列数据。列如：学生信息(学号、姓名、性别、年龄)，每一个列进行压缩，形成了学生完整的数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过创建模拟学号，类似采集过程中学生学号数据</span></span><br><span class="line">stuids = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">10001</span>, <span class="number">10009</span>))</span><br><span class="line"><span class="comment"># print(stuids)</span></span><br><span class="line"></span><br><span class="line">stunames = <span class="string">&#x27;张三 李四 王五 马六 田七 何八 郭就 怒是&#x27;</span>.split()</span><br><span class="line"><span class="comment"># print(stunames)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># print(len(stuids), len(stunames))</span></span><br><span class="line"></span><br><span class="line">stusexs = [<span class="string">&#x27;男&#x27;</span>, <span class="string">&#x27;女&#x27;</span>, <span class="string">&#x27;男&#x27;</span>, <span class="string">&#x27; 女&#x27;</span>, <span class="string">&#x27;男&#x27;</span>] * <span class="number">2</span></span><br><span class="line"><span class="comment"># print(stusexs)</span></span><br><span class="line"></span><br><span class="line">stuages = [<span class="number">18</span>, <span class="number">19</span>, <span class="number">20</span>, <span class="number">23</span>, <span class="number">12</span>, <span class="number">23</span>, <span class="number">23</span>, <span class="number">13</span>, <span class="number">24</span>, <span class="number">26</span>]</span><br><span class="line"><span class="comment"># print(stuages)</span></span><br><span class="line"></span><br><span class="line">stuinfo = <span class="built_in">zip</span>(stuids, stunames, stusexs, stuages)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(stuinfo))</span><br><span class="line"></span><br></pre></td></tr></table></figure>







<p><strong>保存数据</strong></p>
<ul>
<li>将数据存储为txt格式</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存数据</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;E:\采集的小说信息.txt&#x27;</span>, mode=<span class="string">&#x27;w+&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> i, book <span class="keyword">in</span> <span class="built_in">enumerate</span>(bookInfo):</span><br><span class="line">        <span class="keyword">if</span> i == <span class="built_in">len</span>(bookNames) - <span class="number">1</span>:</span><br><span class="line">            f.write(<span class="string">&#x27; &#x27;</span>.join(book))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            f.write(<span class="string">&#x27; &#x27;</span>.join(book) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;写入完成！&#x27;</span>)</span><br></pre></td></tr></table></figure>



<ul>
<li>将数据存储为csv格式(逗号分割值文本文档格式)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存为csv文件数据</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;E:\采集的小说信息.csv&#x27;</span>, mode=<span class="string">&#x27;w+&#x27;</span>, encoding=<span class="string">&#x27;GBK&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> i, book <span class="keyword">in</span> <span class="built_in">enumerate</span>(bookInfo):</span><br><span class="line">        <span class="keyword">if</span> i == <span class="built_in">len</span>(bookNames) - <span class="number">1</span>:</span><br><span class="line">            f.write(<span class="string">&#x27;,&#x27;</span>.join(book))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            f.write(<span class="string">&#x27;,&#x27;</span>.join(book) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;写入完成！&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<h5 id="5-2-使用PyMysql进行数据库连接执行增、删、改、查"><a href="#5-2-使用PyMysql进行数据库连接执行增、删、改、查" class="headerlink" title="5.2 使用PyMysql进行数据库连接执行增、删、改、查"></a>5.2 使用PyMysql进行数据库连接执行增、删、改、查</h5><ol>
<li>请通过pip命令安装pymsql,在终端命令为：</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pymysql</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>打开数据库工具navicat软件，进行创建数据库：</li>
</ol>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281006111.png" alt="image-20260128100650031"></p>
<ol start="3">
<li>可以选择在navicat或python程序中创建数据库表，接下来的演示，我们在python中进行创建 数据库表</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"># 1.导入pymsql</span><br><span class="line">import pymysql</span><br><span class="line"></span><br><span class="line"># 2.创建数据库连接</span><br><span class="line"># host 表示主机， port 表示端口号， user 表示用户名， passworld 表示密码， database 表示需要连接数据库的名字</span><br><span class="line">db = pymysql.connect(host=&#x27;localhost&#x27;,</span><br><span class="line">                     port=3306,</span><br><span class="line">                     user=&#x27;root&#x27;,</span><br><span class="line">                     password=&#x27;123456&#x27;,</span><br><span class="line">                     database=&#x27;pymysqldb&#x27;)</span><br><span class="line"></span><br><span class="line"># 3.创建一个游标对象</span><br><span class="line">cursor = db.cursor()</span><br><span class="line"></span><br><span class="line"># 使用游标对象执行sql语句</span><br><span class="line">cursor.execute(&#x27;DROP TABLE IF EXISTS student&#x27;)</span><br><span class="line"></span><br><span class="line">sql = &#x27;&#x27;&#x27;</span><br><span class="line">CREATE TABLE student(</span><br><span class="line">	stuid int PRIMARY key,</span><br><span class="line">	stuname VARCHAR(30) not NULL,</span><br><span class="line">	stusex VARCHAR(2) NOT NULL,</span><br><span class="line">	stuage int NOT NULL</span><br><span class="line">)</span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line"></span><br><span class="line">cursor.execute(sql)</span><br><span class="line"></span><br><span class="line">#  5.关闭数据库连接</span><br><span class="line">db.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p><strong>使用Pymysql插入数据相关操作</strong></p>
<p>简单操作(理解使用，不推荐实际使用)：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 导入pymysql</span></span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"><span class="comment"># 2. 创建数据库连接</span></span><br><span class="line"><span class="comment"># host 表示主机，port 表示端口号，user 表示用户名，password 表示密码，database 表示需</span></span><br><span class="line">要连接的数据库名字</span><br><span class="line">db = pymysql.connect(host=<span class="string">&#x27;localhost&#x27;</span>,</span><br><span class="line">port=<span class="number">3306</span>,</span><br><span class="line">user=<span class="string">&#x27;root&#x27;</span>,</span><br><span class="line">password=<span class="string">&#x27;123456&#x27;</span>,</span><br><span class="line">database=<span class="string">&#x27;pymysqldb&#x27;</span>)</span><br><span class="line"><span class="comment"># 3. 创建一个游标对象</span></span><br><span class="line">cursor = db.cursor()</span><br><span class="line"><span class="comment"># 4. 插入数据的操作</span></span><br><span class="line">sql = <span class="string">&quot;INSERT INTO student(stuid, stuname, stusex, stuage) &quot;</span> \</span><br><span class="line"><span class="string">&quot;VALUES (10001, &#x27;张三&#x27;, &#x27;男&#x27;, 20)&quot;</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">cursor.execute(sql)</span><br><span class="line"><span class="comment"># 提交到数据库执行</span></span><br><span class="line">db.commit()</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line"><span class="comment"># 如果发生错误，执行数据库的回滚</span></span><br><span class="line">db.rollback()</span><br><span class="line"><span class="comment"># 5. 关闭数据库连接</span></span><br><span class="line">db.close()</span><br></pre></td></tr></table></figure>



<p><strong>正确操作(推荐大家使用)</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 导入pymysql</span></span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"><span class="comment"># 2. 创建数据库连接</span></span><br><span class="line"><span class="comment"># host 表示主机，port 表示端口号，user 表示用户名，password 表示密码，database 表示需</span></span><br><span class="line">要连接的数据库名字</span><br><span class="line">db = pymysql.connect(host=<span class="string">&#x27;localhost&#x27;</span>,</span><br><span class="line">port=<span class="number">3306</span>,</span><br><span class="line">user=<span class="string">&#x27;root&#x27;</span>,</span><br><span class="line">password=<span class="string">&#x27;123456&#x27;</span>,</span><br><span class="line">database=<span class="string">&#x27;pymysqldb&#x27;</span>)</span><br><span class="line"><span class="comment"># 3. 创建一个游标对象</span></span><br><span class="line">cursor = db.cursor()</span><br><span class="line"><span class="comment"># 4. 插入数据的操作</span></span><br><span class="line"><span class="comment"># sql = &quot;INSERT INTO student(stuid, stuname, stusex, stuage) &quot; \</span></span><br><span class="line"><span class="comment"># &quot;VALUES (10001, &#x27;张三&#x27;, &#x27;男&#x27;, 20)&quot;</span></span><br><span class="line"><span class="comment"># 在实际运用中sql正确写法</span></span><br><span class="line">stuid = <span class="number">10002</span></span><br><span class="line">stuname = <span class="string">&#x27;李四&#x27;</span></span><br><span class="line">stusex = <span class="string">&#x27;男&#x27;</span></span><br><span class="line">stuage = <span class="number">18</span></span><br><span class="line">sql = <span class="string">&quot;INSERT INTO student(stuid, stuname, stusex, stuage) &quot;</span> \</span><br><span class="line"><span class="string">&quot;VALUES (&#x27;%s&#x27;, &#x27;%s&#x27;, &#x27;%s&#x27;, &#x27;%s&#x27;)&quot;</span> % (stuid, stuname, stusex, stuage)</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">cursor.execute(sql)</span><br><span class="line"><span class="comment"># 提交到数据库执行</span></span><br><span class="line">db.commit()</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line"><span class="comment"># 如果发生错误，执行数据库的回滚</span></span><br><span class="line">db.rollback()</span><br><span class="line"><span class="comment"># 5. 关闭数据库连接</span></span><br><span class="line">db.close()</span><br></pre></td></tr></table></figure>



<p>实践练习：30分钟 通过PyMySQL向pymysqldb数据库中student表插入如下数据：</p>
<table>
<thead>
<tr>
<th>stuid</th>
<th>stuname</th>
<th>stusex</th>
<th>stuage</th>
</tr>
</thead>
<tbody><tr>
<td>10003</td>
<td>何仙姑</td>
<td>女</td>
<td>23</td>
</tr>
<tr>
<td>10004</td>
<td>周伯通</td>
<td>男</td>
<td>25</td>
</tr>
<tr>
<td>10005</td>
<td>黄蓉</td>
<td>女</td>
<td>17</td>
</tr>
<tr>
<td>10006</td>
<td>郭靖</td>
<td>男</td>
<td>20</td>
</tr>
<tr>
<td>10007</td>
<td>杨过</td>
<td>男</td>
<td>16</td>
</tr>
</tbody></table>
<p><strong>方式一：通过循环进行逐条插入数据</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 导入pymysql</span></span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"><span class="comment"># 2. 创建数据库连接</span></span><br><span class="line"><span class="comment"># host 表示主机，port 表示端口号，user 表示用户名，password 表示密码，database 表示需</span></span><br><span class="line">要连接的数据库名字</span><br><span class="line">db = pymysql.connect(host=<span class="string">&#x27;localhost&#x27;</span>,</span><br><span class="line">port=<span class="number">3306</span>,</span><br><span class="line">user=<span class="string">&#x27;root&#x27;</span>,</span><br><span class="line">password=<span class="string">&#x27;123456&#x27;</span>,</span><br><span class="line">database=<span class="string">&#x27;pymysqldb&#x27;</span>)</span><br><span class="line"><span class="comment"># 3. 创建一个游标对象</span></span><br><span class="line">cursor = db.cursor()</span><br><span class="line"><span class="comment"># 4. 插入数据的操作</span></span><br><span class="line">stuids = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">10003</span>, <span class="number">10008</span>))</span><br><span class="line">stunames = <span class="string">&#x27;何仙姑 周伯通 黄蓉 郭靖 杨过&#x27;</span>.split()</span><br><span class="line">stusexs = (<span class="string">&#x27;女 男&#x27;</span>.split()) * <span class="number">2</span> + [<span class="string">&#x27;男&#x27;</span>]</span><br><span class="line">stuages = [<span class="number">23</span>, <span class="number">25</span>, <span class="number">17</span>, <span class="number">20</span>, <span class="number">16</span>]</span><br><span class="line">datas = <span class="built_in">zip</span>(stuids, stunames, stusexs, stuages)</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line"><span class="keyword">for</span> stuid, stuname, stusex, stuage <span class="keyword">in</span> datas:</span><br><span class="line">sql = <span class="string">&quot;INSERT INTO student(stuid, stuname, stusex, stuage) &quot;</span> \</span><br><span class="line"><span class="string">&quot;VALUES (&#x27;%s&#x27;, &#x27;%s&#x27;, &#x27;%s&#x27;, &#x27;%s&#x27;)&quot;</span> % (stuid, stuname, stusex,</span><br><span class="line">stuage)</span><br><span class="line">cursor.execute(sql)</span><br><span class="line"><span class="comment"># 提交到数据库执行</span></span><br><span class="line">db.commit()</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line"><span class="comment"># 如果发生错误，执行数据库的回滚</span></span><br><span class="line">db.rollback()</span><br><span class="line"><span class="comment"># 5. 关闭数据库连接</span></span><br><span class="line">db.close()</span><br></pre></td></tr></table></figure>



<p><strong>方法二：通过PyMySQL通过方法进行批量插入数据(推荐)</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 导入pymysql</span></span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"><span class="comment"># 2. 创建数据库连接</span></span><br><span class="line"><span class="comment"># host 表示主机，port 表示端口号，user 表示用户名，password 表示密码，database 表示需</span></span><br><span class="line">要连接的数据库名字</span><br><span class="line">db = pymysql.connect(host=<span class="string">&#x27;localhost&#x27;</span>,</span><br><span class="line">port=<span class="number">3306</span>,</span><br><span class="line">user=<span class="string">&#x27;root&#x27;</span>,</span><br><span class="line">password=<span class="string">&#x27;123456&#x27;</span>,</span><br><span class="line">database=<span class="string">&#x27;pymysqldb&#x27;</span>)</span><br><span class="line"><span class="comment"># 3. 创建一个游标对象</span></span><br><span class="line">cursor = db.cursor()</span><br><span class="line"><span class="comment"># 4. 插入数据的操作</span></span><br><span class="line">stuids = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">10003</span>, <span class="number">10008</span>))</span><br><span class="line">stunames = <span class="string">&#x27;何仙姑 周伯通 黄蓉 郭靖 杨过&#x27;</span>.split()</span><br><span class="line">stusexs = (<span class="string">&#x27;女 男&#x27;</span>.split()) * <span class="number">2</span> + [<span class="string">&#x27;男&#x27;</span>]</span><br><span class="line">stuages = [<span class="number">23</span>, <span class="number">25</span>, <span class="number">17</span>, <span class="number">20</span>, <span class="number">16</span>]</span><br><span class="line">datas = <span class="built_in">zip</span>(stuids, stunames, stusexs, stuages)</span><br><span class="line"><span class="comment"># 提示：使用批量插入需要修订sql写法</span></span><br><span class="line">sql = <span class="string">&quot;INSERT INTO student(stuid, stuname, stusex, stuage) &quot;</span> \</span><br><span class="line"><span class="string">&quot;VALUES (%s, %s, %s, %s)&quot;</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">cursor.executemany(sql, datas)</span><br><span class="line"><span class="comment"># 提交到数据库执行</span></span><br><span class="line">db.commit()</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;发生错误！&#x27;</span>)</span><br><span class="line"><span class="comment"># 如果发生错误，执行数据库的回滚</span></span><br><span class="line">db.rollback()</span><br><span class="line"><span class="comment"># 5. 关闭数据库连接</span></span><br><span class="line">db.close()</span><br></pre></td></tr></table></figure>





<p><strong>期末项目考核一：</strong></p>
<ul>
<li>在数据库管理系统中新建一个数据库： feiludb </li>
<li>在当前数据库创建数据表( mybooks )字段： bookname 字符串类型(100) 、 authorname 字符串类 型(30) 、 booktype 字符串类型(50) 、 booktime 日期类型 、 bookbrief 字符串类型(255) 、 bookurl 字符串类型(100) </li>
<li>依据之前编写的采集飞卢小说网中，本站强推的小说信息数据采集 </li>
<li>将其相关数据存储 </li>
<li>提交相关操作代码(SQL(建立数据库、数据表)、python采集信息和存储数据库的代码)，相关如 下图所示：</li>
</ul>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281007764.png" alt="image-20260128100708689"></p>
<p><strong>期末项目考核附加(30分)：</strong> </p>
<ul>
<li>采集飞卢小说网中本站强推 </li>
<li>采集的数据为小说的封面图片，保存到本地电脑中 xiaoshuotupian 文件夹内 </li>
<li>每张图片名字为网站本身图片名字 </li>
<li>采集一页多张图片(10分)，两页多张图片(15分)，三页或更多页多张图片(20分) </li>
<li>根据大家代码的质量以及性能进行评分(3~10分)。 </li>
<li>最晚提交时间：2023年11月8日 18:00之前</li>
</ul>
<p><strong>PyMySQL查询数据</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.导入pymsql</span></span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.创建数据库连接</span></span><br><span class="line"><span class="comment"># host 表示主机， port 表示端口号， user 表示用户名， passworld 表示密码， database 表示需要连接数据库的名字</span></span><br><span class="line">db = pymysql.connect(host=<span class="string">&#x27;localhost&#x27;</span>,</span><br><span class="line">                     port=<span class="number">3306</span>,</span><br><span class="line">                     user=<span class="string">&#x27;root&#x27;</span>,</span><br><span class="line">                     password=<span class="string">&#x27;123456&#x27;</span>,</span><br><span class="line">                     database=<span class="string">&#x27;pymysqldb&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.创建一个游标对象</span></span><br><span class="line">cursor = db.cursor()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.创建查询sql语句</span></span><br><span class="line">sql = <span class="string">&quot;SELECT * FROM student where stuage &gt; %s&quot;</span> % (<span class="number">19</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="comment"># 5.执行sql语句</span></span><br><span class="line">    cursor.execute(sql)</span><br><span class="line">    <span class="comment"># 6.执行获取所有记录的方法</span></span><br><span class="line">    results = cursor.fetchall()</span><br><span class="line">    <span class="comment"># 7.通过循环将其进行逐行读取</span></span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> results:</span><br><span class="line">        uid = row[<span class="number">0</span>]</span><br><span class="line">        name = row[<span class="number">1</span>]</span><br><span class="line">        sex = row[<span class="number">2</span>]</span><br><span class="line">        age = row[<span class="number">3</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;学号=%s,姓名=%s,性别=%s,年龄=%s&#x27;</span> % (uid, name, sex, age))</span><br><span class="line"><span class="keyword">except</span> :</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;发生错误&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 8.关闭数据库连接</span></span><br><span class="line">db.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure>







<h3 id="数据生产库Faker"><a href="#数据生产库Faker" class="headerlink" title="数据生产库Faker"></a>数据生产库Faker</h3><p><strong>Faker的作用：</strong></p>
<p>Python第三方开源项目，可以生成虚假数据，无论我们要引导数据库，填写一些持久性数据对项目进行 压力测试。</p>
<p><strong>能生成的数据：</strong></p>
<ul>
<li>地理信息 </li>
<li>网络信息 </li>
<li>邮箱信息 </li>
<li>人工作生活信息 </li>
<li>浏览器信息 </li>
<li>数字信息 </li>
<li>文本加密信息 </li>
<li>时间信息</li>
</ul>
<p><strong>如何安装：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install faker</span><br></pre></td></tr></table></figure>

<p><strong>基本运用</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入Fack类</span></span><br><span class="line"><span class="keyword">from</span> faker <span class="keyword">import</span> Faker</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.创建对象，默认是英文，需要创建传入参数 zh_CN 表示指定中文</span></span><br><span class="line">fake = Faker(<span class="string">&#x27;zh_CN&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟输出姓名</span></span><br><span class="line"><span class="built_in">print</span>(fake.name())</span><br><span class="line"></span><br><span class="line">names = [fake.name() <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line"><span class="built_in">print</span>(names)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟生成家庭地址</span></span><br><span class="line"><span class="built_in">print</span>(fake.address())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟生成电话号码</span></span><br><span class="line"><span class="built_in">print</span>(fake.phone_number())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟生成电子邮箱</span></span><br><span class="line"><span class="built_in">print</span>(fake.email())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟数据生成国家</span></span><br><span class="line"><span class="built_in">print</span>(fake.country())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟生成地区</span></span><br><span class="line"><span class="built_in">print</span>(fake.province())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟生成用户名</span></span><br><span class="line"><span class="built_in">print</span>(fake.user_name())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟生成网站</span></span><br><span class="line"><span class="built_in">print</span>(fake.url())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟生成身份证</span></span><br><span class="line"><span class="built_in">print</span>(fake.ssn())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 相关函数的参考网址</span></span><br><span class="line"><span class="comment"># https://www.cnblogs.com/OceanHoi/p/16866183.html</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281007251.png" alt="image-20260128100719165"></p>
<h2 id="数据采集02"><a href="#数据采集02" class="headerlink" title="数据采集02"></a>数据采集02</h2><h3 id="一、开发环境需求"><a href="#一、开发环境需求" class="headerlink" title="一、开发环境需求"></a>一、开发环境需求</h3><h4 id="1-1-关于Python需求"><a href="#1-1-关于Python需求" class="headerlink" title="1.1 关于Python需求"></a>1.1 关于Python需求</h4><ul>
<li>安装Python解释器(Python3) </li>
<li>安装Anaconda(Python3发行版本)</li>
</ul>
<h4 id="1-2-开发工具需求"><a href="#1-2-开发工具需求" class="headerlink" title="1.2 开发工具需求"></a>1.2 开发工具需求</h4><ul>
<li>PyCharm(推荐) </li>
<li>Jupyter Notebook(Anaconda自带) </li>
<li>VScode(需要配置插件)</li>
</ul>
<h4 id="1-3-数据采集常用请求库"><a href="#1-3-数据采集常用请求库" class="headerlink" title="1.3 数据采集常用请求库"></a>1.3 数据采集常用请求库</h4><ul>
<li>Python内置请求库(Urllib3) - 基本上都没有怎么用了 </li>
<li>requests</li>
<li>Selenium(自动化工具) + ChromeDriver驱动配置 </li>
<li>PhantomJS(无界面、可脚本编程的Webkit浏览器引擎)</li>
</ul>
<h4 id="1-4-数据采集常用解析库"><a href="#1-4-数据采集常用解析库" class="headerlink" title="1.4 数据采集常用解析库"></a>1.4 数据采集常用解析库</h4><ul>
<li>lxml </li>
<li>Beautiful Soup </li>
<li>pyquery </li>
<li>tesserocr(了解，我们在采集数据时，遇到了验证码或图形验证码，可以用OCR来识别)</li>
</ul>
<h4 id="1-5-常用存储"><a href="#1-5-常用存储" class="headerlink" title="1.5 常用存储"></a>1.5 常用存储</h4><ul>
<li>MySQL(关系型数据库) </li>
<li>MongoDB(列式数据库) - 代理(IP代理、登录用户代理等等) </li>
<li>Redis(基于内存的高效非关系型数据) - 代理(IP代理、登录用户代理等等)</li>
</ul>
<h4 id="1-6-存储连接操作库"><a href="#1-6-存储连接操作库" class="headerlink" title="1.6 存储连接操作库"></a>1.6 存储连接操作库</h4><ul>
<li>PyMySQL </li>
<li>PyMongoDB </li>
<li>redis-py + redisDump(数据导入&#x2F;导出)的工具</li>
</ul>
<h4 id="1-7-App爬取相关库"><a href="#1-7-App爬取相关库" class="headerlink" title="1.7 App爬取相关库"></a>1.7 App爬取相关库</h4><ul>
<li>Charles(网络抓包工具) </li>
<li>Appium(移动端的自动化测试工具)</li>
</ul>
<h4 id="1-8-爬虫框架库"><a href="#1-8-爬虫框架库" class="headerlink" title="1.8 爬虫框架库"></a>1.8 爬虫框架库</h4><ul>
<li>Scrapy </li>
<li>pyspider</li>
</ul>
<h3 id="二、安装相关库"><a href="#二、安装相关库" class="headerlink" title="二、安装相关库"></a>二、安装相关库</h3><h4 id="2-1-PyCharm的Python解释器配置"><a href="#2-1-PyCharm的Python解释器配置" class="headerlink" title="2.1 PyCharm的Python解释器配置"></a>2.1 PyCharm的Python解释器配置</h4><p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281007415.png" alt="image-20260128100730318"></p>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281007006.png" alt="image-20260128100737920"></p>
<h4 id="2-2-查看当前解释器已经安装好了哪些库"><a href="#2-2-查看当前解释器已经安装好了哪些库" class="headerlink" title="2.2 查看当前解释器已经安装好了哪些库"></a>2.2 查看当前解释器已经安装好了哪些库</h4><p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281007693.png" alt="image-20260128100747596"></p>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281007281.png" alt="image-20260128100756196"></p>
<h4 id="2-3-安装要使用的第三方库"><a href="#2-3-安装要使用的第三方库" class="headerlink" title="2.3 安装要使用的第三方库"></a>2.3 安装要使用的第三方库</h4><p>文本转语音</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下面的是安装文本转语音的三方库</span></span><br><span class="line">pip install pyttsx3</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pyttsx3</span><br><span class="line">engine = pyttsx3.init()</span><br><span class="line">engine.say(<span class="string">&quot;How Do You Do, 今天是2023年12月12日双十二活动现场，接下来有请我们主持人:张</span></span><br><span class="line"><span class="string">俊宇。大家掌声欢迎&quot;</span>)</span><br><span class="line">engine.runAndWait()</span><br></pre></td></tr></table></figure>



<p>微信聊天机器人</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pyautogui</span><br></pre></td></tr></table></figure>

<p>会自动安装一个 pyperclip</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pyautogui</span><br><span class="line"><span class="keyword">import</span> pyperclip</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># 需要发生具体消息</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_msg</span>():</span><br><span class="line">contents = <span class="string">&#x27;通知：2023年12月22日10:00到515集合，今天讲解内容为：网络爬虫采集小说</span></span><br><span class="line"><span class="string">数据&#x27;</span></span><br><span class="line"><span class="keyword">return</span> contents.split(<span class="string">&quot;，&quot;</span>)</span><br><span class="line"><span class="comment"># 发送操作</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">send</span>(<span class="params">msg</span>):</span><br><span class="line"><span class="comment"># 复制需要发送的内容到粘贴板</span></span><br><span class="line">pyperclip.copy(msg)</span><br><span class="line"><span class="comment"># 模拟键盘粘贴快捷键</span></span><br><span class="line">pyautogui.hotkey(<span class="string">&#x27;ctrl&#x27;</span>, <span class="string">&#x27;v&#x27;</span>) <span class="comment"># ctrl + v</span></span><br><span class="line"><span class="comment"># 发送消息</span></span><br><span class="line">pyautogui.hotkey(<span class="string">&#x27;enter&#x27;</span>)</span><br><span class="line"><span class="comment"># 操作微信</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">send_msg</span>(<span class="params">friend_name</span>):</span><br><span class="line"><span class="comment"># 模拟打开微信的快捷键</span></span><br><span class="line">pyautogui.hotkey(<span class="string">&#x27;ctrl&#x27;</span>, <span class="string">&#x27;alt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line"><span class="comment"># 搜索好友</span></span><br><span class="line">pyautogui.hotkey(<span class="string">&#x27;ctrl&#x27;</span>, <span class="string">&#x27;f&#x27;</span>)</span><br><span class="line"><span class="comment"># 复制好友名字</span></span><br><span class="line">pyperclip.copy(friend_name)</span><br><span class="line"><span class="comment"># 模拟键盘粘贴好友到输入框</span></span><br><span class="line">pyautogui.hotkey(<span class="string">&#x27;ctrl&#x27;</span>, <span class="string">&#x27;v&#x27;</span>)</span><br><span class="line"><span class="comment"># 线程停止3秒</span></span><br><span class="line">time.sleep(<span class="number">3</span>)</span><br><span class="line"><span class="comment"># 回车进入好友消息界面</span></span><br><span class="line">pyautogui.hotkey(<span class="string">&#x27;enter&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> msg <span class="keyword">in</span> get_msg():</span><br><span class="line">send(msg)</span><br><span class="line"><span class="comment"># 每条消息间隔30秒</span></span><br><span class="line">time.sleep(<span class="number">30</span>)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">send_msg(<span class="string">&quot;22级大数据-谭含天&quot;</span>)</span><br></pre></td></tr></table></figure>



<h3 id="三、网络请求框架"><a href="#三、网络请求框架" class="headerlink" title="三、网络请求框架"></a>三、网络请求框架</h3><h4 id="3-1-Requests请求"><a href="#3-1-Requests请求" class="headerlink" title="3.1 Requests请求"></a>3.1 Requests请求</h4><p>Requests是一个 优雅而简单 的 Python HTTP 库，专为人类而构建。 </p>
<p>Requests允许您极其轻松地发送 HTTP&#x2F;1.1 请求。无需手动将查询字符串添加到 URL，或对 POST 数据进行表单编码。得益于urllib3，Keep-alive 和 HTTP 连接池是 100% 自动的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install requests</span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 请求到响应基础运用(以百度为例)</span></span><br><span class="line"><span class="comment"># 1. 导入需要情况库文件</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 请求和响应</span></span><br><span class="line"><span class="comment"># rep变量就是得到请求成功后响应的对象</span></span><br><span class="line"><span class="comment"># requests.get(网址字符串)</span></span><br><span class="line">webUrl = <span class="string">&#x27;https://www.baidu.com&#x27;</span></span><br><span class="line">rep = requests.get(webUrl)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 读取百度网站的HTML内容(字符串)</span></span><br><span class="line"><span class="built_in">print</span>(rep.text)</span><br><span class="line"><span class="comment"># 我们是不是发现响应回来的内容有乱码</span></span><br><span class="line"><span class="comment"># 默认请求百度的编码方式</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;百度的编码方式为：&quot;</span> + rep.encoding)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;自动推断区域编码：&quot;</span> + rep.apparent_encoding)</span><br><span class="line">rep.encoding = rep.apparent_encoding</span><br><span class="line"><span class="built_in">print</span>(rep.text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 状态码</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;百度请求的状态码&quot;</span> + <span class="built_in">str</span>(rep.status_code))</span><br></pre></td></tr></table></figure>



<p><strong>状态码</strong></p>
<p>1开头状态码：请求收到，继续处理 </p>
<p>2开头状态码：操作成功收到，分析、接受 </p>
<p>3开头状态码：完成此请求必须进一步处理 </p>
<p>4开头状态码：请求包含一个错误语法或不能完成 </p>
<p>5开头状态码：服务器执行一个完全有效请求失败 </p>
<p>100——客户必须继续发出请求 </p>
<p>101——客户要求服务器根据请求转换HTTP协议版本</p>
<p>200——交易成功 </p>
<p>201——提示知道新文件的URL </p>
<p>202——接受和处理、但处理未完成 </p>
<p>203——返回信息不确定或不完整 </p>
<p>204——请求收到，但返回信息为空 </p>
<p>205——服务器完成了请求，用户代理必须复位当前已经浏览过的文件 </p>
<p>206——服务器已经完成了部分用户的GET请求 </p>
<p>300——请求的资源可在多处得到 </p>
<p>301——删除请求数据 </p>
<p>302——在其他地址发现了请求数据 </p>
<p>303——建议客户访问其他URL或访问方式 </p>
<p>304——客户端已经执行了GET，但文件未变化 </p>
<p>305——请求的资源必须从服务器指定的地址得到 </p>
<p>306——前一版本HTTP中使用的代码，现行版本中不再使用 </p>
<p>307——申明请求的资源临时性删除 </p>
<p>400——客户端发起的请求错误，如语法错误 </p>
<p>401——请求授权失败，需要身份认证 </p>
<p>402——保留有效ChargeTo头响应 </p>
<p>403——服务端理解客户端的请求，但是拒接此请求（你说气不气？） </p>
<p>404——没有发现文件、查询或URl </p>
<p>405——用户在Request-Line字段定义的方法不允许 </p>
<p>406——根据用户发送的Accept拖，请求资源不可访问</p>
<p>407——类似401，用户必须首先在代理服务器上得到授权 </p>
<p>408——客户端没有在用户指定的饿时间内完成请求 </p>
<p>409——对当前资源状态，请求不能完成 </p>
<p>410——服务器上不再有此资源且无进一步的参考地址,</p>
<p>410不同于404，如果资源以前有现在被永久删除 了可使用410代码，网站设计人员可通过301代码指定资源的新位置 </p>
<p>411——服务器拒绝用户定义的Content-Length属性请求 </p>
<p>412——一个或多个请求头字段在当前请求中错误 </p>
<p>413——请求的资源大于服务器允许的大小 </p>
<p>414——请求的资源URL长于服务器允许的长度 </p>
<p>415——请求资源不支持请求项目格式 </p>
<p>416——请求中包含Range请求头字段，在当前请求资源范围内没有range指示值，请求也不包含IfRange请求头字段 </p>
<p>417——服务器不满足请求Expect头字段指定的期望值，如果是代理服务器，可能是下一级服务器不能满 足请求 </p>
<p>500——服务器内部发生错误，无法完成请求响应 </p>
<p>501——服务器不支持请求的功能 </p>
<p>502——充当网关或代理的服务器，从远端服务器接收到了一个无效的请求 </p>
<p>503——服务器过载或处于维护状态，暂停服务 </p>
<p>504——充当网关或代理的服务器，未及时从远端服务器获得请求 </p>
<p>505——服务器不支持或拒绝请求头中指定的HTTP版本</p>
<p><strong>如何请求和响应多媒体数据</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">imgUrl =</span><br><span class="line"><span class="string">&quot;https://globalimg.sucai999.com/preimg/DBC456/700/DBC456/101/7f3b16dbdee11014</span></span><br><span class="line"><span class="string">56ecca13e8b0dd94.jpg&quot;</span></span><br><span class="line">rep = requests.get(imgUrl)</span><br><span class="line"><span class="comment"># 写入图片的操作</span></span><br><span class="line"><span class="comment"># mode=&#x27;w&#x27; 表示写入文本，如果要写入二进制(byte)就需要使用 &#x27;wb&#x27;(write byte)</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;D:/美女1.jpg&#x27;</span>, mode=<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">f.write(rep.content)</span><br></pre></td></tr></table></figure>

<p><strong>我们请求的网站是如何知道请求是爬虫？我们该如何解决？</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">webUrl = <span class="string">&#x27;https://www.douban.com/&#x27;</span></span><br><span class="line"><span class="comment"># 伪装请求的头部信息</span></span><br><span class="line">head = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64)</span></span><br><span class="line"><span class="string">AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">rep = requests.get(webUrl, headers=head)</span><br><span class="line">rep.encoding = rep.apparent_encoding</span><br><span class="line"><span class="built_in">print</span>(rep.text)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;豆瓣网返回响应的状态码：&quot;</span> + <span class="built_in">str</span>(rep.status_code))</span><br><span class="line"><span class="comment"># 向服务器请求时，带了哪些协议过去？</span></span><br><span class="line"><span class="built_in">print</span>(rep.request.headers)</span><br></pre></td></tr></table></figure>

<p><strong>请求返回数据的通用模块</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="comment"># 请求和响应的通用模块</span></span><br><span class="line"><span class="comment"># 参数：webUrl为需要请求的网址，whetherByte=False为是否为字节数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getHTMLAndByte</span>(<span class="params">webUrl, whetherByte=<span class="literal">False</span></span>):</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line"><span class="comment"># 伪装请求的头部信息</span></span><br><span class="line">head = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64)</span></span><br><span class="line"><span class="string">AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">rep = requests.get(webUrl, headers=head)</span><br><span class="line"><span class="comment"># 当请求响应回来的状态为200就是正常，会执行后续代码。如果非200就进入异常块</span></span><br><span class="line">(<span class="keyword">except</span>)</span><br><span class="line">rep.raise_for_status()</span><br><span class="line">rep.encoding = rep.apparent_encoding</span><br><span class="line"><span class="comment"># 当前whetherByte的值为True时，返回二进制字节数据</span></span><br><span class="line"><span class="keyword">if</span> whetherByte:</span><br><span class="line"><span class="keyword">return</span> rep.content</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="keyword">return</span> rep.text</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line"><span class="keyword">return</span> <span class="string">&#x27;产生非200响应异常，当前响应状态码为&#123;&#125;, 请及时修改代</span></span><br><span class="line"><span class="string">码&#x27;</span>.<span class="built_in">format</span>(rep.status_code)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 验证模块是否能请求</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"><span class="comment"># url = &#x27;http://www.baidu.com&#x27;</span></span><br><span class="line"><span class="comment"># data1 = getHTMLAndByte(url)</span></span><br><span class="line"><span class="comment"># print(data1)</span></span><br><span class="line">url =</span><br><span class="line"><span class="string">&#x27;https://globalimg.sucai999.com/preimg/DBC456/700/DBC456/155/4ceecb3136b74eb9</span></span><br><span class="line"><span class="string">2e0a097eb4a27b.jpg&#x27;</span></span><br><span class="line">imgByte = getHTMLAndByte(url, <span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(imgByte)</span><br></pre></td></tr></table></figure>



<h4 id="3-2-数据采集训练"><a href="#3-2-数据采集训练" class="headerlink" title="3.2 数据采集训练"></a>3.2 数据采集训练</h4><ol>
<li>获取12306的所有火车的站点数据</li>
</ol>
<ul>
<li>请求网址：<a target="_blank" rel="noopener" href="https://www.12306.cn/index/script/core/common/station_name_new">https://www.12306.cn/index/script/core/common/station_name_new</a>_ v10023.js </li>
<li>获取所有站点的中文名称 </li>
<li>然后将其写入到一个名称 12306火车站点数据.txt 文件中，每个站点占一行。具体效果如下：</li>
</ul>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281008671.png" alt="image-20260128100809604"></p>
<p><strong>实现代码：</strong></p>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281008664.png" alt="image-20260128100818571"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="comment"># 请求和响应的通用模块</span></span><br><span class="line"><span class="comment"># 参数：webUrl为需要请求的网址，whetherByte=False为是否为字节数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getHTMLAndByte</span>(<span class="params">webUrl, whetherByte=<span class="literal">False</span></span>):</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line"><span class="comment"># 伪装请求的头部信息</span></span><br><span class="line">head = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64)</span></span><br><span class="line"><span class="string">AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">rep = requests.get(webUrl, headers=head)</span><br><span class="line"><span class="comment"># 当请求响应回来的状态为200就是正常，会执行后续代码。如果非200就进入异常块</span></span><br><span class="line">(<span class="keyword">except</span>)</span><br><span class="line">rep.raise_for_status()</span><br><span class="line">rep.encoding = rep.apparent_encoding</span><br><span class="line"><span class="comment"># 当前whetherByte的值为True时，返回二进制字节数据</span></span><br><span class="line"><span class="keyword">if</span> whetherByte:</span><br><span class="line"><span class="keyword">return</span> rep.content</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="keyword">return</span> rep.text</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line"><span class="keyword">return</span> <span class="string">&#x27;产生非200响应异常，当前响应状态码为&#123;&#125;, 请及时修改代</span></span><br><span class="line"><span class="string">码&#x27;</span>.<span class="built_in">format</span>(rep.status_code)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">url =</span><br><span class="line"><span class="string">&#x27;https://www.12306.cn/index/script/core/common/station_name_new_v10024.js&#x27;</span></span><br><span class="line"><span class="comment"># # 测试</span></span><br><span class="line"><span class="comment"># print(getHTMLAndByte(url))</span></span><br><span class="line"><span class="comment"># 获取12306站点的JS文件数据</span></span><br><span class="line">jsdata = getHTMLAndByte(url)</span><br><span class="line"><span class="comment"># 处理字符串数据(字符串截取)，然后切片器进行选取数据</span></span><br><span class="line">sitedata = jsdata.split(<span class="string">&#x27;|&#x27;</span>)[<span class="number">1</span>::<span class="number">10</span>]</span><br><span class="line"><span class="comment"># 保存数据</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;trainsite.txt&#x27;</span>, mode=<span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> sitedata:</span><br><span class="line">f.write(data + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;文本写入完成！&#x27;</span>)</span><br></pre></td></tr></table></figure>



<ol start="2">
<li>采集好看视频的视频数据</li>
</ol>
<ul>
<li>网址：<a target="_blank" rel="noopener" href="https://haokan.baidu.com/">https://haokan.baidu.com/</a> </li>
<li>至少采集4个视频，通过代码下载到你的本地电脑中的指定文件夹 好看视频数据采集 中。</li>
</ul>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281008912.png" alt="image-20260128100825736"></p>
<p><strong>实现代码</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请求和响应的通用模块</span></span><br><span class="line"><span class="comment"># 参数：webUrl为需要请求的网址，whetherByte=False为是否为字节数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getHTMLAndByte</span>(<span class="params">webUrl, whetherByte=<span class="literal">False</span></span>):</span><br><span class="line">	<span class="keyword">try</span>:</span><br><span class="line">		<span class="comment"># 伪装请求的头部信息</span></span><br><span class="line">		head = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">		rep = requests.get(webUrl, headers=head)</span><br><span class="line">		<span class="comment"># 当请求响应回来的状态为200就是正常，会执行后续代码。如果非200就进入异常块(except)</span></span><br><span class="line">		rep.raise_for_status()</span><br><span class="line">		rep.encoding = rep.apparent_encoding</span><br><span class="line">		<span class="comment"># 当前whetherByte的值为True时，返回二进制字节数据</span></span><br><span class="line">		<span class="keyword">if</span> whetherByte:</span><br><span class="line">			<span class="keyword">return</span> rep.content</span><br><span class="line">		<span class="keyword">else</span>:</span><br><span class="line">			<span class="keyword">return</span> rep.text</span><br><span class="line">	<span class="keyword">except</span>:</span><br><span class="line">		<span class="keyword">return</span> <span class="string">&#x27;产生非200响应异常，当前响应状态码为&#123;&#125;, 请及时修改代码&#x27;</span>.<span class="built_in">format</span>(rep.status_code)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">	videoUrls = [<span class="string">&#x27;https://highlight-video.cdn.bcebos.com/video/6s/4a4ba5e4-9e01-11ee-a624-b4055dd173d7.mp4&#x27;</span>,</span><br><span class="line">				<span class="string">&#x27;https://highlight-video.cdn.bcebos.com/video/6s/a07afd0c9aa0-11ee-aa73-6c92bf4060b7.mp4&#x27;</span>,</span><br><span class="line">             	<span class="string">&#x27;https://highlight-video.cdn.bcebos.com/video/6s/5f6e2c8e94ac-11ee-9047-6c92bfb3fd7e.mp4&#x27;</span>]</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">	<span class="comment"># 编写循环处理多个视频链接地址</span></span><br><span class="line">	<span class="keyword">for</span> url <span class="keyword">in</span> videoUrls:</span><br><span class="line">		<span class="comment"># 获取视频的字节流数据</span></span><br><span class="line">		videoByte = getHTMLAndByte(url, whetherByte=<span class="literal">True</span>)</span><br><span class="line">		<span class="comment"># 处理视频的名字, [&#x27;https:&#x27;, &#x27;&#x27;, &#x27;highlight-video.cdn.bcebos.com&#x27;,&#x27;video&#x27;, &#x27;6s&#x27;, &#x27;4a4ba5e4-9e01-11ee-a624-b4055dd173d7.mp4&#x27;]</span></span><br><span class="line">		videoName = url.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>]</span><br><span class="line">		<span class="comment"># 写入视频数据</span></span><br><span class="line">		<span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;好看视频采集数据/&#x27;</span> + videoName, mode=<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">			f.write(videoByte)</span><br><span class="line">	<span class="built_in">print</span>(<span class="string">&#x27;视频采集完成！&#x27;</span>)</span><br></pre></td></tr></table></figure>



<p><strong>扩展知识</strong>：selenium和ChromeDriver </p>
<p>ChromeDriver淘宝镜像：<a target="_blank" rel="noopener" href="https://registry.npmmirror.com/binary.html?path=chromed">https://registry.npmmirror.com/binary.html?path=chromed</a> river&#x2F;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.keys <span class="keyword">import</span> Keys</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.implicitly_wait(<span class="number">10</span>)</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">	browser.get(<span class="string">&quot;https://www.vip.com&quot;</span>)</span><br><span class="line">	<span class="built_in">input</span> = browser.find_element(By.CSS_SELECTOR, <span class="string">&#x27;.c-search-input&#x27;</span>)</span><br><span class="line">	<span class="built_in">input</span>.send_keys(<span class="string">&#x27;口红&#x27;</span>)</span><br><span class="line">	time.sleep(<span class="number">3</span>)</span><br><span class="line">	<span class="built_in">input</span>.send_keys(Keys.ENTER)</span><br><span class="line">	names = browser.find_elements(By.CLASS_NAME, <span class="string">&#x27;c-goods-item__name&#x27;</span>)</span><br><span class="line">	<span class="keyword">for</span> name <span class="keyword">in</span> names:</span><br><span class="line">		<span class="built_in">print</span>(name.text)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">	browser.close()</span><br></pre></td></tr></table></figure>



<h4 id="3-3-网址采集时的参数传递"><a href="#3-3-网址采集时的参数传递" class="headerlink" title="3.3 网址采集时的参数传递"></a>3.3 网址采集时的参数传递</h4><p>对于GET请求，如果我们要附加额外信息，就是要添加参数。比如：下列网址进行参数对比。 </p>
<p>百度搜索： <a target="_blank" rel="noopener" href="https://www.baidu.com/s?wd=javascript">https://www.baidu.com/s?wd=javascript</a> </p>
<p>搜狗搜索：<a target="_blank" rel="noopener" href="https://www.sogou.com/web?query=javascript">https://www.sogou.com/web?query=javascript</a> </p>
<p>什么是参数呢？ </p>
<p>在 ？ 后面就是需要添加的额外参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># 需要请求网址</span></span><br><span class="line">webUrl = <span class="string">&#x27;https://www.baidu.com/s&#x27;</span></span><br><span class="line"><span class="comment"># 请求网址是添加参数</span></span><br><span class="line">webParams = &#123;</span><br><span class="line">	<span class="string">&#x27;wd&#x27;</span>: <span class="string">&#x27;javascript&#x27;</span>,</span><br><span class="line">	<span class="string">&#x27;tn&#x27;</span>: <span class="string">&#x27;baiduhome_pg&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 伪装请求的头部信息</span></span><br><span class="line">head = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">rep = requests.get(webUrl, headers=head, params=webParams)</span><br><span class="line"><span class="built_in">print</span>(rep.request.url)</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://www.baidu.com/s?wd=javascript&tn=baiduhome_pg">https://www.baidu.com/s?wd=javascript&amp;tn=baiduhome_pg</a></p>
<p><strong>对比分析：</strong></p>
<p>单程</p>
<p><a target="_blank" rel="noopener" href="https://kyfw.12306.cn/otn/leftTicket/init?linktypeid=dc">https://kyfw.12306.cn/otn/leftTicket/init?linktypeid=dc</a></p>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281008988.png" alt="image-20260128100835908"></p>
<p>往返</p>
<p><a target="_blank" rel="noopener" href="https://kyfw.12306.cn/otn/leftTicket/init?linktypeid=wf">https://kyfw.12306.cn/otn/leftTicket/init?linktypeid=wf</a></p>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281008604.png" alt="image-20260128100842526"></p>
<h4 id="3-4-如何实现模拟登录"><a href="#3-4-如何实现模拟登录" class="headerlink" title="3.4 如何实现模拟登录"></a>3.4 如何实现模拟登录</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># 需要请求网址</span></span><br><span class="line">webUrl = <span class="string">&#x27;https://home.jd.com/&#x27;</span></span><br><span class="line"><span class="comment"># 伪装请求的头部信息</span></span><br><span class="line">head = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64)</span></span><br><span class="line"><span class="string">AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">rep = requests.get(webUrl, headers=head)</span><br><span class="line"><span class="built_in">print</span>(rep.text)</span><br></pre></td></tr></table></figure>

<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">title</span>&gt;</span>京东-欢迎登录<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br></pre></td></tr></table></figure>



<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281008079.png" alt="image-20260128100847991"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># 需要请求网址</span></span><br><span class="line">webUrl = <span class="string">&#x27;https://home.jd.com/&#x27;</span></span><br><span class="line"><span class="comment"># 伪装请求的头部信息</span></span><br><span class="line"><span class="comment"># 需要模拟登录简单粗暴的使用cookies</span></span><br><span class="line">head = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36&#x27;</span>,</span><br><span class="line">		<span class="string">&#x27;Cookie&#x27;</span>: <span class="string">&#x27;__jdu=16956384678711835153554; shshshfpa=726bacda-6837-98e5-4a73-60705bb4d99d-1695638474; shshshfpx=726bacda-6837-98e5-4a73-60705bb4d99d-1695638474; pinId=YsezASvotgm1ffsfn98I-w; ipLoc-djd=4-48207-48261-0; pin=dengq720; unick=FreeMan_Deng;_tp=ip8c6qT99GWkZGU2mU%2Falg%3D%3D; _pst=dengq720; __jdv=76161171|direct|-|none|-|1702947611805; PCSYCityID=CN_500000_500100_0; ceshi3.com=103; ...&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">rep = requests.get(webUrl, headers=head)</span><br><span class="line"><span class="built_in">print</span>(rep.text)</span><br></pre></td></tr></table></figure>

<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">title</span>&gt;</span>我的京东</span><br></pre></td></tr></table></figure>



<h3 id="四、网页解析框架"><a href="#四、网页解析框架" class="headerlink" title="四、网页解析框架"></a>四、网页解析框架</h3><h4 id="4-1-lxml和Beautiful-Soup"><a href="#4-1-lxml和Beautiful-Soup" class="headerlink" title="4.1 lxml和Beautiful Soup"></a>4.1 lxml和Beautiful Soup</h4><p>lxml 是 Python 的一个解析库 ， 支持 HTML 和 XML 的解析，支持 XPath 解析方式，而且 解析效率非常高 。先安装lxml。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install lxml</span><br></pre></td></tr></table></figure>

<p>Beautiful Soup 是 Python 的一个 HTML 或 XML 的解析库，我们可以用它来方便地从网页中 提 取数据 。 它拥有强大的 API 和多样的解析方式，接下来了解一下它的安装方式。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install beautifulsoup4</span><br></pre></td></tr></table></figure>

<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281008029.png" alt="image-20260128100854940"></p>
<h4 id="4-2-Beautiful-Soup支持的解释器介绍"><a href="#4-2-Beautiful-Soup支持的解释器介绍" class="headerlink" title="4.2 Beautiful Soup支持的解释器介绍"></a>4.2 Beautiful Soup支持的解释器介绍</h4><p>Beautiful Soup 在解析时实际上依赖解析器，它除了支持 Python 标准库中的 HTML 解析器外， 还支持一些第三方解析器（比如 lxml ）。下列出是 Beautiful Soup 支持的解析器。</p>
<table>
<thead>
<tr>
<th>解析器</th>
<th>使用方法</th>
<th>优势</th>
<th>劣势</th>
</tr>
</thead>
<tbody><tr>
<td>Python 标准库</td>
<td>BeautifulSoup(markup,” html. parser”)</td>
<td>Python 的内置标准 库、执行速度适中、 文档容错能力强</td>
<td>Python 2.7.3 及 Python3 . 2 .2 之前的版本文档容错 能力差</td>
</tr>
<tr>
<td>lxml HTML 解 析器</td>
<td>BeautifulSoup(markup,” lxml”)</td>
<td>速度快 、文档容错 能力强</td>
<td>需要安装C语言库</td>
</tr>
<tr>
<td>lxml XML 解析器</td>
<td>BeautifulSoup(markup, “xml”)</td>
<td>速度快、唯一支持 XML 的解析器</td>
<td>需要安装C语言库</td>
</tr>
<tr>
<td>html5lib</td>
<td>BeautifulSoup(markup,” html5lib”)</td>
<td>最好的容错性、以浏 览器的方式解析文 档、生成 HTML5 格 式的文档</td>
<td>速度慢、不依赖外部 扩展</td>
</tr>
</tbody></table>
<p>通过以上对比可以看出， lxml 解析器有解析 HTML 和 XML 的功能，而且速度’快，容错能力强， 所以推荐使用它。 如果使用 lxml ，那么在初始化 Beautiful Soup 时，可以把第二个参数改为 lxml 即可:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 导入操作</span></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 解析网页数据(理解为：我们通过requests请求回来的具体HTML页面)</span></span><br><span class="line"><span class="comment"># BeautifulSoup(&#x27;&lt;h1&gt;BeautifulSoup&lt;/h1&gt;&#x27;, &#x27;lxml&#x27;)</span></span><br><span class="line"><span class="comment"># 参数1：需要解析的具体网页</span></span><br><span class="line"><span class="comment"># 参数2：你要使用那个解析器(解析器的名字)</span></span><br><span class="line">soup = BeautifulSoup(<span class="string">&#x27;&lt;h1&gt;BeautifulSoup&lt;/h1&gt;&#x27;</span>, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.提取数据</span></span><br><span class="line"><span class="built_in">print</span>(soup.h1.string)</span><br></pre></td></tr></table></figure>

<p>在后面， Beautiful Soup 的用法实例也统一用这个解析器来演示。</p>
<h4 id="4-3-基本运用"><a href="#4-3-基本运用" class="headerlink" title="4.3 基本运用"></a>4.3 基本运用</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">html = <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&lt;html&gt;&lt;head&gt;&lt;title&gt;文献网&lt;/title&gt;&lt;/head&gt;</span></span><br><span class="line"><span class="string">&lt;body&gt;</span></span><br><span class="line"><span class="string">&lt;p class=&quot;title&quot; name=&quot;dromouse&quot;&gt;&lt;b&gt;睡鼠的故事&lt;/b&gt;&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p class=&quot;story&quot;&gt;</span></span><br><span class="line"><span class="string">,</span></span><br><span class="line"><span class="string">和</span></span><br><span class="line"><span class="string">;</span></span><br><span class="line"><span class="string">他们住在井底。&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p class=&quot;story&quot;&gt;其他内容隐藏...&lt;/p&gt;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">soup = BeautifulSoup(html, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(soup.prettify())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;以下是提取网页标题的内容&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup.title.string)</span><br></pre></td></tr></table></figure>



<p><strong>BeautifulSoup的基本元素</strong></p>
<table>
<thead>
<tr>
<th>基本元素</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>Tag</td>
<td>标签，最基本的信息组织单元，分别用&lt;&gt;和标明开头和结尾</td>
</tr>
<tr>
<td>Name</td>
<td>标签的名字，&lt;p ………&lt;&#x2F;p&gt;的名字是‘p’   格式： .name</td>
</tr>
<tr>
<td>Attributes</td>
<td>标签的属性，字典形式组织，格式：，.attrs</td>
</tr>
<tr>
<td>NavigableString</td>
<td>标签内非属性字符串，&lt;&gt;……中字符串，格式：.string</td>
</tr>
<tr>
<td>Comment</td>
<td>标签内字符串的注释部分，一种特殊的Comment类型</td>
</tr>
</tbody></table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">html = <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&lt;html&gt;&lt;head&gt;&lt;title&gt;文献网&lt;/title&gt;&lt;/head&gt;</span></span><br><span class="line"><span class="string">&lt;body&gt;</span></span><br><span class="line"><span class="string">&lt;p class=&quot;title&quot; name=&quot;dromouse&quot;&gt;&lt;b&gt;睡鼠的故事&lt;/b&gt;&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p class=&quot;story&quot;&gt;</span></span><br><span class="line"><span class="string">,</span></span><br><span class="line"><span class="string">和</span></span><br><span class="line"><span class="string">;</span></span><br><span class="line"><span class="string">他们住在井底。&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p class=&quot;story&quot;&gt;其他内容隐藏...&lt;/p&gt;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">soup = BeautifulSoup(html, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 选择元素</span></span><br><span class="line"><span class="comment"># soup.title 查找title这个标签</span></span><br><span class="line"><span class="built_in">print</span>(soup.title)</span><br><span class="line"><span class="comment"># 类型：bs4.element.Tag</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(soup.title))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(soup.p)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(soup.p))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 提取信息操作</span></span><br><span class="line"><span class="built_in">print</span>(soup.title.name)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 提取元素的属性</span></span><br><span class="line"><span class="built_in">print</span>(soup.p.attrs)</span><br><span class="line"><span class="built_in">print</span>(soup.p.attrs[<span class="string">&#x27;name&#x27;</span>])</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">html = <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&lt;html&gt;&lt;head&gt;&lt;title&gt;文献网&lt;/title&gt;&lt;/head&gt;</span></span><br><span class="line"><span class="string">&lt;body&gt;</span></span><br><span class="line"><span class="string">&lt;p class=&quot;title&quot; name=&quot;dromouse&quot;&gt;&lt;b&gt;睡鼠的故事&lt;/b&gt;&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p class=&quot;story&quot;&gt;</span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;linkl&quot;&gt;&lt;!-- Elsie --&gt;</span></span><br><span class="line"><span class="string">&lt;/a&gt;,</span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;蕾西&lt;/a&gt;和</span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;蒂莉&lt;/a&gt;;</span></span><br><span class="line"><span class="string">他们住在井底。&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p class=&quot;story&quot;&gt;其他内容隐藏...&lt;/p&gt;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">soup = BeautifulSoup(html, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(soup.a.attrs)</span><br><span class="line"><span class="built_in">print</span>(soup.a.attrs[<span class="string">&#x27;href&#x27;</span>])</span><br></pre></td></tr></table></figure>





<h4 id="4-4-采集数据的初体验"><a href="#4-4-采集数据的初体验" class="headerlink" title="4.4 采集数据的初体验"></a>4.4 采集数据的初体验</h4><p>数据采集的整体工作流程:飞卢小说网为例 </p>
<ol>
<li>明确采集的目标(就是我们要采集的网站) </li>
<li>分析采集目标的数据组成结构以及它的规则 </li>
<li>反爬机制的分析(测试，该目标有哪些反爬技术，我们需要使用哪些方法来进行处理) </li>
<li>编写采集代码 </li>
<li>(建议)：先测试小量数据(发现问题，解决问题) </li>
<li>进行大批量数据采集(文本内容保存或者多媒体数据保存)</li>
</ol>
<p><strong>体验采集小说网的分析过程</strong> </p>
<p>标新榜： <a target="_blank" rel="noopener" href="https://b.faloo.com/Rank_1.html">https://b.faloo.com/Rank_1.html</a> </p>
<p>总榜：<a target="_blank" rel="noopener" href="https://b.faloo.com/Rank_2.html">https://b.faloo.com/Rank_2.html</a> </p>
<p>分类榜：<a target="_blank" rel="noopener" href="https://b.faloo.com/Rank_3.html">https://b.faloo.com/Rank_3.html</a> </p>
<p>女生榜：<a target="_blank" rel="noopener" href="https://b.faloo.com/Rank_4.html">https://b.faloo.com/Rank_4.html</a></p>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281009935.png" alt="image-20260128100905787"></p>
<p><img data-src="E:/typora%E5%9B%BE%E7%89%87/image-20240102103356381.png" alt="image-20240102103356381"></p>
<p>整个图片的CSS样式选择： #Tab1 .c_de_rk_content .c_de_rk_c_data .c_de_rk_c_d_img a img</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请求和响应的通用模块</span></span><br><span class="line"><span class="comment"># 参数：webUrl为需要请求的网址，whetherByte=False为是否为字节数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getHTMLAndByte</span>(<span class="params">webUrl, whetherByte=<span class="literal">False</span></span>):</span><br><span class="line">	<span class="keyword">try</span>:</span><br><span class="line">		<span class="comment"># 伪装请求的头部信息</span></span><br><span class="line">		head = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">		rep = requests.get(webUrl, headers=head)</span><br><span class="line">		<span class="comment"># 当请求响应回来的状态为200就是正常，会执行后续代码。如果非200就进入异常块(except)</span></span><br><span class="line">		rep.raise_for_status()</span><br><span class="line">		rep.encoding = rep.apparent_encoding</span><br><span class="line">		<span class="comment"># 当前whetherByte的值为True时，返回二进制字节数据</span></span><br><span class="line">		<span class="keyword">if</span> whetherByte:</span><br><span class="line">			<span class="keyword">return</span> rep.content</span><br><span class="line">		<span class="keyword">else</span>:</span><br><span class="line">			<span class="keyword">return</span> rep.text</span><br><span class="line">	<span class="keyword">except</span>:</span><br><span class="line">		<span class="keyword">return</span> <span class="string">&#x27;产生非200响应异常，当前响应状态码为&#123;&#125;, 请及时修改代码&#x27;</span>.<span class="built_in">format</span>(rep.status_code)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 请求网址</span></span><br><span class="line">bookUrl = <span class="string">&#x27;https://b.faloo.com/Rank_1.html&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 引用解析库</span></span><br><span class="line">soup = BeautifulSoup(getHTMLAndByte(bookUrl), <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="comment"># # 测试</span></span><br><span class="line"><span class="comment"># print(soup.prettify())</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># # 测试是否找到了，我们想要的img标签数据，如果是多个，返回列表(数组)</span></span><br><span class="line"><span class="comment"># print(soup.select(&#x27;#Tab1 .c_de_rk_content .c_de_rk_c_data .c_de_rk_c_d_imga img&#x27;))</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> tag <span class="keyword">in</span> soup.select(<span class="string">&#x27;#Tab1 .c_de_rk_content .c_de_rk_c_data.c_de_rk_c_d_img a img&#x27;</span>):</span><br><span class="line">	<span class="comment"># 每张图片的链接地址</span></span><br><span class="line">	imgUrl = tag.attrs[<span class="string">&#x27;src&#x27;</span>]</span><br><span class="line">	<span class="comment"># 定义变量获取图片名字</span></span><br><span class="line">	imgName = imgUrl.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>]</span><br><span class="line">	<span class="comment"># print(imgName)</span></span><br><span class="line">    </span><br><span class="line">	<span class="comment"># 获取下载图片的字节流</span></span><br><span class="line">	imgByte = getHTMLAndByte(imgUrl, whetherByte=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">	<span class="comment"># 写入图片IO操作</span></span><br><span class="line">	<span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;D:/飞卢小说图片/&#x27;</span> + imgName, mode=<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">		f.write(imgByte)</span><br></pre></td></tr></table></figure>



<p><strong>采集训练：</strong></p>
<p>任务：将女生榜中图片数据进行采集到本地 </p>
<p>思考：我如何能将 标新榜、总榜、分类榜、女生榜 里面的图片一次性全部下载。对应的网址它的规则如何 处理，需要用到哪些Python基础知识。</p>
<p><strong>扩展：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过分析我们可以使用循环来生成有规则的请求地址</span></span><br><span class="line"></span><br><span class="line">xsUrl = <span class="string">&#x27;https://b.faloo.com/Rank_&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">5</span>):</span><br><span class="line">	url = xsUrl + <span class="built_in">str</span>(i) + <span class="string">&#x27;.html&#x27;</span></span><br><span class="line">	<span class="built_in">print</span>(url)</span><br></pre></td></tr></table></figure>



<h4 id="4-5-Selector应用"><a href="#4-5-Selector应用" class="headerlink" title="4.5 Selector应用"></a>4.5 Selector应用</h4><p>什么是Selector?它是当前元素定义的CSS样式，它的返回值可能是id选择器、class选择器、标签 (元素)选择器。我们在大一时，学习CSS层叠样式表的原理和方式，所有我们对Selector的操作应该 比较容易上手。</p>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281009191.png" alt="image-20260128100917108"></p>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281009446.png" alt="image-20260128100925345"></p>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281009107.png" alt="image-20260128100933005"></p>
<h4 id="4-6-Beautiful-Soup关联元素选择"><a href="#4-6-Beautiful-Soup关联元素选择" class="headerlink" title="4.6 Beautiful Soup关联元素选择"></a>4.6 Beautiful Soup关联元素选择</h4><p>我们在做选择的时候，有时候不能做到一步就选到炫耀的节点元素，需要先选取某一个节点元素，然后 以它为基准在选择它的子节点、父节点、兄弟节点等。</p>
<h5 id="4-6-1-子节点与子孙节点"><a href="#4-6-1-子节点与子孙节点" class="headerlink" title="4.6.1 子节点与子孙节点"></a>4.6.1 子节点与子孙节点</h5><table>
<thead>
<tr>
<th>属性</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>.contents</td>
<td>子节点的列表，将  所有子节点存入列表</td>
</tr>
<tr>
<td>.children</td>
<td>子节点的迭代类型，用于循环遍历子节点</td>
</tr>
<tr>
<td>.descendants</td>
<td>子孙节点的迭代类型，包含所有子孙节点，用于循环遍历子孙节点</td>
</tr>
</tbody></table>
<p><strong>.contents属性，示例：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请求和响应的通用模块</span></span><br><span class="line"><span class="comment"># 参数：webUrl为需要请求的网址，whetherByte=False为是否为字节数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getHTMLAndByte</span>(<span class="params">webUrl, whetherByte=<span class="literal">False</span></span>):</span><br><span class="line">	<span class="keyword">try</span>:</span><br><span class="line">		<span class="comment"># 伪装请求的头部信息</span></span><br><span class="line">		head = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">		rep = requests.get(webUrl, headers=head)</span><br><span class="line">		<span class="comment"># 当请求响应回来的状态为200就是正常，会执行后续代码。如果非200就进入异常块(except)</span></span><br><span class="line">		rep.raise_for_status()</span><br><span class="line">		rep.encoding = rep.apparent_encoding</span><br><span class="line">		<span class="comment"># 当前whetherByte的值为True时，返回二进制字节数据</span></span><br><span class="line">		<span class="keyword">if</span> whetherByte:</span><br><span class="line">			<span class="keyword">return</span> rep.content</span><br><span class="line">		<span class="keyword">else</span>:</span><br><span class="line">			<span class="keyword">return</span> rep.text</span><br><span class="line">	<span class="keyword">except</span>:</span><br><span class="line">		<span class="keyword">return</span> <span class="string">&#x27;产生非200响应异常，当前响应状态码为&#123;&#125;, 请及时修改代码&#x27;</span>.<span class="built_in">format</span>(rep.status_code)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 靶向网站 http://python123.io/ws/demo.html</span></span><br><span class="line"><span class="comment"># 创建bs4</span></span><br><span class="line">webUrl = <span class="string">&#x27;http://python123.io/ws/demo.html&#x27;</span></span><br><span class="line">soup = BeautifulSoup(getHTMLAndByte(webUrl), <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="comment"># body中有那些子节点</span></span><br><span class="line"><span class="comment"># print(soup.body.contents)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># p标签中有那些子节点</span></span><br><span class="line"><span class="built_in">print</span>(soup.p.contents)</span><br></pre></td></tr></table></figure>

<p><strong>子节点与子孙节点基本应用</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请求和响应的通用模块</span></span><br><span class="line"><span class="comment"># 参数：webUrl为需要请求的网址，whetherByte=False为是否为字节数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getHTMLAndByte</span>(<span class="params">webUrl, whetherByte=<span class="literal">False</span></span>):</span><br><span class="line">	<span class="keyword">try</span>:</span><br><span class="line">		<span class="comment"># 伪装请求的头部信息</span></span><br><span class="line">		head = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">		rep = requests.get(webUrl, headers=head)</span><br><span class="line">		<span class="comment"># 当请求响应回来的状态为200就是正常，会执行后续代码。如果非200就进入异常块(except)</span></span><br><span class="line">		rep.raise_for_status()</span><br><span class="line">		rep.encoding = rep.apparent_encoding</span><br><span class="line">		<span class="comment"># 当前whetherByte的值为True时，返回二进制字节数据</span></span><br><span class="line">		<span class="keyword">if</span> whetherByte:</span><br><span class="line">			<span class="keyword">return</span> rep.content</span><br><span class="line">		<span class="keyword">else</span>:</span><br><span class="line">			<span class="keyword">return</span> rep.text</span><br><span class="line">	<span class="keyword">except</span>:</span><br><span class="line">		<span class="keyword">return</span> <span class="string">&#x27;产生非200响应异常，当前响应状态码为&#123;&#125;, 请及时修改代码&#x27;</span>.<span class="built_in">format</span>(rep.status_code)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="comment"># 靶向网站 http://python123.io/ws/demo.html 创建bs4</span></span><br><span class="line">webUrl = <span class="string">&#x27;http://python123.io/ws/demo.html&#x27;</span></span><br><span class="line">soup = BeautifulSoup(getHTMLAndByte(webUrl), <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="comment"># body中有那些子节点</span></span><br><span class="line"><span class="comment"># print(soup.body.contents)</span></span><br><span class="line"><span class="comment"># p标签中有那些子节点</span></span><br><span class="line"><span class="comment"># print(soup.p.contents)</span></span><br><span class="line"><span class="comment"># children 迭代类型，遍历所有的子节点</span></span><br><span class="line"><span class="comment"># print(soup.p.children) # 得到的是一个迭代对象</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取第一个p标签中所有的子节点，通过循环将其迭代</span></span><br><span class="line"><span class="keyword">for</span> child <span class="keyword">in</span> soup.p.contents:</span><br><span class="line">	<span class="built_in">print</span>(child)</span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;-&#x27;</span> * <span class="number">50</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取第一个p标签中所以的子孙节点，通过循环将其迭代</span></span><br><span class="line"><span class="keyword">for</span> child <span class="keyword">in</span> soup.p.descendants:</span><br><span class="line">	<span class="built_in">print</span>(child)</span><br></pre></td></tr></table></figure>



<h5 id="4-6-2-父节点和先辈-祖先-节点"><a href="#4-6-2-父节点和先辈-祖先-节点" class="headerlink" title="4.6.2 父节点和先辈(祖先)节点"></a>4.6.2 父节点和先辈(祖先)节点</h5><table>
<thead>
<tr>
<th>属性</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>.parent</td>
<td>节点的父标签</td>
</tr>
<tr>
<td>.parents</td>
<td>节点先辈标签的迭代类型，用于循环遍历先辈节点</td>
</tr>
</tbody></table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">webUrl = <span class="string">&#x27;https://python123.io/ws/demo.html&#x27;</span></span><br><span class="line">rep = requests.get(webUrl)</span><br><span class="line">soup = BeautifulSoup(rep.text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># soup.title.parent.name 的意思为：通过BeautifulSoup对象查询标签为title的父节点标签并获取其名字</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(soup.title.parent.name)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;-&#x27;</span> * <span class="number">50</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> parent <span class="keyword">in</span> soup.title.parents:</span><br><span class="line">	<span class="built_in">print</span>(parent.name)</span><br></pre></td></tr></table></figure>

<p><strong>4.6.3 兄弟(同辈)节点</strong></p>
<table>
<thead>
<tr>
<th>属性</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>.next_sibling</td>
<td>返回按照 HTML 文本顺序的下一个平行节点标签</td>
</tr>
<tr>
<td>.previous_sibling</td>
<td>返回按照 HTML 文本顺序的上一个平行节点标签</td>
</tr>
<tr>
<td>.next_siblings</td>
<td>迭代类型，返回按照 HTML 文本顺序的后续所有平行节点标签</td>
</tr>
<tr>
<td>.previous_siblings</td>
<td>迭代类型，返回按照 HTML 文本顺序的前续所有平行节点标签</td>
</tr>
</tbody></table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">webUrl = <span class="string">&#x27;https://python123.io/ws/demo.html&#x27;</span></span><br><span class="line">rep = requests.get(webUrl)</span><br><span class="line">soup = BeautifulSoup(rep.text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下一个同辈元素 (and) 字符串</span></span><br><span class="line"><span class="built_in">print</span>(soup.a.next_sibling)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果我想去获取到另外一个a标签怎么写？</span></span><br><span class="line"><span class="built_in">print</span>(soup.a.next_sibling.next_sibling)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果我想去获取a标签前面一个字符串数据</span></span><br><span class="line"><span class="built_in">print</span>(soup.a.previous_sibling)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果我想去获取a标签后面所有的兄弟节点</span></span><br><span class="line"><span class="keyword">for</span> sibling <span class="keyword">in</span> soup.a.next_siblings:</span><br><span class="line">	<span class="built_in">print</span>(sibling)</span><br></pre></td></tr></table></figure>







<h3 id="五、阶段性实战项目"><a href="#五、阶段性实战项目" class="headerlink" title="五、阶段性实战项目"></a>五、阶段性实战项目</h3><h4 id="5-1-获取链家的城市数据"><a href="#5-1-获取链家的城市数据" class="headerlink" title="5.1 获取链家的城市数据"></a>5.1 获取链家的城市数据</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请求和响应的通用模块</span></span><br><span class="line"><span class="comment"># 参数：webUrl为需要请求的网址，whetherByte=False为是否为字节数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getHTMLAndByte</span>(<span class="params">webUrl, whetherByte=<span class="literal">False</span></span>):</span><br><span class="line">	<span class="keyword">try</span>:</span><br><span class="line">		<span class="comment"># 伪装请求的头部信息</span></span><br><span class="line">		head = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">		rep = requests.get(webUrl, headers=head)</span><br><span class="line">    	<span class="comment"># 当请求响应回来的状态为200就是正常，会执行后续代码。如果非200就进入异常块(except)</span></span><br><span class="line">		rep.raise_for_status()</span><br><span class="line">		rep.encoding = rep.apparent_encoding</span><br><span class="line">		<span class="comment"># 当前whetherByte的值为True时，返回二进制字节数据</span></span><br><span class="line">		<span class="keyword">if</span> whetherByte:</span><br><span class="line">			<span class="keyword">return</span> rep.content</span><br><span class="line">		<span class="keyword">else</span>:</span><br><span class="line">			<span class="keyword">return</span> rep.text</span><br><span class="line">	<span class="keyword">except</span>:</span><br><span class="line">		<span class="keyword">return</span> <span class="string">&#x27;产生非200响应异常，当前响应状态码为&#123;&#125;, 请及时修改代码&#x27;</span>.<span class="built_in">format</span>(rep.status_code)</span><br><span class="line">    </span><br><span class="line">cityUrl = <span class="string">&#x27;https://www.lianjia.com/city/&#x27;</span></span><br><span class="line"><span class="comment"># getHTMLAndByte(cityUrl) 核心点，请求并响应回来的相关HTML网页的字符串数据</span></span><br><span class="line">soup = BeautifulSoup(getHTMLAndByte(cityUrl), <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="comment"># 定义存放数据的列表</span></span><br><span class="line">cityNames = []</span><br><span class="line">cityUrls = []</span><br><span class="line"><span class="keyword">for</span> tag <span class="keyword">in</span> soup.select(<span class="string">&#x27;.city_list_ul a&#x27;</span>):</span><br><span class="line">	<span class="comment"># 获取a的城市名字</span></span><br><span class="line">	cityNames.append(tag.string)</span><br><span class="line">	<span class="comment"># 获取a的超链接地址</span></span><br><span class="line">	cityUrls.append(tag.attrs[<span class="string">&#x27;href&#x27;</span>])</span><br><span class="line">    </span><br><span class="line">data = <span class="built_in">zip</span>(cityNames, cityUrls)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;D:/城市数据.txt&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">	<span class="keyword">for</span> s <span class="keyword">in</span> data:</span><br><span class="line">		<span class="keyword">pass</span></span><br></pre></td></tr></table></figure>



<h4 id="5-2-采集链家房产数据"><a href="#5-2-采集链家房产数据" class="headerlink" title="5.2 采集链家房产数据"></a>5.2 采集链家房产数据</h4><h5 id="5-2-1-请求通用模块"><a href="#5-2-1-请求通用模块" class="headerlink" title="5.2.1 请求通用模块"></a>5.2.1 请求通用模块</h5><p><strong>ReqHtmlOrByte.py</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请求和响应的通用模块</span></span><br><span class="line"><span class="comment"># 参数：webUrl为需要请求的网址，whetherByte=False为是否为字节数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getHTMLAndByte</span>(<span class="params">webUrl, whetherByte=<span class="literal">False</span></span>):</span><br><span class="line">	<span class="keyword">try</span>:</span><br><span class="line">		<span class="comment"># 伪装请求的头部信息</span></span><br><span class="line">		head = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">		rep = requests.get(webUrl, headers=head)</span><br><span class="line">		<span class="comment"># 当请求响应回来的状态为200就是正常，会执行后续代码。如果非200就进入异常块(except)</span></span><br><span class="line">		rep.raise_for_status()</span><br><span class="line">		rep.encoding = rep.apparent_encoding</span><br><span class="line">		<span class="comment"># 当前whetherByte的值为True时，返回二进制字节数据</span></span><br><span class="line">		<span class="keyword">if</span> whetherByte:</span><br><span class="line">			<span class="keyword">return</span> rep.content</span><br><span class="line">		<span class="keyword">else</span>:</span><br><span class="line">			<span class="keyword">return</span> rep.text</span><br><span class="line">	<span class="keyword">except</span>:</span><br><span class="line">		<span class="keyword">return</span> <span class="string">&#x27;产生非200响应异常，当前响应状态码为&#123;&#125;, 请及时修改代码&#x27;</span>.<span class="built_in">format</span>(rep.status_code)</span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># # 引用模块方法一</span></span><br><span class="line"><span class="comment"># import ReqHtmlOrByte</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 引用模块方法二</span></span><br><span class="line"><span class="keyword">from</span> ReqHtmlOrByte <span class="keyword">import</span> getHTMLAndByte</span><br><span class="line"></span><br><span class="line">webUrl = <span class="string">&#x27;https://cq.lianjia.com/ershoufang/&#x27;</span></span><br><span class="line"><span class="comment"># # 用模块.函数进行使用</span></span><br><span class="line"><span class="comment"># data = ReqHtmlOrByte.getHTMLAndByte(webUrl)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 直接调用函数</span></span><br><span class="line">data = getHTMLAndByte(webUrl)</span><br><span class="line"><span class="built_in">print</span>(data)</span><br></pre></td></tr></table></figure>



<h5 id="5-2-2-关于JSON"><a href="#5-2-2-关于JSON" class="headerlink" title="5.2.2 关于JSON"></a>5.2.2 关于JSON</h5><ul>
<li>JSON: JavaScript Object Notation(JavaScript 对象表示法) </li>
<li>JSON 是 存储和交换文本信息 的语法，类似 XML。 </li>
<li>JSON 比 XML 更小、更快，更易解析。 </li>
<li>JSON 易于人阅读和编写。 </li>
<li>C、Python、C++、Java、PHP、Go等编程语言都支持 JSON。 JSON 是轻量级的文本数据交换格式。</li>
</ul>
<p>JSON学习网址：<a target="_blank" rel="noopener" href="https://www.runoob.com/json/json-tutorial.html">https://www.runoob.com/json/json-tutorial.html</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入json库</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">jsondata = <span class="string">&#x27;&#x27;&#x27;&#123;</span></span><br><span class="line"><span class="string">	&quot;sites&quot;: [</span></span><br><span class="line"><span class="string">	&#123; &quot;name&quot;:&quot;蓝桥&quot; , &quot;url&quot;:&quot;www.lanqiao.cm&quot; &#125;,</span></span><br><span class="line"><span class="string">    &#123; &quot;name&quot;:&quot;百度&quot; , &quot;url&quot;:&quot;www.baidu.com&quot; &#125;,</span></span><br><span class="line"><span class="string">    &#123; &quot;name&quot;:&quot;京东&quot; , &quot;url&quot;:&quot;www.jd.com&quot; &#125;</span></span><br><span class="line"><span class="string">	]</span></span><br><span class="line"><span class="string">&#125;&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将json格式转换为字典</span></span><br><span class="line">mydict = json.loads(jsondata)</span><br><span class="line"><span class="comment"># print(type(mydict))</span></span><br><span class="line"><span class="built_in">print</span>(mydict[<span class="string">&#x27;sites&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> d <span class="keyword">in</span> mydict[<span class="string">&#x27;sites&#x27;</span>]:</span><br><span class="line">    <span class="built_in">print</span>(d[<span class="string">&#x27;name&#x27;</span>], d[<span class="string">&#x27;url&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 字典转json格式</span></span><br><span class="line">dictData = &#123;</span><br><span class="line">	<span class="string">&quot;student&quot;</span>: [</span><br><span class="line">		&#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;张三&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">20</span>, <span class="string">&#x27;sex&#x27;</span>: <span class="literal">True</span>&#125;,</span><br><span class="line">		&#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;李四&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">21</span>, <span class="string">&#x27;sex&#x27;</span>: <span class="literal">False</span>&#125;,</span><br><span class="line">		&#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;王五&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">18</span>, <span class="string">&#x27;sex&#x27;</span>: <span class="literal">True</span>&#125;</span><br><span class="line">	]</span><br><span class="line">&#125;</span><br><span class="line">data = json.dumps(dictData)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(data))</span><br><span class="line"><span class="built_in">print</span>(data)</span><br></pre></td></tr></table></figure>



<h5 id="5-2-3-获取链家二手房所有的网址"><a href="#5-2-3-获取链家二手房所有的网址" class="headerlink" title="5.2.3 获取链家二手房所有的网址"></a>5.2.3 获取链家二手房所有的网址</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> ReqHtmlOrByte <span class="keyword">import</span> getHTMLAndByte</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">webUrl = <span class="string">&#x27;https://cq.lianjia.com/ershoufang/&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取最大页数</span></span><br><span class="line">soup = BeautifulSoup(getHTMLAndByte(webUrl), <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="comment"># print(soup.select(&#x27;.house-lst-page-box&#x27;)[0].attrs[&#x27;page-data&#x27;])</span></span><br><span class="line"><span class="comment"># print(json.loads(soup.select(&#x27;.house-lst-page-box&#x27;)[0].attrs[&#x27;page-data&#x27;])[&#x27;totalPage&#x27;])</span></span><br><span class="line"><span class="comment"># print(type(soup.select(&#x27;.house-lst-page-box&#x27;)[0].attrs[&#x27;page-data&#x27;]))</span></span><br><span class="line"><span class="comment"># print(type(json.loads(soup.select(&#x27;.house-lst-page-box&#x27;)[0].attrs[&#x27;page-data&#x27;])))</span></span><br><span class="line"></span><br><span class="line">pc = json.loads(soup.select(<span class="string">&#x27;.house-lst-page-box&#x27;</span>)[<span class="number">0</span>].attrs[<span class="string">&#x27;page-data&#x27;</span>])[<span class="string">&#x27;totalPage&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分页采集获取网址</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, pc + <span class="number">1</span>):</span><br><span class="line">    url = webUrl + <span class="string">&#x27;pg&#x27;</span> + <span class="built_in">str</span>(i)</span><br><span class="line">    <span class="built_in">print</span>(url)</span><br></pre></td></tr></table></figure>



<p><strong>任务：</strong> </p>
<ol>
<li>熟悉本周讲解的相关内容。 </li>
<li>摸索如何对链家重庆二手房数据进行全面采集。具体要求如下：</li>
</ol>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601281009884.png" alt="image-20260128100946741"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> ReqHtmlOrByte <span class="keyword">import</span> getHTMLAndByte</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">webUrl = <span class="string">&#x27;https://cq.lianjia.com/ershoufang/&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取最大页数</span></span><br><span class="line">soup = BeautifulSoup(getHTMLAndByte(webUrl), <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="comment"># print(soup.select(&#x27;.house-lst-page-box&#x27;)[0].attrs[&#x27;page-data&#x27;])</span></span><br><span class="line"><span class="comment"># print(json.loads(soup.select(&#x27;.house-lst-page-box&#x27;)[0].attrs[&#x27;page-data&#x27;])[&#x27;totalPage&#x27;])</span></span><br><span class="line"><span class="comment"># print(type(soup.select(&#x27;.house-lst-page-box&#x27;)[0].attrs[&#x27;page-data&#x27;]))</span></span><br><span class="line"><span class="comment"># print(type(json.loads(soup.select(&#x27;.house-lst-page-box&#x27;)[0].attrs[&#x27;page-data&#x27;])))</span></span><br><span class="line"></span><br><span class="line">pc = json.loads(soup.select(<span class="string">&#x27;.house-lst-page-box&#x27;</span>)[<span class="number">0</span>].attrs[<span class="string">&#x27;page-data&#x27;</span>])[<span class="string">&#x27;totalPage&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分页采集获取网址</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">2</span>):  <span class="comment"># pc + 1</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;开始进行采集&quot;</span>, i, <span class="string">&quot;页数据...&quot;</span>)</span><br><span class="line">    title, name, address, info, tag, totalprice, unitprice = [], [], [], [], [], [], []</span><br><span class="line">    url = webUrl + <span class="string">&#x27;pg&#x27;</span> + <span class="built_in">str</span>(i)</span><br><span class="line">    <span class="comment"># print(url)</span></span><br><span class="line">    soup = BeautifulSoup(getHTMLAndByte(url), <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取标题</span></span><br><span class="line">    <span class="comment"># for element in soup.select(&#x27;div.info &gt; div.title&#x27;):</span></span><br><span class="line">    <span class="comment">#     # print(element.a.string)</span></span><br><span class="line">    <span class="comment">#     title.append(element.a.string)</span></span><br><span class="line"></span><br><span class="line">    title = [element.a.string <span class="keyword">for</span> element <span class="keyword">in</span> soup.select(<span class="string">&#x27;div.info &gt; div.title&#x27;</span>)]</span><br><span class="line">    <span class="comment"># print(title)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取小区名称与区域</span></span><br><span class="line">    <span class="comment"># for element in soup.select(&#x27;div.positionInfo&#x27;):</span></span><br><span class="line">    <span class="comment">#     # print(element.a.string, element.a.next_sibling.next_sibling.string)</span></span><br><span class="line">    <span class="comment">#     name.append(element.a.string)</span></span><br><span class="line">    <span class="comment">#     address.append(element.a.next_sibling.next_sibling.string)</span></span><br><span class="line"></span><br><span class="line">    name = [element.a.string <span class="keyword">for</span> element <span class="keyword">in</span> soup.select(<span class="string">&#x27;div.positionInfo&#x27;</span>)]</span><br><span class="line">    address = [element.a.next_sibling.next_sibling.string <span class="keyword">for</span> element <span class="keyword">in</span> soup.select(<span class="string">&#x27;div.positionInfo&#x27;</span>)]</span><br><span class="line">    <span class="comment"># print(name)</span></span><br><span class="line">    <span class="comment"># print(address)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取房屋信息</span></span><br><span class="line">    <span class="comment"># for element in soup.select(&#x27;div.houseInfo&#x27;):</span></span><br><span class="line">    <span class="comment">#     # print(element.span.next_sibling)</span></span><br><span class="line">    <span class="comment">#     info.append(element.span.next_sibling)</span></span><br><span class="line"></span><br><span class="line">    info = [element.span.next_sibling <span class="keyword">for</span> element <span class="keyword">in</span> soup.select(<span class="string">&#x27;div.houseInfo&#x27;</span>)]</span><br><span class="line">    <span class="comment"># print(info)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取房屋信息标签</span></span><br><span class="line">    <span class="comment"># for element in soup.select(&#x27;div.tag&#x27;):</span></span><br><span class="line">    <span class="comment">#     # print(&#x27;|&#x27;.join([tag.string for tag in element.children]))</span></span><br><span class="line">    <span class="comment">#     tag.append(&#x27;|&#x27;.join([tag.string for tag in element.children]))</span></span><br><span class="line"></span><br><span class="line">    tag = [<span class="string">&#x27;|&#x27;</span>.join([tag.string <span class="keyword">for</span> tag <span class="keyword">in</span> element.children]) <span class="keyword">for</span> element <span class="keyword">in</span> soup.select(<span class="string">&#x27;div.tag&#x27;</span>)]</span><br><span class="line">    <span class="comment"># print(tag)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 字符串处理连接操作</span></span><br><span class="line">    <span class="comment"># test = [&#x27;one&#x27;, &#x27;two&#x27;, &#x27;three&#x27;, &#x27;four&#x27;, &#x27;five&#x27;]</span></span><br><span class="line">    <span class="comment"># print(&#x27;-&#x27;.join(test))</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取总价</span></span><br><span class="line">    <span class="comment"># for element in soup.select(&#x27;div.totalPrice&#x27;):</span></span><br><span class="line">    <span class="comment">#     # print(element.span.string + element.span.next_sibling.string)</span></span><br><span class="line">    <span class="comment">#     totalprice.append(element.span.string + element.span.next_sibling.string)</span></span><br><span class="line"></span><br><span class="line">    totalprice = [element.span.string + element.span.next_sibling.string <span class="keyword">for</span> element <span class="keyword">in</span> soup.select(<span class="string">&#x27;div.totalPrice&#x27;</span>)]</span><br><span class="line">    <span class="comment"># print(totalprice)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取房屋的单价</span></span><br><span class="line">    <span class="comment"># for element in soup.select(&#x27;div.unitPrice&#x27;):</span></span><br><span class="line">    <span class="comment">#     # print(element.span.string.replace(&#x27;,&#x27;, &#x27;&#x27;))</span></span><br><span class="line">    <span class="comment">#     unitprice.append(element.span.string.replace(&#x27;,&#x27;, &#x27;&#x27;))</span></span><br><span class="line"></span><br><span class="line">    unitprice = [element.span.string.replace(<span class="string">&#x27;,&#x27;</span>, <span class="string">&#x27;&#x27;</span>) <span class="keyword">for</span> element <span class="keyword">in</span> soup.select(<span class="string">&#x27;div.unitPrice&#x27;</span>)]</span><br><span class="line">    <span class="comment"># print(unitprice)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 压缩数据</span></span><br><span class="line">    datas = [<span class="string">&#x27;,&#x27;</span>.join(d) + <span class="string">&#x27;/n&#x27;</span> <span class="keyword">for</span> d <span class="keyword">in</span> <span class="built_in">zip</span>(title, name, address, info, tag, totalprice, unitprice)]</span><br><span class="line">    <span class="comment"># print(datas)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 写入数据</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;E:\python_crawler_item\爬取信息存放\重庆链家房产信息.csv&#x27;</span>, mode=<span class="string">&#x27;a+&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.writelines(datas)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># time.sleep(10)</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;所有数据采集完成！&#x27;</span>)</span><br></pre></td></tr></table></figure>


    </div>

    
    
    
      


    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/python/" rel="tag"># python</a>
              <a href="/tags/requests/" rel="tag"># requests</a>
              <a href="/tags/BeautifulSoup/" rel="tag"># BeautifulSoup</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2021-07-25-shell-snippet.html" rel="prev" title="搬砖常用的 shell 片段记录">
                  <i class="fa fa-chevron-left"></i> 搬砖常用的 shell 片段记录
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2024-05-12-java-notes.html" rel="next" title="Java笔记">
                  Java笔记 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    
  <div class="comments" id="disqus_thread">
    <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
  </div>
  
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2026</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Cisgu</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">593k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">8:59</span>
  </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
  <script src="https://cdn.jsdelivr.net/npm/lozad@1.16.0/dist/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous" defer></script>
<script src="/js/comments.js" defer></script><script src="/js/utils.js" defer></script><script src="/js/next-boot.js" defer></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.5.0/dist/search.js" integrity="sha256-xFC6PJ82SL9b3WkGjFavNiA9gm5z6UBxWPiu4CYjptg=" crossorigin="anonymous" defer></script>
<script src="/js/third-party/search/local-search.js" defer></script>




  <script src="/js/third-party/pace.js" defer></script>

  




<script class="next-config" data-name="disqus" type="application/json">{"enable":true,"shortname":"muzi","count":true,"i18n":{"disqus":"disqus"}}</script>
<script src="/js/third-party/comments/disqus.js" defer></script>

</body>
</html>
