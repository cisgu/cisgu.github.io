<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="rgba(0,0,0,0)"><meta name="generator" content="Hexo 8.1.1">

<link rel="preconnect" href="//fonts.loli.net" crossorigin>
<link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
  <link rel="manifest" href="/manifest.json">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.loli.net/css2?family=Lato:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/themes/blue/pace-theme-center-atom.css">
  <script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous" defer></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"cisgu.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.27.0","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"github","dark":"github"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":true,"style":"mac"}},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"buttons","active":"disqus","storage":true,"lazyload":false,"nav":{"disqus":{"text":"Load Disqus","order":-1}},"activeClass":"disqus"},"stickytabs":false,"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="思维导图大数据技术栈思维导图 大数据处理简化流程 yarn工作原理 yarn工作原理简图 谷歌浏览器长截图： 检查 —&gt;     Shift+Ctrl+p    —-&#x3D;&gt;    full hadoop完全分布式安装一、配置主机名命令：hostnamectl set-hostname [主机名] 12345# 修改主机名[root@hadoop111 ~]# hostnamec">
<meta property="og:type" content="blog">
<meta property="og:title" content="大数据技术">
<meta property="og:url" content="https://cisgu.github.io/2024-09-12-big-data-development.html">
<meta property="og:site_name" content="Cisgu&#39;s blog">
<meta property="og:description" content="思维导图大数据技术栈思维导图 大数据处理简化流程 yarn工作原理 yarn工作原理简图 谷歌浏览器长截图： 检查 —&gt;     Shift+Ctrl+p    —-&#x3D;&gt;    full hadoop完全分布式安装一、配置主机名命令：hostnamectl set-hostname [主机名] 12345# 修改主机名[root@hadoop111 ~]# hostnamec">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271727671.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271727873.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271727953.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271652662.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20210324224529347.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzQ2NDEzMDY1,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20210324223910846.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzQ2NDEzMDY1,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271703245.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271727011.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271704024.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271704738.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271705087.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271705840.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271727159.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271705881.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271727322.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271705040.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271706806.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271706861.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271706429.png">
<meta property="og:image" content="e:/typora%E5%9B%BE%E7%89%87/image-20231221163927708.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271707163.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271707600.png">
<meta property="og:image" content="e:/typora%E5%9B%BE%E7%89%87/image-20231212110957048.png">
<meta property="og:image" content="e:/typora%E5%9B%BE%E7%89%87/image-20231212170908553.png">
<meta property="og:image" content="e:/typora%E5%9B%BE%E7%89%87/image-20231213154113647.png">
<meta property="og:image" content="e:/typora%E5%9B%BE%E7%89%87/image-20231213154533997.png">
<meta property="og:image" content="e:/typora%E5%9B%BE%E7%89%87/image-20231213155518859.png">
<meta property="og:image" content="e:/typora%E5%9B%BE%E7%89%87/image-20231213160855000.png">
<meta property="og:image" content="e:/typora%E5%9B%BE%E7%89%87/image-20231213162533931.png">
<meta property="og:image" content="e:/typora%E5%9B%BE%E7%89%87/image-20231213165525855.png">
<meta property="og:image" content="e:/typora%E5%9B%BE%E7%89%87/image-20231213171654405.png">
<meta property="og:image" content="e:/typora%E5%9B%BE%E7%89%87/image-20231213173500001.png">
<meta property="og:image" content="e:/typora%E5%9B%BE%E7%89%87/image-20231213173825783.png">
<meta property="og:image" content="e:/typora%E5%9B%BE%E7%89%87/image-20231213174537566.png">
<meta property="og:image" content="e:/typora%E5%9B%BE%E7%89%87/image-20231214083253778.png">
<meta property="og:image" content="e:/typora%E5%9B%BE%E7%89%87/image-20231214083353078.png">
<meta property="og:image" content="e:/typora%E5%9B%BE%E7%89%87/image-20231214085834628.png">
<meta property="og:image" content="e:/typora%E5%9B%BE%E7%89%87/image-20231214085907092.png">
<meta property="og:image" content="e:/typora%E5%9B%BE%E7%89%87/image-20231214085922852.png">
<meta property="og:image" content="e:/typora%E5%9B%BE%E7%89%87/image-20231214092354917.png">
<meta property="og:image" content="e:/typora%E5%9B%BE%E7%89%87/image-20231214092419564.png">
<meta property="og:image" content="e:/typora%E5%9B%BE%E7%89%87/image-20231214092448067.png">
<meta property="og:image" content="e:/typora%E5%9B%BE%E7%89%87/image-20231214092503853.png">
<meta property="og:image" content="e:/typora%E5%9B%BE%E7%89%87/image-20231214092523751.png">
<meta property="og:image" content="e:/typora%E5%9B%BE%E7%89%87/image-20231225215043624.png">
<meta property="article:published_time" content="2024-09-11T16:00:00.000Z">
<meta property="article:modified_time" content="2024-12-02T16:00:00.000Z">
<meta property="article:author" content="Cisgu">
<meta property="article:tag" content="hadoop">
<meta property="article:tag" content="scala">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271727671.png">


<link rel="canonical" href="https://cisgu.github.io/2024-09-12-big-data-development.html">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://cisgu.github.io/2024-09-12-big-data-development.html","path":"2024-09-12-big-data-development.html","title":"大数据技术"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>大数据技术 | Cisgu's blog</title>
  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Cisgu's blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/about.html" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE"><span class="nav-number">1.</span> <span class="nav-text">思维导图</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hadoop%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85"><span class="nav-number">2.</span> <span class="nav-text">hadoop完全分布式安装</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9FHDFS"><span class="nav-number">3.</span> <span class="nav-text">分布式文件系统HDFS</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Scala%E5%9F%BA%E7%A1%80"><span class="nav-number">4.</span> <span class="nav-text">Scala基础</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="nav-number">5.</span> <span class="nav-text">Hive基本概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark-%E5%9F%BA%E7%A1%80"><span class="nav-number">6.</span> <span class="nav-text">Spark 基础</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Docker"><span class="nav-number">7.</span> <span class="nav-text">Docker</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Cisgu"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Cisgu</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">5</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/cisgu" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;cisgu" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:ugycc@qq.com" title="E-Mail → mailto:ugycc@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/cisgu" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;cisgu" rel="noopener" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://t.me/cisgu" title="Telegram → https:&#x2F;&#x2F;t.me&#x2F;cisgu" rel="noopener" target="_blank"><i class="fa-brands fa-telegram fa-fw"></i>Telegram</a>
      </span>
      <span class="links-of-author-item">
        <a href="/atom.xml" title="RSS → &#x2F;atom.xml"><i class="fa-solid fa-square-rss fa-fw"></i>RSS</a>
      </span>
  </div>



        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://cisgu.github.io/2024-09-12-big-data-development.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Cisgu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Cisgu's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="大数据技术 | Cisgu's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          大数据技术
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-09-12 2024-09-12T00:00:00+08:00" itemprop="dateCreated datePublished" datetime="2024-09-12T00:00:00+08:00">2024-09-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-12-03 2024-12-03T00:00:00+08:00" itemprop="dateModified" datetime="2024-12-03T00:00:00+08:00">2024-12-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">笔记</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2024-09-12-big-data-development.html#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2024-09-12-big-data-development.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>193k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>2:55</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h3 id="思维导图"><a href="#思维导图" class="headerlink" title="思维导图"></a>思维导图</h3><h4 id="大数据技术栈思维导图"><a href="#大数据技术栈思维导图" class="headerlink" title="大数据技术栈思维导图"></a>大数据技术栈思维导图</h4><p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271727671.png" alt="大数据技术栈思维导图"></p>
<h4 id="大数据处理简化流程"><a href="#大数据处理简化流程" class="headerlink" title="大数据处理简化流程"></a>大数据处理简化流程</h4><p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271727873.png" alt="大数据处理简化流程"></p>
<h4 id="yarn工作原理"><a href="#yarn工作原理" class="headerlink" title="yarn工作原理"></a>yarn工作原理</h4><p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271727953.png" alt="yarn工作原理"></p>
<h4 id="yarn工作原理简图"><a href="#yarn工作原理简图" class="headerlink" title="yarn工作原理简图"></a>yarn工作原理简图</h4><p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271652662.png" alt="yarn工作原理简图"></p>
<p>谷歌浏览器长截图：</p>
<p>检查 —&gt;     Shift+Ctrl+p    —-&#x3D;&gt;    full</p>
<h3 id="hadoop完全分布式安装"><a href="#hadoop完全分布式安装" class="headerlink" title="hadoop完全分布式安装"></a>hadoop完全分布式安装</h3><h4 id="一、配置主机名"><a href="#一、配置主机名" class="headerlink" title="一、配置主机名"></a>一、配置主机名</h4><p>命令：hostnamectl set-hostname [主机名]</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改主机名</span></span><br><span class="line">[root@hadoop111 ~]# hostnamectl set-hostname hadoop111</span><br><span class="line"><span class="comment"># 查看主机名</span></span><br><span class="line">[root@hadoop111 ~]# hostname</span><br><span class="line">hadoop111</span><br></pre></td></tr></table></figure>

<h4 id="二、配置IP映射"><a href="#二、配置IP映射" class="headerlink" title="二、配置IP映射"></a>二、配置IP映射</h4><p>配置IP映射前,要明确当前虚拟机的IP和主机名</p>
<p>命令：vi &#x2F;etc&#x2F;hosts</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop111 ~]# vi /etc/hosts</span><br></pre></td></tr></table></figure>

<p>配置内容：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">localhost6.localdomain6</span><br><span class="line">192.168.137.133 hadoop111</span><br><span class="line">192.168.137.134 hadoop112</span><br><span class="line">192.168.137.135 hadoop113</span><br></pre></td></tr></table></figure>





<h4 id="三、网络参数配置"><a href="#三、网络参数配置" class="headerlink" title="三、网络参数配置"></a>三、网络参数配置</h4><p>前面,对虚拟机的主机名和IP映射进行了配置,而想要虚拟机能够正常使用,还需要进行网络参数配置。</p>
<p>(1) 查看网络是否连通</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop111 ~]# ping www.baidu.com</span><br><span class="line">PING www.a.shifen.com (183.2.172.185) 56(84) bytes of data.</span><br><span class="line">64 bytes from 183.2.172.185 (183.2.172.185): icmp_seq=1 ttl=128 <span class="keyword">time</span>=29.5 ms</span><br><span class="line">^C</span><br><span class="line">--- www.a.shifen.com ping statistics ---</span><br><span class="line">3 packets transmitted, 3 received, 0% packet loss, <span class="keyword">time</span> 2012ms</span><br><span class="line">rtt min/avg/max/mdev = 29.135/29.298/29.500/0.151 ms</span><br><span class="line">[root@hadoop111 ~]#</span><br></pre></td></tr></table></figure>



<p>(2)查看MAC地址（enter后面）：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop111 ~]# ifconfig</span><br><span class="line">ens33: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 192.168.137.133  netmask 255.255.255.0  broadcast 192.168.137.255</span><br><span class="line">        inet6 fe80::6594:415e:4d5:72b8  prefixlen 64  scopeid 0x20&lt;<span class="built_in">link</span>&gt;</span><br><span class="line">        ether 00:0c:29:32:bf:50  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 1414  bytes 148232 (144.7 KiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 998  bytes 100435 (98.0 KiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536</span><br><span class="line">        inet 127.0.0.1  netmask 255.0.0.0</span><br><span class="line">        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;</span><br><span class="line">        loop  txqueuelen 1000  (Local Loopback)</span><br><span class="line">        RX packets 0  bytes 0 (0.0 B)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 0  bytes 0 (0.0 B)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">virbr0: flags=4099&lt;UP,BROADCAST,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 192.168.122.1  netmask 255.255.255.0  broadcast 192.168.122.255</span><br><span class="line">        ether 52:54:00:20:1a:75  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 0  bytes 0 (0.0 B)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 0  bytes 0 (0.0 B)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br></pre></td></tr></table></figure>

<p>（3）修改网络配置文件：</p>
<p>命令： vim &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-ens33</p>
<ul>
<li>HWADDR:表示虚拟机 MAC地址,需要与当前虚拟机MAC地址一致;</li>
<li>IPADDR:表示虚拟机的IP地址,这里设置的IP地址要与前面IP映射配置时的IP地址一致,否则无法通过主机名找到对应IP;</li>
<li>GATEWAY:表示虚拟机网关,通常都是将IP地址最后一位改成2;</li>
<li>NETMASK:表示虚拟机子网掩码,通常都是255.255.255.0;</li>
<li>DNS1:表示域名解析器,此处采用Google提供的免费DNS服务器8.8.8.8(也可以设置为PC端电脑对应的DNS)。</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop111 ~]# vim /etc/sysconfig/network-scripts/ifcfg-ens33</span><br></pre></td></tr></table></figure>

<p>修改内容：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">TYPE=<span class="string">&quot;Ethernet&quot;</span></span><br><span class="line">PROXY_METHOD=<span class="string">&quot;none&quot;</span></span><br><span class="line">BROWSER_ONLY=<span class="string">&quot;no&quot;</span></span><br><span class="line">BOOTPROTO=<span class="string">&quot;static&quot;</span></span><br><span class="line">DEFROUTE=<span class="string">&quot;yes&quot;</span></span><br><span class="line">IPV4_FAILURE_FATAL=<span class="string">&quot;no&quot;</span></span><br><span class="line">IPV6INIT=<span class="string">&quot;yes&quot;</span></span><br><span class="line">IPV6_AUTOCONF=<span class="string">&quot;yes&quot;</span></span><br><span class="line">IPV6_DEFROUTE=<span class="string">&quot;yes&quot;</span></span><br><span class="line">IPV6_FAILURE_FATAL=<span class="string">&quot;no&quot;</span></span><br><span class="line">IPV6_ADDR_GEN_MODE=<span class="string">&quot;stable-privacy&quot;</span></span><br><span class="line">NAME=<span class="string">&quot;ens33&quot;</span></span><br><span class="line">UUID=<span class="string">&quot;7e054fea-e568-4406-8160-6b7c1d983be5&quot;</span></span><br><span class="line">DEVICE=<span class="string">&quot;ens33&quot;</span></span><br><span class="line">ONBOOT=<span class="string">&quot;yes&quot;</span></span><br><span class="line">HWADDR=<span class="string">&quot;00:0c:29:32:bf:50&quot;</span></span><br><span class="line">IPADDR=<span class="string">&quot;192.168.137.133&quot;</span></span><br><span class="line">GATEWAY=<span class="string">&quot;192.168.137.2&quot;</span></span><br><span class="line">NETMASK=<span class="string">&quot;255.255.255.0&quot;</span></span><br><span class="line">DNS1=<span class="string">&quot;8.8.8.8&quot;</span></span><br></pre></td></tr></table></figure>

<p>再ping一下网是否连通：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重启网络</span></span><br><span class="line">[root@hadoop111 ~]# systemctl restart network</span><br><span class="line"></span><br><span class="line">[root@hadoop111 ~]# ping www.baidu.com</span><br><span class="line">PING www.wshifen.com (104.193.88.123) 56(84) bytes of data.</span><br><span class="line">64 bytes from 104.193.88.123 (104.193.88.123): icmp_seq=1 ttl=128 <span class="keyword">time</span>=171 ms</span><br><span class="line">^C</span><br><span class="line">--- www.wshifen.com ping statistics ---</span><br><span class="line">2 packets transmitted, 1 received, 50% packet loss, <span class="keyword">time</span> 1002ms</span><br><span class="line">rtt min/avg/max/mdev = 171.776/171.776/171.776/0.000 ms</span><br><span class="line">[root@hadoop111 ~]#</span><br></pre></td></tr></table></figure>

<p>同样方法克隆两台虚拟机如上设置</p>
<h4 id="四、SSH免密"><a href="#四、SSH免密" class="headerlink" title="四、SSH免密"></a>四、SSH免密</h4><p>（1）防火墙的操作</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看防火墙状态</span></span><br><span class="line">[root@hadoop111 ~]# systemctl status firewalld.service</span><br><span class="line">● firewalld.service - firewalld - dynamic firewall daemon</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/firewalld.service; enabled; vendor preset: enabled)</span><br><span class="line">   Active: active (running) since 一 2023-12-04 14:37:22 CST; 10min ago</span><br><span class="line">     Docs: man:firewalld(1)</span><br><span class="line"> Main PID: 792 (firewalld)</span><br><span class="line">    Tasks: 2</span><br><span class="line">   CGroup: /system.slice/firewalld.service</span><br><span class="line">           └─792 /usr/bin/python2 -Es /usr/sbin/firewalld --nofork --nopid</span><br><span class="line"></span><br><span class="line">12月 04 14:37:20 hadoop111 systemd[1]: Starting firewalld - dynamic firewall daemon...</span><br><span class="line">12月 04 14:37:22 hadoop111 systemd[1]: Started firewalld - dynamic firewall daemon.</span><br><span class="line">12月 04 14:37:22 hadoop111 firewalld[792]: WARNING: AllowZoneDrifting is enabled. ...w.</span><br><span class="line">Hint: Some lines were ellipsized, use -l to show <span class="keyword">in</span> full.</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭防火墙</span></span><br><span class="line">[root@hadoop111 ~]# systemctl stop firewalld.service</span><br><span class="line"><span class="comment"># 关闭防火墙的自启动(永久关闭)</span></span><br><span class="line">[root@hadoop111 ~]# systemctl <span class="built_in">disable</span> firewalld.service</span><br><span class="line">Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.</span><br><span class="line">Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.</span><br><span class="line"><span class="comment"># 重启网络</span></span><br><span class="line">[root@hadoop111 ~]# systemctl restart network</span><br></pre></td></tr></table></figure>



<p>(2) 免密登录原理</p>
<img data-src="https://img-blog.csdnimg.cn/20210324224529347.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzQ2NDEzMDY1,size_16,color_FFFFFF,t_70" alt="img"  />

<p>生成密钥文件:</p>
<p>命令：ssh-keygen -t rsa</p>
<p>连续按4次回车</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop111 ~]# ssh-keygen -t rsa</span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file <span class="keyword">in</span> <span class="built_in">which</span> to save the key (/root/.ssh/id_rsa):</span><br><span class="line">Created directory <span class="string">&#x27;/root/.ssh&#x27;</span>.</span><br><span class="line">Enter passphrase (empty <span class="keyword">for</span> no passphrase):</span><br><span class="line">Enter same passphrase again:</span><br><span class="line">Your identification has been saved <span class="keyword">in</span> /root/.ssh/id_rsa.</span><br><span class="line">Your public key has been saved <span class="keyword">in</span> /root/.ssh/id_rsa.pub.</span><br><span class="line">The key fingerprint is:</span><br><span class="line">SHA256:6rzN1cbKCPaQmOxTVgK8+Mmz59fCMDY7i5dEAh2FvGw root@hadoop111</span><br><span class="line">The key<span class="string">&#x27;s randomart image is:</span></span><br><span class="line"><span class="string">+---[RSA 2048]----+</span></span><br><span class="line"><span class="string">|   +.+.          |</span></span><br><span class="line"><span class="string">|  . *            |</span></span><br><span class="line"><span class="string">|   + +           |</span></span><br><span class="line"><span class="string">|  . E o .        |</span></span><br><span class="line"><span class="string">|   + + oS        |</span></span><br><span class="line"><span class="string">|   .=oOo   o     |</span></span><br><span class="line"><span class="string">|    +B*B .. +    |</span></span><br><span class="line"><span class="string">|   .o=**++.o     |</span></span><br><span class="line"><span class="string">|    o=*==.o      |</span></span><br><span class="line"><span class="string">+----[SHA256]-----+</span></span><br></pre></td></tr></table></figure>

<p>将本机公钥文件复制到其他虚ssh拟机上</p>
<p>命令：ssh-copy-id [主机名]</p>
<p>在hadoop200上执行，先输入yes，后输入对应主机的密码，三台虚拟机配置操作相同：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop111 ~]# ssh-copy-id hadoop111</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: <span class="string">&quot;/root/.ssh/id_rsa.pub&quot;</span></span><br><span class="line">The authenticity of host <span class="string">&#x27;hadoop111 (192.168.137.133)&#x27;</span> can<span class="string">&#x27;t be established.</span></span><br><span class="line"><span class="string">ECDSA key fingerprint is SHA256:Cj4xUYc6IsbQuoo7d+eu10SyayJ/Q1N0ZmlzjEmme/k.</span></span><br><span class="line"><span class="string">ECDSA key fingerprint is MD5:f3:ea:99:f7:71:c5:e5:4a:85:00:6f:8d:10:c9:42:0a.</span></span><br><span class="line"><span class="string">Are you sure you want to continue connecting (yes/no)? yes</span></span><br><span class="line"><span class="string">/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any                                                                    that are already installed</span></span><br><span class="line"><span class="string">/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now i                                                                   t is to install the new keys</span></span><br><span class="line"><span class="string">root@hadoop111&#x27;</span>s password:</span><br><span class="line"></span><br><span class="line">Number of key(s) added: 1</span><br><span class="line"></span><br><span class="line">Now try logging into the machine, with:   <span class="string">&quot;ssh &#x27;hadoop111&#x27;&quot;</span></span><br><span class="line">and check to make sure that only the key(s) you wanted were added.</span><br><span class="line"></span><br><span class="line">[root@hadoop111 ~]# ssh-copy-id hadoop112</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: <span class="string">&quot;/root/.ssh/id_rsa.pub&quot;</span></span><br><span class="line">The authenticity of host <span class="string">&#x27;hadoop112 (192.168.137.134)&#x27;</span> can<span class="string">&#x27;t be established.</span></span><br><span class="line"><span class="string">ECDSA key fingerprint is SHA256:Cj4xUYc6IsbQuoo7d+eu10SyayJ/Q1N0ZmlzjEmme/k.</span></span><br><span class="line"><span class="string">ECDSA key fingerprint is MD5:f3:ea:99:f7:71:c5:e5:4a:85:00:6f:8d:10:c9:42:0a.</span></span><br><span class="line"><span class="string">Are you sure you want to continue connecting (yes/no)? yes</span></span><br><span class="line"><span class="string">/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any                                                                    that are already installed</span></span><br><span class="line"><span class="string">/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now i                                                                   t is to install the new keys</span></span><br><span class="line"><span class="string">root@hadoop112&#x27;</span>s password:</span><br><span class="line"></span><br><span class="line">Number of key(s) added: 1</span><br><span class="line"></span><br><span class="line">Now try logging into the machine, with:   <span class="string">&quot;ssh &#x27;hadoop112&#x27;&quot;</span></span><br><span class="line">and check to make sure that only the key(s) you wanted were added.</span><br><span class="line"></span><br><span class="line">[root@hadoop111 ~]# ssh-copy-id hadoop113</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: <span class="string">&quot;/root/.ssh/id_rsa.pub&quot;</span></span><br><span class="line">The authenticity of host <span class="string">&#x27;hadoop113 (192.168.137.135)&#x27;</span> can<span class="string">&#x27;t be established.</span></span><br><span class="line"><span class="string">ECDSA key fingerprint is SHA256:Cj4xUYc6IsbQuoo7d+eu10SyayJ/Q1N0ZmlzjEmme/k.</span></span><br><span class="line"><span class="string">ECDSA key fingerprint is MD5:f3:ea:99:f7:71:c5:e5:4a:85:00:6f:8d:10:c9:42:0a.</span></span><br><span class="line"><span class="string">Are you sure you want to continue connecting (yes/no)? yes</span></span><br><span class="line"><span class="string">/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any                                                                    that are already installed</span></span><br><span class="line"><span class="string">/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now i                                                                   t is to install the new keys</span></span><br><span class="line"><span class="string">root@hadoop113&#x27;</span>s password:</span><br><span class="line"></span><br><span class="line">Number of key(s) added: 1</span><br><span class="line"></span><br><span class="line">Now try logging into the machine, with:   <span class="string">&quot;ssh &#x27;hadoop113&#x27;&quot;</span></span><br><span class="line">and check to make sure that only the key(s) you wanted were added.</span><br></pre></td></tr></table></figure>

<p>验证是否免密成功</p>
<p>命令：ssh [主机名]</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop111 ~]# ssh hadoop112</span><br><span class="line">Last login: Mon Dec  4 14:38:54 2023 from 192.168.137.1</span><br><span class="line">[root@hadoop112 ~]# <span class="built_in">exit</span></span><br><span class="line">登出</span><br><span class="line">Connection to hadoop112 closed.</span><br></pre></td></tr></table></figure>

<p>.ssh 文件夹下 （~&#x2F;.ssh ） 的文件功能解释</p>
<img data-src="https://img-blog.csdnimg.cn/20210324223910846.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzQ2NDEzMDY1,size_16,color_FFFFFF,t_70" alt="img"  />



<h4 id="五、JDK-hadoop安装"><a href="#五、JDK-hadoop安装" class="headerlink" title="五、JDK&amp;hadoop安装"></a>五、JDK&amp;hadoop安装</h4><ol>
<li>查看系统自带的jdk</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop111 ~]# rpm -qa | grep -i java</span><br><span class="line">java-1.7.0-openjdk-headless-1.7.0.261-2.6.22.2.el7_8.x86_64</span><br><span class="line">python-javapackages-3.4.1-11.el7.noarch</span><br><span class="line">tzdata-java-2020a-1.el7.noarch</span><br><span class="line">java-1.8.0-openjdk-headless-1.8.0.262.b10-1.el7.x86_64</span><br><span class="line">java-1.8.0-openjdk-1.8.0.262.b10-1.el7.x86_64</span><br><span class="line">javapackages-tools-3.4.1-11.el7.noarch</span><br><span class="line">java-1.7.0-openjdk-1.7.0.261-2.6.22.2.el7_8.x86_64</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>如果之前没创的话，创建自己的新用户 ，并修改新用户用户的密码</li>
</ol>
<p>命令：useradd newname</p>
<p>​			passwd newname</p>
<ol start="3">
<li>配置 leokadia 用户具有 root 权限 ， 方便 后期 加 sudo 执行 root 权限的命令</li>
</ol>
<p>命令：vim &#x2F;etc&#x2F;sudoers</p>
<p>进入后，下翻，找到如下地方</p>
<p>在%wheel 这行下面添加一行，如下内容：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yun   ALL=(ALL)     NOPASSWD:ALL</span><br></pre></td></tr></table></figure>

<p>注意要输入 wq! 保存并退出</p>
<ol start="4">
<li>用 Xshell 传输工具将 JDK 导入到 opt 目录下面的 software 文件夹下面</li>
</ol>
<p>先在opt目录下创建software、module目录</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop111 opt]# <span class="built_in">mkdir</span> software module</span><br><span class="line">[root@hadoop111 opt]# ll</span><br><span class="line">总用量 0</span><br><span class="line">drwxr-xr-x. 4 yun yun 31 11月 29 17:15 module</span><br><span class="line">drwxr-xr-x. 2 yun yun  6 10月 31 2018 rh</span><br><span class="line">drwxr-xr-x. 2 yun yun 67 11月 29 17:12 software</span><br></pre></td></tr></table></figure>

<p>先可以也提前将Hadoop的安装包也一起传来了</p>
<p> 在opt &#x2F;software目录中查看软件包是否导入成功</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop111 software]# ll</span><br><span class="line">总用量 515524</span><br><span class="line">-rw-r--r--. 1 yun yun 338075860 11月 29 17:13 hadoop-3.1.3.tar.gz</span><br><span class="line">-rw-r--r--. 1 yun yun 189815615 11月 29 17:12 jdk-8u162-linux-x64.tar.gz</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>解压 JDK&amp;hadoop 到&#x2F;opt&#x2F;module 目录cd下</li>
</ol>
<p>命令：tar -zxvf jdk-8u162-linux-x64.tar.gz -C &#x2F;opt&#x2F;module&#x2F;</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop111 software]# tar -zxvf jdk-8u162-linux-x64.tar.gz -C /opt/module/</span><br><span class="line">[root@hadoop111 software]# tar -zxvf hadoop-3.1.3.tar.gz -C /opt/module/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切换会/opt/module目录，查看相关内容</span></span><br><span class="line">[root@hadoop111 opt]# ll</span><br><span class="line">总用量 0</span><br><span class="line">drwxr-xr-x. 4 yun yun 31 11月 29 17:15 module</span><br><span class="line">drwxr-xr-x. 2 yun yun  6 10月 31 2018 rh</span><br><span class="line">drwxr-xr-x. 2 yun yun 67 11月 29 17:12 software</span><br></pre></td></tr></table></figure>



<ol start="6">
<li>配置 JDK &amp;hadoop环境变量</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入 profile</span></span><br><span class="line">[root@hadoop111 etc]# vim /etc/profile</span><br><span class="line"></span><br><span class="line"><span class="comment"># java环境配置</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/module/jdk</span><br><span class="line"><span class="built_in">export</span> PATH=.:<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="comment"># hadoop环境配置</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/opt/module/hadoop</span><br><span class="line"><span class="built_in">export</span> PATH=.:<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin:<span class="variable">$PATH</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>source 一下&#x2F;etc&#x2F;profile 文件，让新的环境变量 PATH 生效</p>
<p>命令：source &#x2F;etc&#x2F;profile</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop111 etc]# <span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure>



<ol start="7">
<li>测试 JDK &amp;hadoop是否安装成功</li>
</ol>
<p>命令：java</p>
<p>命令：java -version</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop111 etc]# java -version</span><br><span class="line">java version <span class="string">&quot;1.8.0_162&quot;</span></span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_162-b12)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.162-b12, mixed mode)</span><br></pre></td></tr></table></figure>

<p>命令：hadoop version</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop111 etc]# hadoop version</span><br><span class="line">Hadoop 3.1.3</span><br><span class="line">Source code repository https://gitbox.apache.org/repos/asf/hadoop.git -r ba631c436b806728f8ec2f54ab1e289526c90579</span><br><span class="line">Compiled by ztang on 2019-09-12T02:47Z</span><br><span class="line">Compiled with protoc 2.5.0</span><br><span class="line">From <span class="built_in">source</span> with checksum ec785077c385118ac91aadde5ec9799</span><br><span class="line">This <span class="built_in">command</span> was run using /opt/module/hadoop/share/hadoop/common/hadoop-common-3.1.3.jar</span><br></pre></td></tr></table></figure>



<h4 id="六、编写集群分发脚本-xsync"><a href="#六、编写集群分发脚本-xsync" class="headerlink" title="六、编写集群分发脚本 xsync"></a>六、编写集群分发脚本 xsync</h4><ol>
<li>在&#x2F;bin目录下创建 xsync 文件</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop111 ~]# <span class="built_in">cd</span> bin</span><br><span class="line">[root@hadoop111 bin]# vim xsync</span><br></pre></td></tr></table></figure>

<p>在该文件中编写如下内容</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#1. 判断参数个数</span></span><br><span class="line"><span class="comment"># 判断参数是否小于1</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$#</span> -lt 1 ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> Not Enough Arguement!</span><br><span class="line">    <span class="built_in">exit</span>;</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#2. 遍历集群所有机器</span></span><br><span class="line"><span class="comment"># 对111，112，113都进行分发</span></span><br><span class="line"><span class="keyword">for</span> host <span class="keyword">in</span> hadoop111 hadoop112 hadoop113</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">   <span class="built_in">echo</span> ====================  <span class="variable">$host</span>  ====================</span><br><span class="line">   <span class="comment">#3. 遍历所有目录，挨个发送</span></span><br><span class="line">   <span class="keyword">for</span> file <span class="keyword">in</span> <span class="variable">$@</span></span><br><span class="line">   <span class="keyword">do</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#4. 判断文件是否存在</span></span><br><span class="line">        <span class="keyword">if</span> [ -e <span class="variable">$file</span> ]</span><br><span class="line">            <span class="keyword">then</span></span><br><span class="line">                <span class="comment">#5. 获取父目录</span></span><br><span class="line">                pdir=$(<span class="built_in">cd</span> -P $(<span class="built_in">dirname</span> <span class="variable">$file</span>); <span class="built_in">pwd</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment">#6. 获取当前文件的名称</span></span><br><span class="line">                fname=$(<span class="built_in">basename</span> <span class="variable">$file</span>)</span><br><span class="line">                ssh <span class="variable">$host</span> <span class="string">&quot;mkdir -p <span class="variable">$pdir</span>&quot;</span></span><br><span class="line">                rsync -av <span class="variable">$pdir</span>/<span class="variable">$fname</span> <span class="variable">$host</span>:<span class="variable">$pdir</span> </span><br><span class="line">            <span class="comment"># 如果不存在</span></span><br><span class="line">            <span class="keyword">else</span> </span><br><span class="line">                <span class="built_in">echo</span> <span class="variable">$file</span> does not exists! </span><br><span class="line">        <span class="keyword">fi</span> </span><br><span class="line">    <span class="keyword">done</span> </span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>修改脚本 xsync 具有执行权限</li>
</ol>
<p>命令：chmod +x xsync</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop111 bin]# ll</span><br><span class="line">总用量 4</span><br><span class="line">-rw-r--r--. 1 root root 874 12月  4 15:37 xsync</span><br><span class="line">[root@hadoop111 bin]# <span class="built_in">chmod</span> +x xsync</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>测试脚本</li>
</ol>
<p>命令：xsync bin&#x2F;</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop111 ~]# xsync bin/</span><br><span class="line">==================== hadoop111 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line"></span><br><span class="line">sent 80 bytes  received 17 bytes  194.00 bytes/sec</span><br><span class="line">total size is 874  speedup is 9.01</span><br><span class="line">==================== hadoop112 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line">bin/</span><br><span class="line">bin/xsync</span><br><span class="line"></span><br><span class="line">sent 1,000 bytes  received 39 bytes  2,078.00 bytes/sec</span><br><span class="line">total size is 874  speedup is 0.84</span><br><span class="line">==================== hadoop113 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line">bin/</span><br><span class="line">bin/xsync</span><br><span class="line"></span><br><span class="line">sent 1,000 bytes  received 39 bytes  2,078.00 bytes/sec</span><br><span class="line">total size is 874  speedup is 0.84</span><br></pre></td></tr></table></figure>

<p>在hadoop112，hadoop113上验证，发现脚本传输成功</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop111 ~]# ll</span><br><span class="line">总用量 8</span><br><span class="line">-rw-------. 1 root root 1734 11月 25 18:14 anaconda-ks.cfg</span><br><span class="line">drwxr-xr-x. 2 root root   19 12月  4 15:37 bin</span><br><span class="line">-rw-r--r--. 1 root root 1782 11月 25 18:16 initial-setup-ks.cfg</span><br><span class="line">drwxr-xr-x. 2 root root    6 11月 25 18:16 公共</span><br><span class="line">drwxr-xr-x. 2 root root    6 11月 25 18:16 模板</span><br><span class="line">drwxr-xr-x. 2 root root    6 11月 25 18:16 视频</span><br><span class="line">drwxr-xr-x. 2 root root    6 11月 25 18:16 图片</span><br><span class="line">drwxr-xr-x. 2 root root    6 11月 25 18:16 文档</span><br><span class="line">drwxr-xr-x. 2 root root    6 11月 25 18:16 下载</span><br><span class="line">drwxr-xr-x. 2 root root    6 11月 25 18:16 音乐</span><br><span class="line">drwxr-xr-x. 2 root root    6 11月 25 18:16 桌面</span><br></pre></td></tr></table></figure>

<p>………</p>
<h4 id="七、集群配置"><a href="#七、集群配置" class="headerlink" title="七、集群配置"></a>七、集群配置</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> [hadmin@master hadoop]$ vim hadoop-env.sh </span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改下列内容，大概在55行左右 </span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/module/jdk</span><br></pre></td></tr></table></figure>



<ol>
<li>核心配置文件</li>
</ol>
<p>配置 core-site.xml</p>
<p>命令：cd $HADOOP_HOME&#x2F;etc&#x2F;hadoop</p>
<p>命令：vim core-site.xml</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop111 ~]# <span class="built_in">cd</span> <span class="variable">$HADOOP_HOME</span>/etc/hadoop</span><br><span class="line">[root@hadoop111 hadoop]# vim core-site.xml</span><br></pre></td></tr></table></figure>

<p>配置内容：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 指定 NameNode 的地址 --&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">       &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">       &lt;value&gt;hdfs://hadoop111:8020&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">   &lt;!-- 指定 hadoop 数据的存储目录 --&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">       &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">       &lt;value&gt;/opt/module/hadoop/data&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">   &lt;!-- 配置 HDFS 网页登录使用的静态用户为 atguigu --&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">       &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt;</span><br><span class="line">       &lt;value&gt;atguigu&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>HDFS 配置文件</li>
</ol>
<p>命令：vim hdfs-site.xml</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop111 hadoop]# vim hdfs-site.xml</span><br></pre></td></tr></table></figure>

<p>配置内容：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- NameNode web 端访问地址--&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">       &lt;name&gt;dfs.namenode.http-address&lt;/name&gt;</span><br><span class="line">       &lt;value&gt;hadoop111:9870&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line"> &lt;!-- SecondaryNameNode web 端访问地址--&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">       &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</span><br><span class="line">       &lt;value&gt;hadoop113:9868&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>YARN 配置文件</li>
</ol>
<p>命令：vim yarn-site.xml</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop111 hadoop]# vim yarn-site.xml</span><br></pre></td></tr></table></figure>

<p>配置内容：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 指定 MR 走 shuffle --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- 指定 ResourceManager 的地址--&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hadoop112&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- 环境变量的继承 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt;</span><br><span class="line"></span><br><span class="line">&lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>MapReduce 配置文件</li>
</ol>
<p>命令：vim mapred-site.xml</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop111 hadoop]# vim mapred-site.xml</span><br></pre></td></tr></table></figure>

<p>配置内容：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 指定 MapReduce 程序运行在 Yarn 上 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>需要将这个配置文件分发给hadoop112，hadoop113</li>
</ol>
<p>在集群上分发配置好的 Hadoop 配置文件</p>
<p>命令：xsync &#x2F;opt&#x2F;module&#x2F;hadoop&#x2F;etc&#x2F;hadoop&#x2F;</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop111 hadoop]# xsync /opt/module/hadoop/etc/hadoop/</span><br><span class="line">==================== hadoop111 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line"></span><br><span class="line">sent 890 bytes  received 18 bytes  1,816.00 bytes/sec</span><br><span class="line">total size is 107,822  speedup is 118.75</span><br><span class="line">==================== hadoop112 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line">hadoop/</span><br><span class="line">hadoop/core-site.xml</span><br><span class="line">hadoop/hdfs-site.xml</span><br><span class="line">hadoop/mapred-site.xml</span><br><span class="line">hadoop/yarn-site.xml</span><br><span class="line"></span><br><span class="line">sent 3,544 bytes  received 145 bytes  7,378.00 bytes/sec</span><br><span class="line">total size is 107,822  speedup is 29.23</span><br><span class="line">==================== hadoop113 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line">hadoop/</span><br><span class="line">hadoop/core-site.xml</span><br><span class="line">hadoop/hdfs-site.xml</span><br><span class="line">hadoop/mapred-site.xml</span><br><span class="line">hadoop/yarn-site.xml</span><br><span class="line"></span><br><span class="line">sent 3,544 bytes  received 145 bytes  2,459.33 bytes/sec</span><br><span class="line">total size is 107,822  speedup is 29.23</span><br></pre></td></tr></table></figure>

<p>去112 和 113 上 查看文件分发情况</p>
<p>命令：cat &#x2F;opt&#x2F;module&#x2F;hadoop&#x2F;etc&#x2F;hadoop&#x2F;core-site.xml</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop111 ~]# <span class="built_in">cat</span> /opt/module/hadoop/etc/hadoop/core-site.xml</span><br><span class="line">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span><br><span class="line">&lt;?xml-stylesheet <span class="built_in">type</span>=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span><br><span class="line">&lt;!--</span><br><span class="line">  Licensed under the Apache License, Version 2.0 (the <span class="string">&quot;License&quot;</span>);</span><br><span class="line">  you may not use this file except <span class="keyword">in</span> compliance with the License.</span><br><span class="line">  You may obtain a copy of the License at</span><br><span class="line"></span><br><span class="line">    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="line"></span><br><span class="line">  Unless required by applicable law or agreed to <span class="keyword">in</span> writing, software</span><br><span class="line">  distributed under the License is distributed on an <span class="string">&quot;AS IS&quot;</span> BASIS,</span><br><span class="line">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line">  See the License <span class="keyword">for</span> the specific language governing permissions and</span><br><span class="line">  limitations under the License. See accompanying LICENSE file.</span><br><span class="line">--&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- Put site-specific property overrides <span class="keyword">in</span> this file. --&gt;</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">   &lt;!-- 指定 NameNode 的地址 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hdfs://hadoop111:8020&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- 指定 hadoop 数据的存储目录 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/opt/module/hadoop/data&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- 配置 HDFS 网页登录使用的静态用户为 atguigu --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;atguigu&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<p>…….</p>
<ol start="6">
<li>配置 workers</li>
</ol>
<p>命令：cd $HADOOP_HOME&#x2F;etc&#x2F;hadoop</p>
<p>命令：vim &#x2F;opt&#x2F;module&#x2F;hadoop&#x2F;etc&#x2F;hadoop&#x2F;workers</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop111 ~]# <span class="built_in">cd</span> <span class="variable">$HADOOP_HOME</span>/etc/hadoop</span><br><span class="line">[root@hadoop111 hadoop]# vim /opt/module/hadoop/etc/hadoop/workers</span><br></pre></td></tr></table></figure>

<p>在该文件中增加如下内容：（有几个节点就配置几个主机名称）</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop111</span><br><span class="line">hadoop112</span><br><span class="line">hadoop113</span><br></pre></td></tr></table></figure>

<p>同步所有节点配置文件</p>
<p>命令：xsync &#x2F;opt&#x2F;module&#x2F;hadoop&#x2F;etc</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop111 hadoop]# xsync /opt/module/hadoop/etc</span><br><span class="line">==================== hadoop111 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line">etc/hadoop/</span><br><span class="line">etc/hadoop/workers</span><br><span class="line"></span><br><span class="line">sent 999 bytes  received 51 bytes  2,100.00 bytes/sec</span><br><span class="line">total size is 107,842  speedup is 102.71</span><br><span class="line">==================== hadoop112 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line"></span><br><span class="line">sent 919 bytes  received 19 bytes  625.33 bytes/sec</span><br><span class="line">total size is 107,842  speedup is 114.97</span><br><span class="line">==================== hadoop113 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line">etc/hadoop/</span><br><span class="line">etc/hadoop/workers</span><br><span class="line"></span><br><span class="line">sent 999 bytes  received 51 bytes  700.00 bytes/sec</span><br><span class="line">total size is 107,842  speedup is 102.71</span><br></pre></td></tr></table></figure>

<p>分发配置，将三台节点配置完毕，回到家目录，准备启动集群</p>
<p>注意因为我使用的是root 用户需要配置profile变量</p>
<p>命令：vi &#x2F;etc&#x2F;profile</p>
<p>然后在最后添加如下内容：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HDFS_NAMENODE_USER=root</span><br><span class="line"><span class="built_in">export</span> HDFS_DATANODE_USER=root</span><br><span class="line"><span class="built_in">export</span> HDFS_SECONDARYNAMENODE_USER=root</span><br><span class="line"><span class="built_in">export</span> YARN_RESOURCEMANAGER_USER=root</span><br><span class="line"><span class="built_in">export</span> YARN_NODEMANAGER_USER=root</span><br></pre></td></tr></table></figure>

<p>最后使其生效</p>
<p>命令：source &#x2F;etc&#x2F;profile</p>
<ol start="7">
<li>启动集群</li>
</ol>
<p>初始化（注意：只有第一次的时候才需要）</p>
<p>如果集群是第一次启动，需要在 hadoop200 节点格式化 NameNode（注意：格式化 NameNode，会产生新的集群 id，导致 NameNode 和 DataNode 的集群 id 不一致，集群找不到已往数据。如果集群在运行过程中报错，需要重新格式化 NameNode 的话，一定要先停止 namenode 和 datanode 进程，并且要删除所有机器的 data 和 logs 目录，然后再进行格式化。）</p>
<p>命令：hdfs namenode -format</p>
<p>停止 namenode 和 datanode 进程:</p>
<p>hdfs –daemon stop namenode</p>
<p>hdfs –daemon stop datanode</p>
<ol start="8">
<li>启动 HDFS</li>
</ol>
<p>命令：sbin&#x2F;start-dfs.sh</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop111 hadoop]# sbin/start-dfs.sh</span><br></pre></td></tr></table></figure>

<p>在配置了 ResourceManager 的节点（hadoop112 ）启动 YARN</p>
<p>命令：sbin&#x2F;start-yarn.sh</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop112 hadoop]# sbin/start-yarn.sh</span><br></pre></td></tr></table></figure>

<ol start="9">
<li><p>Web 端查看 HDFS 的 NameNode </p>
<p>浏览器中输入：<code>http://hadoop200:9870</code></p>
</li>
</ol>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271703245.png" alt="image-20231127162838147"></p>
<ol start="10">
<li><p>Web 端查看 YARN 的 ResourceManager</p>
<p>浏览器中输入：<code>http://hadoop201:8088</code></p>
</li>
</ol>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271727011.png" alt="image-20231127163034588"></p>
<h3 id="分布式文件系统HDFS"><a href="#分布式文件系统HDFS" class="headerlink" title="分布式文件系统HDFS"></a>分布式文件系统HDFS</h3><h4 id="一、HDFS-Shell命令格式"><a href="#一、HDFS-Shell命令格式" class="headerlink" title="一、HDFS Shell命令格式"></a>一、HDFS Shell命令格式</h4><p>基础命名格式</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -操作命令 参数 具体文件或路径</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">hadoop fs -操作命令 参数 具体文件或路径</span><br></pre></td></tr></table></figure>



<h4 id="二、HDFS-Shell-常用操作命令"><a href="#二、HDFS-Shell-常用操作命令" class="headerlink" title="二、HDFS Shell 常用操作命令"></a>二、HDFS Shell 常用操作命令</h4><ol>
<li>帮助命令</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop200 ~]# hdfs dfs -<span class="built_in">help</span> <span class="built_in">touch</span></span><br></pre></td></tr></table></figure>



<ol start="2">
<li>HDFS中创建目录和查看信息</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop200 ~]# hdfs dfs -<span class="built_in">mkdir</span> /test</span><br></pre></td></tr></table></figure>



<ol start="3">
<li>HDFS中创建多层目录</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop200 ~]# hdfs dfs -<span class="built_in">mkdir</span> -p /inpot/log</span><br></pre></td></tr></table></figure>



<ol start="4">
<li>上传相关素材 HDFS分布式文件系统素材.zip 并解压</li>
</ol>
<p>unzip 负责解压 *.zip格式文件</p>
<p>-od 参数</p>
<p>.&#x2F; 表示需要解压到哪里， .&#x2F; 的作用为：当前目录</p>
<p>HDFS分布式文件系统素材.zip 表示需要解压的文件</p>
<p>命令：unzip -od .&#x2F; HDFS分布式文件系统素材.zip</p>
<ol start="5">
<li>HDFS的上传命令</li>
</ol>
<p> 上传单个文件</p>
<p> 命令：hdfs dfs -put ~&#x2F;NumberData.csv[需要上传的文件路径] &#x2F;inpot[上传到HDFS 路径]</p>
<p> 多文件同时上传 </p>
<p>命令：hdfs dfs -put ~&#x2F;MI_StepCountData.csv ~&#x2F;inpot&#x2F;log</p>
<p>上传目录操作</p>
<p>命令：hdfs dfs -put ~&#x2F;inpot&#x2F; &#x2F;log</p>
<ol start="6">
<li>查看数据的相关内容</li>
</ol>
<p>-cat 查看文件的相关内容(全部)</p>
<p>命令：hdfs dfs -cat &#x2F;test&#x2F;User01.csv</p>
<p>-cat 查看文件的相关内容(全部)</p>
<p>命令：hdfs dfs -cat &#x2F;test&#x2F;User01.csv</p>
<p>如果想查看内容的后面N行数据</p>
<p>命令：hdfs dfs -cat &#x2F;test&#x2F;User01.csv | tail -5</p>
<p>如果我想知道当前文件的内容一共有多少行数据？ </p>
<p>添加管道符 | wc -l, wc -l 是3个单词组成：Word Count Lines </p>
<p>命令：hdfs dfs -cat &#x2F;test&#x2F;User01.csv | wc -l</p>
<ol start="7">
<li>查看文件大小和查找文件命令</li>
</ol>
<p> -du 查看指定目录每个文件的大小(单位为：字节(Byte)) </p>
<p>命令：hdfs dfs -du &#x2F;TemporaryData</p>
<p> -find 搜索相关文件， 在哪里搜索(路径) -name 搜索的文件名字 </p>
<p>命令：hdfs dfs -find &#x2F; -name U*</p>
<ol start="8">
<li>查看HDFS文件系统的磁盘使用情况</li>
</ol>
<p>命令：hdfs dfs -df</p>
<ol start="9">
<li>将HDFS中的数据下载到本地</li>
</ol>
<p>命令：hdfs dfs -get &#x2F;test&#x2F;User01.csv &#x2F;home&#x2F;yun&#x2F;MyData.csv</p>
<ol start="10">
<li>删除空目录</li>
</ol>
<p>命令：hdfs dfs -rmdir &#x2F;inpot&#x2F;log&#x2F;Log</p>
<ol start="11">
<li>删除文件和删除指定目录及其所有子目录与文件</li>
</ol>
<p>删除单个文件 </p>
<p>命令： hdfs dfs -rm &#x2F;test&#x2F;User01.csv Deleted &#x2F;test&#x2F;User01.csv </p>
<p> 删除目录及其子目录与文件 </p>
<p>命令：hdfs dfs -rm -r &#x2F;WriteOnlyDataSet Deleted &#x2F;WriteOnlyDataSet</p>
<h3 id="Scala基础"><a href="#Scala基础" class="headerlink" title="Scala基础"></a>Scala基础</h3><h4 id="一、scala类和对象"><a href="#一、scala类和对象" class="headerlink" title="一、scala类和对象"></a>一、scala类和对象</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.bjsxt.scala</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Scala:</span></span><br><span class="line"><span class="comment"> * 1.Scala object相当于Java中的单列。object中定义的全是静态的。相当于Java的工具类。 Object不可以传参，(对象要传参，使用apply方法)</span></span><br><span class="line"><span class="comment"> * 2.Scala 中定义变量使用var，定义常量使用val，变量可变，常量不可变，变量和常量类型可以省略不写，会自动推断。</span></span><br><span class="line"><span class="comment"> * 3.Scala 中每行后面都会有分号自动推断机制，不用显示写出“;”</span></span><br><span class="line"><span class="comment"> * 4.建议在Scala中命名使用驼峰命名法。</span></span><br><span class="line"><span class="comment"> * 5.Scala 类中可以传参，传参一定要指定类型，有了参数就有了默认了构造。类中的属性默认有getter和setter方法</span></span><br><span class="line"><span class="comment"> * 6.类中重新构造是，构造中第一行必须先调用默认的构造 def this(....)&#123;....&#125;</span></span><br><span class="line"><span class="comment"> * 7.Scala 中当new class 时，类中除了方法不执行【除了构造方法】其他都执行</span></span><br><span class="line"><span class="comment"> * 8.在同一个Scala文件中，class名称和Object名称一样时，这个类叫做这个对象的伴生类，这个对象叫做这个对象的伴生对象。他们之间可以相互访问私有变量</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">xname :<span class="type">String</span>, xage: <span class="type">Int</span></span>)</span>&#123;</span><br><span class="line">  <span class="keyword">val</span> name = xname</span><br><span class="line">  <span class="keyword">var</span> age = xage</span><br><span class="line">  <span class="keyword">var</span> gender = &#x27;<span class="type">M</span>&#x27;</span><br><span class="line"></span><br><span class="line">  println(<span class="string">&quot;***** Persion Class *****&quot;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">this</span></span>(yname:<span class="type">String</span>, yage:<span class="type">Int</span>, ygender:<span class="type">Char</span>)&#123;</span><br><span class="line">    <span class="keyword">this</span>(yname, yage)</span><br><span class="line">    <span class="keyword">this</span>.gender = ygender</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">sayName</span></span>():<span class="type">Unit</span> = &#123;</span><br><span class="line">    println(<span class="string">&quot;hello world....&quot;</span> + <span class="type">Lesson_ClassAndObj</span>.name)</span><br><span class="line">  &#125;</span><br><span class="line">  println(<span class="string">&quot;=======Persion Class======&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Lesson_ClassAndObj</span> </span>&#123;</span><br><span class="line">  println(<span class="string">&quot;#####Lesson_ClassAndObj######&quot;</span>)</span><br><span class="line">  <span class="keyword">val</span> name = <span class="string">&quot;wangwu&quot;</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args:<span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> p = <span class="keyword">new</span> <span class="type">Person</span>(xname = <span class="string">&quot;zhangsan&quot;</span>, xage = <span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//    println(p.gender)</span></span><br><span class="line"><span class="comment">//    val p1 = new Person(&quot;libai&quot;,18,&#x27;F&#x27;)</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//    println(p1.gender)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    p.age = 200</span></span><br><span class="line"><span class="comment">//    println(p.name)</span></span><br><span class="line"><span class="comment">//    println(p.age)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    p.sayName()</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//println(&quot;hello world&quot;)</span></span><br><span class="line"><span class="comment">//    val a = 100</span></span><br><span class="line">    <span class="comment">////    var b = 200</span></span><br><span class="line">    <span class="comment">////    b = 300</span></span><br><span class="line">    <span class="comment">////    println(b)</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="二、scala简单语法"><a href="#二、scala简单语法" class="headerlink" title="二、scala简单语法"></a>二、scala简单语法</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.bjsxt.scala</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">scala_字符串和集合01</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(array:<span class="type">Array</span>[<span class="type">String</span>]):<span class="type">Unit</span>=&#123;</span><br><span class="line">    <span class="keyword">val</span> s = <span class="string">&quot;bjsxt&quot;</span></span><br><span class="line">    <span class="keyword">val</span> s1 = <span class="string">&quot;BJSXT&quot;</span></span><br><span class="line"></span><br><span class="line">    println(s.indexOf(<span class="number">98</span>))    <span class="comment">// 97:a  65:A  返回下标 没有为-1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    println(s.equals(s1))</span></span><br><span class="line"><span class="comment">//    println(s.equalsIgnoreCase(s1))</span></span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="三、scala字符串-集合"><a href="#三、scala字符串-集合" class="headerlink" title="三、scala字符串&amp;集合"></a>三、scala字符串&amp;集合</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.bjsxt.scala</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">scala_字符串和集合02</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> arr = <span class="type">Array</span>[<span class="type">String</span>]( <span class="string">&quot;a&quot;</span>,<span class="string">&quot;b&quot;</span>,<span class="string">&quot;c&quot;</span>,<span class="string">&quot;d&quot;</span>)</span><br><span class="line"><span class="comment">//    arr.foreach(println)  //1.</span></span><br><span class="line"><span class="comment">//    arr.foreach(s=&gt;println(s))  //2.</span></span><br><span class="line"><span class="comment">//    for (i&lt;-arr)&#123;   //3.</span></span><br><span class="line"><span class="comment">//      println(i)</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    val arr1 = new Array[Int](3)</span></span><br><span class="line"><span class="comment">//    arr1(0) = 100</span></span><br><span class="line"><span class="comment">//    arr1(1) = 200</span></span><br><span class="line"><span class="comment">//    arr1(2) = 300</span></span><br><span class="line"><span class="comment">//    arr1.foreach(println)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    val array = new Array[Array[Int]](3)</span></span><br><span class="line"><span class="comment">//    array(0) = Array[Int](1,2,3)</span></span><br><span class="line"><span class="comment">//    array(1) = Array[Int](4,5,6)</span></span><br><span class="line"><span class="comment">//    array(2) = Array[Int](7,8,9)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//1.</span></span><br><span class="line"><span class="comment">//    for(i&lt;-array)&#123;</span></span><br><span class="line"><span class="comment">//      for(j&lt;-i)&#123;</span></span><br><span class="line"><span class="comment">//        println(j)</span></span><br><span class="line"><span class="comment">//      &#125;</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//2.</span></span><br><span class="line"><span class="comment">//    for (i&lt;-array; j&lt;-i)&#123;</span></span><br><span class="line"><span class="comment">//        println(j)</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//3.</span></span><br><span class="line"><span class="comment">//    array.foreach(arr=&gt;&#123;arr.foreach(println)&#125;)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//    val arr3 = Array[String](&quot;q&quot;,&quot;w&quot;,&quot;e&quot;,&quot;r&quot;)</span></span><br><span class="line"><span class="comment">//    val arr4 = Array[String](&quot;t&quot;,&quot;y&quot;,&quot;u&quot;)</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//    val arrays: Array[String] = Array.concat(arr3,arr4)</span></span><br><span class="line"><span class="comment">//    arrays.foreach(println)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    val array: Array[String] = Array.fill(5)(&quot;hello&quot;)</span></span><br><span class="line"><span class="comment">//    array.foreach(println)</span></span><br><span class="line">    </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.bjsxt.scala</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable.<span class="type">ArrayBuffer</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">scala_字符串和集合03</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> arr =<span class="type">ArrayBuffer</span>[<span class="type">Int</span>](<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">    arr.+=(<span class="number">4</span>)</span><br><span class="line">    arr.+=:(<span class="number">100</span>)</span><br><span class="line">    arr.append(<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>)</span><br><span class="line">    arr.foreach(println)</span><br><span class="line"></span><br><span class="line"><span class="comment">//    import scala.collection.mutable.ArrayBuffer</span></span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.bjsxt.scala</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">scala_字符串和集合04</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"><span class="comment">//    val list = List[Int](1,2,3)</span></span><br><span class="line"><span class="comment">//    list.foreach(println)  //1.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    for(i &lt;- list)&#123;    //2.</span></span><br><span class="line"><span class="comment">//      println(i)</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> list = <span class="type">List</span>[<span class="type">String</span>](<span class="string">&quot;hello scala&quot;</span>,<span class="string">&quot;hello java&quot;</span>,<span class="string">&quot;hello python&quot;</span>)</span><br><span class="line">    list.map()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="四、scala循环"><a href="#四、scala循环" class="headerlink" title="四、scala循环"></a>四、scala循环</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.bjsxt.scala</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">scala_循环</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args:<span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">  * if...else...</span></span><br><span class="line"><span class="comment">  * */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    val age = 88</span></span><br><span class="line"><span class="comment">//    if(age&lt;=20)&#123;</span></span><br><span class="line"><span class="comment">//      println(&quot;age&lt;20&quot;)</span></span><br><span class="line"><span class="comment">//    &#125;else if(age&gt;20&amp;&amp;age&lt;=30)&#123;</span></span><br><span class="line"><span class="comment">//      println(&quot;20&lt;age&lt;=30&quot;)</span></span><br><span class="line"><span class="comment">//    &#125;else&#123;</span></span><br><span class="line"><span class="comment">//      println(&quot;age&gt;30&quot;)</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">  * for</span></span><br><span class="line"><span class="comment">  * */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1 to (10, 2)</span></span><br><span class="line">    <span class="keyword">val</span> r = <span class="number">1.</span>to(<span class="number">10</span>,<span class="number">2</span>)</span><br><span class="line">    println(r)</span><br><span class="line"><span class="comment">//    // 1 until 10</span></span><br><span class="line"><span class="comment">//    val r1 = 1 until 10</span></span><br><span class="line"><span class="comment">//    println(r1)</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//    for (i &lt;- 1.to(10,2))&#123;</span></span><br><span class="line"><span class="comment">//      println(i)</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 小九九</span></span><br><span class="line"><span class="comment">//    for (i &lt;- 1 until 10)&#123;</span></span><br><span class="line"><span class="comment">//      for(j &lt;- 1 until 10)&#123;</span></span><br><span class="line"><span class="comment">//        if(i&gt;=j)&#123;</span></span><br><span class="line"><span class="comment">//          print(i+&quot;*&quot;+j+&quot;=&quot;+i*j+&quot;\t&quot;)</span></span><br><span class="line"><span class="comment">//        &#125;</span></span><br><span class="line"><span class="comment">//        if(i==j)&#123;</span></span><br><span class="line"><span class="comment">//          println()</span></span><br><span class="line"><span class="comment">//        &#125;</span></span><br><span class="line"><span class="comment">//      &#125;</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    for(i &lt;- 1 until 10; j &lt;- 1 until 10)&#123;</span></span><br><span class="line"><span class="comment">//      if(i&gt;=j)&#123;</span></span><br><span class="line"><span class="comment">//        print(i+&quot;*&quot;+j+&quot;=&quot;+i*j+&quot;\t&quot;)</span></span><br><span class="line"><span class="comment">//      &#125;</span></span><br><span class="line"><span class="comment">//      if(i==j)&#123;</span></span><br><span class="line"><span class="comment">//        println()</span></span><br><span class="line"><span class="comment">//      &#125;</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    for(i &lt;- 1 to 100; if(i &gt; 50); if(i%5==0))&#123;</span></span><br><span class="line"><span class="comment">//      println(i)</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    val result = for(i &lt;- 1 to 100; if(i &gt; 50); if(i%5==0)) yield i</span></span><br><span class="line"><span class="comment">//    println(result)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">  * while</span></span><br><span class="line"><span class="comment">  * do...while...</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"><span class="comment">//    var i = 0</span></span><br><span class="line"><span class="comment">//    while(i&lt;10)&#123;</span></span><br><span class="line"><span class="comment">//      println(s&quot;第 $i 次求婚。。。。&quot;)</span></span><br><span class="line"><span class="comment">//      i += 1</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> y = <span class="number">0</span></span><br><span class="line">    <span class="keyword">do</span>&#123;</span><br><span class="line">      println(<span class="string">&quot;第&quot;</span>+y+<span class="string">&quot;次求婚！！！！&quot;</span>)</span><br><span class="line">      y += <span class="number">1</span></span><br><span class="line">    &#125;<span class="keyword">while</span>(y&lt;<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="五、scala方法的定义"><a href="#五、scala方法的定义" class="headerlink" title="五、scala方法的定义"></a>五、scala方法的定义</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.bjsxt.scala</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">scala_方法的定义</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1.方法定义：</span></span><br><span class="line"><span class="comment">     *  1).方法体中最后返回值可以使用return,如果使用了return,那么方法体的返回值类型一定要指定</span></span><br><span class="line"><span class="comment">     *  2).如果方法体中没有return,默认将方法体中最后一行计算的结果当做返回值返回。方法体的返回值类型可以省略，会自动推断返回值类型</span></span><br><span class="line"><span class="comment">     *  3).定义方法传入的参数一定要指定类型</span></span><br><span class="line"><span class="comment">     *  4).方法的方法体如果可以一行搞定，那么方法的”&#123;...&#125;“可以省略</span></span><br><span class="line"><span class="comment">     *  5).如果定义方法时，省略了方法名称和方法体之间的”=“，那么无论方法体最后一行计算的结果是什么，都会被丢弃，返回Unit</span></span><br><span class="line"><span class="comment">     *  6).def 定义方法</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    def max(a:Int, b:Int): Int = &#123;</span></span><br><span class="line"><span class="comment">//      if(a&gt;b)&#123;</span></span><br><span class="line"><span class="comment">//         return a</span></span><br><span class="line"><span class="comment">//      &#125;else&#123;</span></span><br><span class="line"><span class="comment">//         return b</span></span><br><span class="line"><span class="comment">//      &#125;</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max</span></span>(a:<span class="type">Int</span>, b:<span class="type">Int</span>): <span class="type">Int</span> = <span class="keyword">if</span>(a&gt;b) a <span class="keyword">else</span> b</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> result: <span class="type">Int</span> = max(<span class="number">100</span>, <span class="number">20</span>)</span><br><span class="line">    println(result)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="六、scala递归"><a href="#六、scala递归" class="headerlink" title="六、scala递归"></a>六、scala递归</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.bjsxt.scala</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.<span class="type">Date</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">scala_递归方法</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(array: <span class="type">Array</span>[<span class="type">String</span>]) : <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 1.递归方法</span></span><br><span class="line"><span class="comment">   *  递归方法要显示的声明函数的返回值类型</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    def fun(num:Int):Int=&#123;</span></span><br><span class="line"><span class="comment">//      if(num==1)&#123;</span></span><br><span class="line"><span class="comment">//        1</span></span><br><span class="line"><span class="comment">//      &#125;else&#123;</span></span><br><span class="line"><span class="comment">//        num*fun(num-1)</span></span><br><span class="line"><span class="comment">//      &#125;</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"><span class="comment">//    println(fun(5))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 2.参数有默认值得方法</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    def fun(a:Int=10,b:Int=20)=&#123;</span></span><br><span class="line"><span class="comment">//      a+b</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">////    println(fun(100,200))</span></span><br><span class="line"><span class="comment">////    println(fun(100))</span></span><br><span class="line"><span class="comment">//    println(fun(b=100))</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 3.可变长参数的方法</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"><span class="comment">//    def fun(s:String*)=&#123;</span></span><br><span class="line"><span class="comment">//      // =&gt; 匿名函数</span></span><br><span class="line"><span class="comment">//      s.foreach(i=&gt;&#123;println(i)&#125;)</span></span><br><span class="line"><span class="comment">////      for(i&lt;-s)&#123;</span></span><br><span class="line"><span class="comment">////        println(i)</span></span><br><span class="line"><span class="comment">////      &#125;</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    def fun(s:String*)=&#123;</span></span><br><span class="line"><span class="comment">//      s.foreach(println)</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//    fun(&quot;hello&quot;,&quot;a&quot;,&quot;b&quot;,&quot;c&quot;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/***</span></span><br><span class="line"><span class="comment">     * 4.匿名函数</span></span><br><span class="line"><span class="comment">     * ”=&gt;“ 就是匿名函数，多用于方法的参数是函数时，常用匿名函数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    def fun1(a:Int,b:Int)=&#123;</span></span><br><span class="line"><span class="comment">//      a+b</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    def fun = (a:Int,b:Int)=&gt;&#123;</span></span><br><span class="line"><span class="comment">//      a+b</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"><span class="comment">//    println(fun(2,3))</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 5.嵌套方法</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"><span class="comment">//    def fun(num:Int)=&#123;</span></span><br><span class="line"><span class="comment">//      def fun1(a:Int):Int=&#123;</span></span><br><span class="line"><span class="comment">//        if(a==1)&#123;</span></span><br><span class="line"><span class="comment">//          1</span></span><br><span class="line"><span class="comment">//        &#125;else&#123;</span></span><br><span class="line"><span class="comment">//          a*fun1(a-1)</span></span><br><span class="line"><span class="comment">//        &#125;</span></span><br><span class="line"><span class="comment">//      &#125;</span></span><br><span class="line"><span class="comment">//      fun1(num)</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"><span class="comment">//    println(fun(5))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 6.偏应用函数</span></span><br><span class="line"><span class="comment">   *  某些情况下，方法中参数非常多，调用这个方法非常频繁，每次条用只有固定的某个变化，可以定义偏应用来实现</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"><span class="comment">//    def showLog(date:Date,log:String)=&#123;</span></span><br><span class="line"><span class="comment">//      println(s&quot;date is $date   , log is $log&quot;)</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"><span class="comment">//    val date = new Date()</span></span><br><span class="line"><span class="comment">//    showLog(date, &quot;a&quot;)</span></span><br><span class="line"><span class="comment">//    showLog(date, &quot;b&quot;)</span></span><br><span class="line"><span class="comment">//    showLog(date, &quot;c&quot;)</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//    def fun = showLog(date,_:String)</span></span><br><span class="line"><span class="comment">//    fun(&quot;aaa&quot;)</span></span><br><span class="line"><span class="comment">//    fun(&quot;bbb&quot;)</span></span><br><span class="line"><span class="comment">//    fun(&quot;ccc&quot;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 7.高阶函数</span></span><br><span class="line"><span class="comment">     *  1).方法的参数是函数</span></span><br><span class="line"><span class="comment">     *  2).方法的返回是函数  &lt;必须要显示的写出方法的返回值类型&gt;,加 _ 就可以不显示的声明方法的返回值类型</span></span><br><span class="line"><span class="comment">     *  3).方法的参数和返回都是函数</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//1.方法的参数是函数</span></span><br><span class="line"><span class="comment">//    def fun(a:Int,b:Int):Int=&#123;</span></span><br><span class="line"><span class="comment">//      a+b</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//    def fun1(f:(Int,Int)=&gt;Int,s:String)=&#123;</span></span><br><span class="line"><span class="comment">//      val i: Int = f(100,200)</span></span><br><span class="line"><span class="comment">//      i+&quot;#&quot;+s</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"><span class="comment">//    val result = fun1(fun,&quot;scala&quot;)</span></span><br><span class="line"><span class="comment">//    println(result)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//    def fun1(f:(Int,Int)=&gt;Int,s:String)=&#123;</span></span><br><span class="line"><span class="comment">//      val i: Int = f(100,200)</span></span><br><span class="line"><span class="comment">//      i+&quot;#&quot;+s</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"><span class="comment">//    val result = fun1((a:Int,b:Int)=&gt;&#123;a*b&#125;,&quot;scala&quot;)</span></span><br><span class="line"><span class="comment">//    println(result)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2.方法的返回是函数</span></span><br><span class="line"><span class="comment">//    def fun(s:String):(String,String)=&gt;String = &#123;</span></span><br><span class="line"><span class="comment">//      def fun1(s1:String, s2:String): String= &#123;</span></span><br><span class="line"><span class="comment">//        s1 + &quot;&amp;&quot;+s2+&quot;#&quot;+s</span></span><br><span class="line"><span class="comment">//      &#125;</span></span><br><span class="line"><span class="comment">//      fun1</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"><span class="comment">//    println(fun(&quot;a&quot;)(&quot;b&quot;,&quot;c&quot;))</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">//3.方法的参数和返回值都是函数</span></span><br><span class="line"><span class="comment">//    def fun(f:(Int,Int)=&gt;Int):(String,String)=&gt;String = &#123;</span></span><br><span class="line"><span class="comment">//      val i: Int = f(1,2)</span></span><br><span class="line"><span class="comment">//      def fun1(s1:String,s2:String):String = &#123;</span></span><br><span class="line"><span class="comment">//        s1+&quot;@&quot;+s2+&quot;*&quot;+i</span></span><br><span class="line"><span class="comment">//      &#125;</span></span><br><span class="line"><span class="comment">//      fun1</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"><span class="comment">//    println(fun((a,b)=&gt;&#123;a+b&#125;)(&quot;hello&quot;,&quot;world&quot;))</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 8.柯里化函数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"><span class="comment">//    def fun(a:Int,b:Int)(c:Int,d:Int)=&#123;</span></span><br><span class="line"><span class="comment">//      a+b+c+d</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"><span class="comment">//    println(fun(1,2)(3,4))</span></span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="七、字符串-集合"><a href="#七、字符串-集合" class="headerlink" title="七、字符串&amp;集合"></a>七、字符串&amp;集合</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.bjsxt.scala</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">scala_字符串和集合01</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(array:<span class="type">Array</span>[<span class="type">String</span>]):<span class="type">Unit</span>=&#123;</span><br><span class="line">    <span class="keyword">val</span> s = <span class="string">&quot;bjsxt&quot;</span></span><br><span class="line">    <span class="keyword">val</span> s1 = <span class="string">&quot;BJSXT&quot;</span></span><br><span class="line"></span><br><span class="line">    println(s.indexOf(<span class="number">98</span>))    <span class="comment">// 97:a  65:A  返回下标 没有为-1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    println(s.equals(s1))</span></span><br><span class="line"><span class="comment">//    println(s.equalsIgnoreCase(s1))</span></span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.bjsxt.scala</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">scala_字符串和集合02</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> arr = <span class="type">Array</span>[<span class="type">String</span>]( <span class="string">&quot;a&quot;</span>,<span class="string">&quot;b&quot;</span>,<span class="string">&quot;c&quot;</span>,<span class="string">&quot;d&quot;</span>)</span><br><span class="line"><span class="comment">//    arr.foreach(println)  //1.</span></span><br><span class="line"><span class="comment">//    arr.foreach(s=&gt;println(s))  //2.</span></span><br><span class="line"><span class="comment">//    for (i&lt;-arr)&#123;   //3.</span></span><br><span class="line"><span class="comment">//      println(i)</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    val arr1 = new Array[Int](3)</span></span><br><span class="line"><span class="comment">//    arr1(0) = 100</span></span><br><span class="line"><span class="comment">//    arr1(1) = 200</span></span><br><span class="line"><span class="comment">//    arr1(2) = 300</span></span><br><span class="line"><span class="comment">//    arr1.foreach(println)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    val array = new Array[Array[Int]](3)</span></span><br><span class="line"><span class="comment">//    array(0) = Array[Int](1,2,3)</span></span><br><span class="line"><span class="comment">//    array(1) = Array[Int](4,5,6)</span></span><br><span class="line"><span class="comment">//    array(2) = Array[Int](7,8,9)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//1.</span></span><br><span class="line"><span class="comment">//    for(i&lt;-array)&#123;</span></span><br><span class="line"><span class="comment">//      for(j&lt;-i)&#123;</span></span><br><span class="line"><span class="comment">//        println(j)</span></span><br><span class="line"><span class="comment">//      &#125;</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//2.</span></span><br><span class="line"><span class="comment">//    for (i&lt;-array; j&lt;-i)&#123;</span></span><br><span class="line"><span class="comment">//        println(j)</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//3.</span></span><br><span class="line"><span class="comment">//    array.foreach(arr=&gt;&#123;arr.foreach(println)&#125;)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//    val arr3 = Array[String](&quot;q&quot;,&quot;w&quot;,&quot;e&quot;,&quot;r&quot;)</span></span><br><span class="line"><span class="comment">//    val arr4 = Array[String](&quot;t&quot;,&quot;y&quot;,&quot;u&quot;)</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//    val arrays: Array[String] = Array.concat(arr3,arr4)</span></span><br><span class="line"><span class="comment">//    arrays.foreach(println)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    val array: Array[String] = Array.fill(5)(&quot;hello&quot;)</span></span><br><span class="line"><span class="comment">//    array.foreach(println)</span></span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.bjsxt.scala</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable.<span class="type">ArrayBuffer</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">scala_字符串和集合03</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> arr =<span class="type">ArrayBuffer</span>[<span class="type">Int</span>](<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">    arr.+=(<span class="number">4</span>)</span><br><span class="line">    arr.+=:(<span class="number">100</span>)</span><br><span class="line">    arr.append(<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>)</span><br><span class="line">    arr.foreach(println)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//    import scala.collection.mutable.ArrayBuffer</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><strong>List</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.bjsxt.scala</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable.<span class="type">ListBuffer</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">scala_List</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"><span class="comment">//    val list = List[Int](1,2,3)</span></span><br><span class="line"><span class="comment">//    list.foreach(println)  //1.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    for(i &lt;- list)&#123;    //2.</span></span><br><span class="line"><span class="comment">//      println(i)</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    val list = List[String](&quot;hello scala&quot;, &quot;hello java&quot;, &quot;hello python&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    val result: List[Array[String]] = list.map(s =&gt; &#123;</span></span><br><span class="line"><span class="comment">//      s.split(&quot; &quot;)</span></span><br><span class="line"><span class="comment">//    &#125;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    val i: Int = list.count(s=&gt; &#123;</span></span><br><span class="line"><span class="comment">//      s.length &lt; 4</span></span><br><span class="line"><span class="comment">//    &#125;)</span></span><br><span class="line"><span class="comment">//    println(i)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//    val result: List[String] = list.flatMap(s=&gt;(s.split(&quot;  &quot;)))</span></span><br><span class="line"><span class="comment">//    result.foreach(println)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    result.foreach(arr =&gt; &#123;</span></span><br><span class="line"><span class="comment">//      println(&quot;新的数组&quot;)</span></span><br><span class="line"><span class="comment">//      arr.foreach(println)</span></span><br><span class="line"><span class="comment">//    &#125;)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> list = <span class="type">ListBuffer</span>[<span class="type">Int</span>](<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">    list.append(<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>)  <span class="comment">// 追加</span></span><br><span class="line">    list.+=:(<span class="number">100</span>)   <span class="comment">// 加到头部</span></span><br><span class="line">    list.foreach(println)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><strong>Set</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.bjsxt.scala</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable.<span class="type">Set</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">scala_Set</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"><span class="comment">//    val set = Set[Int](1,2,3,4)</span></span><br><span class="line"><span class="comment">//    val set1 = Set[Int](3,4,5,6,7)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    val result: Set[Int] = set.intersect(set1)  // 取相交的</span></span><br><span class="line"><span class="comment">//    result.foreach(println)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    val result: Set[Int] = set1.diff(set)   // 取相差的</span></span><br><span class="line"><span class="comment">//    result.foreach(println)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    val result = set &amp; set1</span></span><br><span class="line"><span class="comment">//    result.foreach(println)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    val result = set &amp; set1</span></span><br><span class="line"><span class="comment">//    result.foreach(println)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    val ints: Set[Int] = set.filter(i =&gt; &#123;</span></span><br><span class="line"><span class="comment">//      i &gt;= 2</span></span><br><span class="line"><span class="comment">//    &#125;)</span></span><br><span class="line"><span class="comment">//    ints.foreach(println)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 遍历1</span></span><br><span class="line"><span class="comment">//    for(i&lt;-set)&#123;</span></span><br><span class="line"><span class="comment">//      println(i)</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line">    <span class="comment">// 遍历2</span></span><br><span class="line"><span class="comment">//    set.foreach(println)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 可变长的set</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> set = <span class="type">Set</span>[<span class="type">Int</span>](<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="comment">//    val ints: mutable.Set[Int] = set.+=(100)</span></span><br><span class="line">    set.+=(<span class="number">100</span>)</span><br><span class="line">    set.foreach(println)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> scala.collection.immutable</span><br><span class="line">    <span class="keyword">val</span> set1 = <span class="type">Set</span>[<span class="type">String</span>](<span class="string">&quot;a&quot;</span>,<span class="string">&quot;b&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><strong>Map</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.bjsxt.scala</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">scala_Map</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 不可变map</span></span><br><span class="line"><span class="comment">     * */</span></span><br><span class="line"><span class="comment">//    val map = Map[String,Int](&quot;a&quot;-&gt;100,&quot;b&quot;-&gt;200,(&quot;c&quot;,300),(&quot;c&quot;,400))  // 会去重</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    val x: Option[Int] = map.get(&quot;a&quot;)</span></span><br><span class="line"><span class="comment">//    println(x)</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//    val y: Int = map.get(&quot;b&quot;).get</span></span><br><span class="line"><span class="comment">//    println(y)</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//    val z = map.get(&quot;aa&quot;).getOrElse(&quot;没有对应的值&quot;)</span></span><br><span class="line"><span class="comment">//    println(z)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    val keys: Iterable[String] = map.keys</span></span><br><span class="line"><span class="comment">//    keys.foreach(key=&gt;&#123;</span></span><br><span class="line"><span class="comment">//      val value = map.get(key).get</span></span><br><span class="line"><span class="comment">//      println(s&quot;key= $key, value = $value&quot;)</span></span><br><span class="line"><span class="comment">//    &#125;)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//    val values: Iterable[Int] = map.values</span></span><br><span class="line"><span class="comment">//    values.foreach(println)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//    println(map)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 遍历1</span></span><br><span class="line"><span class="comment">//    map.foreach(println)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 遍历2</span></span><br><span class="line"><span class="comment">//    for (i &lt;- map)&#123;</span></span><br><span class="line"><span class="comment">//      println(i)</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//    val map1 = Map[String,Int]((&quot;a&quot;,1),(&quot;b&quot;,2),(&quot;c&quot;,3),(&quot;d&quot;,4))</span></span><br><span class="line"><span class="comment">//    val map2= Map[String,Int]((&quot;a&quot;,100),(&quot;b&quot;,2),(&quot;c&quot;,300),(&quot;e&quot;,500))</span></span><br><span class="line"><span class="comment">//    val x: Map[String, Int] = map1.++(map2)  //map2替换map1</span></span><br><span class="line"><span class="comment">//    x.foreach(println)</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//    println(&quot;==================&quot;)</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//    val y: Map[String, Int] = map1.++:(map2)  //map1替换map2</span></span><br><span class="line"><span class="comment">//    y.foreach(println)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 可变map</span></span><br><span class="line"><span class="comment">     * */</span></span><br><span class="line">    <span class="keyword">import</span> scala.collection.mutable.<span class="type">Map</span></span><br><span class="line">    <span class="keyword">val</span> map = <span class="type">Map</span>[<span class="type">String</span>,<span class="type">Int</span>]()</span><br><span class="line">    map.put(<span class="string">&quot;a&quot;</span>,<span class="number">100</span>)</span><br><span class="line">    map.put(<span class="string">&quot;b&quot;</span>,<span class="number">200</span>)</span><br><span class="line"><span class="comment">//    map.foreach(println)</span></span><br><span class="line">    <span class="keyword">val</span> result: mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>] = map.filter(tp=&gt;&#123;</span><br><span class="line">      <span class="keyword">val</span> key = tp._1</span><br><span class="line">      <span class="keyword">val</span> value = tp._2</span><br><span class="line">      value == <span class="number">200</span></span><br><span class="line">    &#125;)</span><br><span class="line">    result.foreach(println)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><strong>Tuple_元组</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.bjsxt.scala</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 元组最多支持22个元素</span></span><br><span class="line"><span class="comment">     * */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">scala_Tuple_元组</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> tuple1: <span class="type">Tuple1</span>[<span class="type">String</span>] = <span class="keyword">new</span> <span class="type">Tuple1</span>(<span class="string">&quot;hello&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> tuple2: (<span class="type">String</span>, <span class="type">Int</span>) = <span class="keyword">new</span> <span class="type">Tuple2</span>(<span class="string">&quot;a&quot;</span>,<span class="number">100</span>)</span><br><span class="line">    <span class="keyword">val</span> tuple3: (<span class="type">Int</span>, <span class="type">Boolean</span>, <span class="type">Char</span>) = <span class="keyword">new</span> <span class="type">Tuple3</span>(<span class="number">1</span>,<span class="literal">true</span>,&#x27;<span class="type">C</span>&#x27;)</span><br><span class="line">    <span class="keyword">val</span> tuple4: (<span class="type">Int</span>, <span class="type">Double</span>, <span class="type">String</span>, <span class="type">Boolean</span>) = <span class="keyword">new</span> <span class="type">Tuple4</span>(<span class="number">1</span>,<span class="number">3.4</span>,<span class="string">&quot;abc&quot;</span>,<span class="literal">false</span>)</span><br><span class="line">    <span class="keyword">val</span> tuple6: (<span class="type">Int</span>,<span class="type">Int</span>,<span class="type">Int</span>,<span class="type">Int</span>,<span class="type">Int</span>,<span class="type">String</span>) = (<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="string">&quot;abc&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> tuple22 = (<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>,<span class="number">12</span>,<span class="string">&quot;abc&quot;</span>,<span class="number">14</span>,<span class="number">15</span>,<span class="number">16</span>,<span class="number">17</span>,<span class="number">18</span>,<span class="number">19</span>,<span class="number">20</span>,<span class="number">21</span>,<span class="number">22</span>)</span><br><span class="line">    <span class="keyword">val</span> x: <span class="type">String</span> = tuple22._13</span><br><span class="line"><span class="comment">//    println(x)</span></span><br><span class="line"></span><br><span class="line">    println(tuple2.swap)  <span class="comment">//反转 只有tuple2有</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    println(tuple4)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//    val iter: Iterator[Any] = tuple6.productIterator</span></span><br><span class="line"><span class="comment">////    iter.foreach(println)  // 1</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">////    while (iter.hasNext)&#123;  // 2</span></span><br><span class="line"><span class="comment">////      println(iter.next())</span></span><br><span class="line"><span class="comment">////    &#125;</span></span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><strong>Trait</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.bjsxt.scala</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 一个继承多个trait时，第一个关键字使用extends，之后使用with</span></span><br><span class="line"><span class="comment"> * trait 不可以传参</span></span><br><span class="line"><span class="comment"> * */</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">Read</span></span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">read</span></span>(name:<span class="type">String</span>)=&#123;</span><br><span class="line">    println(<span class="string">s&quot;<span class="subst">$name</span> is reading...&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">Listen</span></span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">listen</span></span>(name:<span class="type">String</span>) =&#123;</span><br><span class="line">    println(<span class="string">s&quot;<span class="subst">$name</span> is listening...&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 继承 第一个用extends，后面的都用with</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Human</span>(<span class="params"></span>) <span class="keyword">extends</span> <span class="title">Read</span> <span class="keyword">with</span> <span class="title">Listen</span></span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">scala_Trait1</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> h = <span class="keyword">new</span> <span class="type">Human</span>()</span><br><span class="line">    h.read(<span class="string">&quot;张三&quot;</span>)</span><br><span class="line">    h.listen(<span class="string">&quot;李四&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.bjsxt.scala</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Trait中可以有方法体的实现或者方法体的不实现，类继承了Trait要实现Trait中没有实现的发放</span></span><br><span class="line"><span class="comment"> * */</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">IsEquale</span></span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">isEqu</span></span>(o:<span class="type">Any</span>):<span class="type">Boolean</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">isNotEqu</span></span>(o:<span class="type">Any</span>):<span class="type">Boolean</span> = !isEqu(o)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Point</span>(<span class="params">xx:<span class="type">Int</span>,xy:<span class="type">Int</span></span>) <span class="keyword">extends</span> <span class="title">IsEquale</span> </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> x = xx</span><br><span class="line">  <span class="keyword">val</span> y = xy</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">isEqu</span></span>(o: <span class="type">Any</span>): <span class="type">Boolean</span> = &#123;</span><br><span class="line">    o.isInstanceOf[<span class="type">Point</span>] &amp;&amp; o.asInstanceOf[<span class="type">Point</span>].x==<span class="keyword">this</span>.x</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">scala_Trait2</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> p1 = <span class="keyword">new</span> <span class="type">Point</span>(xx = <span class="number">1</span>, xy = <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">val</span> p2 = <span class="keyword">new</span> <span class="type">Point</span>(xx = <span class="number">1</span>, xy = <span class="number">3</span>)</span><br><span class="line"><span class="comment">//    println(p1.isEqu(p2))</span></span><br><span class="line">    println(p1.isNotEqu(p2))</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><strong>Match模式匹配</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.bjsxt.scala</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Match 模式匹配</span></span><br><span class="line"><span class="comment"> *  1. case _ 什么都匹配不上匹配，放在最后</span></span><br><span class="line"><span class="comment"> *  2. match 可以匹配值还可以批判类型</span></span><br><span class="line"><span class="comment"> *  3. 匹配过程中会有数值的转换</span></span><br><span class="line"><span class="comment"> *  4. 从上往下匹配，匹配之后会自动终止</span></span><br><span class="line"><span class="comment"> *  5.模式匹配外部的“&#123;...&#125;”可以省略</span></span><br><span class="line"><span class="comment"> * */</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">scala_Match模式匹配</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">   <span class="keyword">val</span> tp = (<span class="number">1</span>,<span class="number">1.2</span>,<span class="string">&quot;abc&quot;</span>,&#x27;a&#x27;,<span class="literal">true</span>)</span><br><span class="line">    <span class="keyword">val</span> iter: <span class="type">Iterator</span>[<span class="type">Any</span>] = tp.productIterator</span><br><span class="line">    iter.foreach(<span class="type">MatchTest</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">MatchTest</span></span>(o:<span class="type">Any</span>) =&#123;</span><br><span class="line">      o <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="number">1</span>=&gt; println(<span class="string">&quot;value is 1&quot;</span>)</span><br><span class="line">        <span class="keyword">case</span> i:<span class="type">Int</span> =&gt; println(<span class="string">s&quot;type is Int, value = <span class="subst">$i</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">case</span> d:<span class="type">Double</span> =&gt; println(<span class="string">s&quot;type is Int, value = <span class="subst">$d</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">case</span> s:<span class="type">String</span>=&gt; println(<span class="string">s&quot;type is Int, value = <span class="subst">$s</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">case</span> &#x27;a&#x27; =&gt; println(<span class="string">&quot;value is c&quot;</span>)</span><br><span class="line">        <span class="keyword">case</span> _=&gt; &#123;println(<span class="string">&quot;no match...&quot;</span>)&#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><strong>PartiaFun模式匹配_偏函数</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.bjsxt.scala</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 偏函数，只能匹配一个值，匹配上了放回某个值</span></span><br><span class="line"><span class="comment"> * PartialFunction[A,B] A是匹配的类型，B是匹配上返回的类型</span></span><br><span class="line"><span class="comment"> * */</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">scala_PartiaFun模式匹配_偏函数</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">MyTest</span></span>: <span class="type">PartialFunction</span>[<span class="type">String</span>,<span class="type">Int</span>] =&#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&quot;abc&quot;</span>=&gt;<span class="number">2</span></span><br><span class="line">    <span class="keyword">case</span> <span class="string">&quot;a&quot;</span>=&gt;<span class="number">1</span></span><br><span class="line">    <span class="keyword">case</span> <span class="string">&quot;b&quot;</span>=&gt;<span class="number">2</span></span><br><span class="line">    <span class="keyword">case</span> _=&gt;<span class="number">200</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"><span class="comment">//    val result: Int = MyTest(&quot;abc&quot;)</span></span><br><span class="line"><span class="comment">//    println(result)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> result: <span class="type">Int</span> = <span class="type">MyTest</span>(<span class="string">&quot;abcb&quot;</span>)</span><br><span class="line">    println(result)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><strong>CaseClass_样例类</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.bjsxt.scala</span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Personl</span>(<span class="params">var name:<span class="type">String</span>, age:<span class="type">Int</span></span>)</span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">scala_CaseClass_样例类</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> p1 = <span class="keyword">new</span> <span class="type">Personl</span>(<span class="string">&quot;张三&quot;</span>,<span class="number">18</span>)</span><br><span class="line">    <span class="keyword">val</span> p2 = <span class="keyword">new</span> <span class="type">Personl</span>(<span class="string">&quot;张三&quot;</span>,<span class="number">18</span>)</span><br><span class="line">    println(p1.equals(p2))</span><br><span class="line">    println(p1)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="八、隐式转换"><a href="#八、隐式转换" class="headerlink" title="八、隐式转换"></a>八、隐式转换</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.bjsxt.scala</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">scala_ImlicitTrans_隐式函数</span> </span>&#123;</span><br><span class="line"><span class="comment">//  def sayName(implicit name:String)=&#123;</span></span><br><span class="line"><span class="comment">//    println(s&quot;$name is a student....&quot;)</span></span><br><span class="line"><span class="comment">//  &#125;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sayName</span></span>(age:<span class="type">Int</span>)(<span class="keyword">implicit</span> name:<span class="type">String</span>)=&#123;</span><br><span class="line">      println(<span class="string">s&quot;<span class="subst">$name</span> is a student, age = <span class="subst">$age</span>....&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">implicit</span> <span class="keyword">val</span> name:<span class="type">String</span> = <span class="string">&quot;张三&quot;</span></span><br><span class="line"><span class="comment">//    sayName(&quot;李四&quot;)</span></span><br><span class="line"><span class="comment">//    sayName</span></span><br><span class="line"></span><br><span class="line">    sayName(<span class="number">18</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.bjsxt.scala</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Animal</span>(<span class="params">name:<span class="type">String</span></span>)</span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">canFiy</span></span>()=&#123;</span><br><span class="line">    println(<span class="string">s&quot;<span class="subst">$name</span> can fly...&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Rabbit</span>(<span class="params">xname:<span class="type">String</span></span>)</span>&#123;</span><br><span class="line">  <span class="keyword">val</span> name = xname</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">scala_ImlicitTrans_隐式函数1</span> </span>&#123;</span><br><span class="line">  <span class="keyword">implicit</span> <span class="function"><span class="keyword">def</span> <span class="title">RabbitToAnimal</span></span>(r:<span class="type">Rabbit</span>):<span class="type">Animal</span> =&#123;</span><br><span class="line">    <span class="keyword">new</span> <span class="type">Animal</span>(r.name)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">//  implicit def RTOA(r:Rabbit):Animal =&#123;  // 不能出现相同类型</span></span><br><span class="line">  <span class="comment">//    new Animal(r.name)</span></span><br><span class="line">  <span class="comment">//  &#125;</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> rabbit = <span class="keyword">new</span> <span class="type">Rabbit</span>(<span class="string">&quot;rabbit&quot;</span>)</span><br><span class="line">    rabbit.canFly()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.bjsxt.scala</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Rabbit1</span>(<span class="params">xname:<span class="type">String</span></span>)</span>&#123;</span><br><span class="line">  <span class="keyword">val</span> name = xname</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">scala_ImlicitTrans_隐式函数2</span> </span>&#123;</span><br><span class="line">  <span class="keyword">implicit</span> <span class="class"><span class="keyword">class</span> <span class="title">Animal1</span>(<span class="params">r:<span class="type">Rabbit1</span></span>) </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">showName</span></span>()=&#123;</span><br><span class="line">      println(<span class="string">s&quot;<span class="subst">$&#123;r.name&#125;</span> is Rabbit ...&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> rabbit = <span class="keyword">new</span> <span class="type">Rabbit1</span>(<span class="string">&quot;RABBIT&quot;</span>)</span><br><span class="line">    rabbit.showName()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="九、复习"><a href="#九、复习" class="headerlink" title="九、复习"></a>九、复习</h4><p><strong>Scala是基于JVM的语言。</strong></p>
<p><strong>六大特征：</strong></p>
<ol>
<li>与java无缝整合</li>
<li>类型推断</li>
<li>支持分别是和并发Actor</li>
<li>Trait特质特性</li>
<li>模式匹配match</li>
<li>高阶函数</li>
</ol>
<p><strong>类和对象</strong></p>
<ul>
<li>当new类时，类中除了方法不执行其它都执行</li>
<li>object相当于java中的单列，定义的都是静态的</li>
<li>class可以传参，传参就有默认的构造</li>
<li>重写构造时，第一行要先调用默认的构造</li>
<li>object 不可以传参，apply()方法</li>
<li>伴生类和伴生对象</li>
<li>for……<ol>
<li>1 to 10</li>
<li>1 until 10</li>
<li>for(i&lt;- 1 to 10)</li>
</ol>
</li>
<li>while…..    do … while…<ol>
<li>i +&#x3D;1    i -&#x3D; 1</li>
</ol>
</li>
<li>if…else…..</li>
</ul>
<p><strong>方法和函数</strong></p>
<ol>
<li>方法的定义<ul>
<li>def方法定义</li>
<li>方法中传参要指定类型</li>
<li>方法自己可以推断返回类型，默认将方法体中最后一行计算的结果当作返回值返回</li>
<li>如果要写return返回值，要显示的说明方法体的返回值类型</li>
<li>如何方法体可以一行搞定，可以将方法体“{}”去掉</li>
<li>如果方法名称和方法体之间没有“&#x3D;”无论方法体返回说明值都会被丢弃，返回Uit</li>
</ul>
</li>
<li>递归方法<ul>
<li>要显示写出返回值类型</li>
</ul>
</li>
<li>参数有默认值的方法<ul>
<li>def fun(x:Int&#x3D;100)</li>
</ul>
</li>
<li>可变长参数的方法<ul>
<li>def fun(x:String*)</li>
</ul>
</li>
<li>匿名函数<ul>
<li>()&#x3D;&gt;{…}</li>
<li>可以赋值给一个变量，下次调用变量就是使用的这个匿名函数</li>
</ul>
</li>
<li>偏应用函数</li>
<li>嵌套方法</li>
<li>高阶函数<ul>
<li>函数的参数是函数</li>
<li>函数的返回时函数</li>
<li>函数的参数和返回都是函数</li>
</ul>
</li>
<li>柯里化函数<ul>
<li>高阶函数的简化</li>
</ul>
</li>
</ol>
<p><strong>String</strong>	</p>
<p>就是java中的String</p>
<p><strong>集合</strong></p>
<ol>
<li>Array</li>
<li>ArrayBuffer</li>
<li>List<ul>
<li>val list &#x3D; List[String]（…..)</li>
</ul>
</li>
<li>ListBuffer</li>
<li>Set<ul>
<li>可变，不可变</li>
</ul>
</li>
<li>Map<ul>
<li>可变，不可变</li>
<li>map中的元素就是一个个的二元组</li>
<li>val value &#x3D; map.get(key)</li>
<li>val value &#x3D; map.get(key).getOrElse(…)</li>
<li>map.keys</li>
<li>map.values</li>
</ul>
</li>
<li>Tuple<ul>
<li>元组</li>
<li>元组取值 tuple._xx</li>
<li>最多支持22个元素</li>
<li>val iter &#x3D; tuple.prducelterator</li>
<li>二元组中有个swap翻转</li>
</ul>
</li>
</ol>
<p><strong>Trait</strong></p>
<ol>
<li>相当于java中的接口和抽象类结合</li>
<li>可以在Trait中定义方法实现与不 实现，变量和常量都可以</li>
<li>Trait 不可以传参</li>
<li>类继承trait第一个关键字使用extends，之后使用with</li>
</ol>
<p><strong>模式匹配</strong></p>
<ol>
<li>math….case….</li>
<li>模式匹配中既可以匹配值，也可以匹配类型<ul>
<li>case 123&#x3D;&gt;{…}</li>
<li>case i:Int&#x3D;&gt;{…}</li>
</ul>
</li>
<li>模式匹配中，从上往下匹配，匹配上了就自动终止</li>
<li>模式匹配过程中会有值转换</li>
<li>case _&#x3D;{…} 什么都匹配不上最后匹配，要写到最后</li>
<li>模式匹配 match …case… 相当于一大行</li>
</ol>
<p><strong>样例类</strong></p>
<ol>
<li>case class</li>
<li>样例类可以new 也可以不new </li>
<li>样李类中参数，默认有getter setter方法，对外可见</li>
</ol>
<p><strong>偏函数</strong></p>
<ol>
<li>PartialFunction[匹配的类型，匹配上传出的类型]</li>
<li>偏函数相当于java中的switch…case…,只能匹配相同类型</li>
</ol>
<p><strong>隐式转换</strong></p>
<p><strong>Actor模式</strong></p>
<h3 id="Hive基本概念"><a href="#Hive基本概念" class="headerlink" title="Hive基本概念"></a>Hive基本概念</h3><h4 id="一、什么是Hive"><a href="#一、什么是Hive" class="headerlink" title="一、什么是Hive"></a>一、什么是Hive</h4><ul>
<li>Hive简介</li>
</ul>
<p>Hive：由FaceBook开源用于解决海量结构化日志的数据统计工具</p>
<p>Hive：基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张表，并提供类SQL的查询功能。</p>
<ul>
<li>Hive本质</li>
</ul>
<p>将HSQL转化成MapReduce程序</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Hive处理的数据存储在HDFS</span><br><span class="line">Hive分析数据底层实现的是MR</span><br><span class="line">执行程序运行在Yarn上</span><br></pre></td></tr></table></figure>



<h4 id="二、Hive的优缺点"><a href="#二、Hive的优缺点" class="headerlink" title="二、Hive的优缺点"></a>二、Hive的优缺点</h4><p>（1）优点</p>
<ul>
<li>接口采用类SQL语法，提供快速开发的能力</li>
<li>避免了去写MR程序，减少开发人员的学习成本</li>
<li>Hive的执行延迟比较高，因此Hive常用于数据分析，对实时性要求不高的场合</li>
<li>Hive的优势在于处理大数据，对于处理小数据没有优势，因为Hive的执行延迟比较高</li>
<li>Hive支持自定义函数，用户可以根据自己的需求来实现自己的函数</li>
</ul>
<p>（2）缺点</p>
<ul>
<li>Hive的HSQL表达能力有限 <ul>
<li>迭代算法无法表达 </li>
<li>数据挖掘方面不擅长，由于MR数据处理流程的限制，效率更高的算法却无法实现</li>
</ul>
</li>
<li>Hive的效率 比较低 <ul>
<li>Hive自动生成的MR作业，通常情况下不够智能化 </li>
<li>Hive调优比较困难，粒度较粗</li>
</ul>
</li>
</ul>
<p>（3）Hive运行机制</p>
<p>Hive通过用户提供的一系列交互接口，接收到用户的指令（SQL），使用自己的Driver，结合元数据（Metastore），将这些指令翻译 成MR，提交到Hadoop中执行，最后，将执行返回的结果输出到用户交互接口。</p>
<p>（4）Hive和数据库比较</p>
<p>由于Hive采用类似SQL的查询语言HQL，因此很容易将Hive理解为数据库。其实从结构来看，Hive 和数据库除了用于类似的查询语言， 再无类似之处。</p>
<p>（5）数据更新</p>
<p>由于Hive是针对数据仓库应用设计的，而数据仓库的内容是读多写少。因此，Hive中不建议对数据的改写，所有数据都是在加载的时候<br>确定好的。而数据库中的数据通常是需要进行修改的，因此可以采用insert into … values添加数据，使用update … set修改数据</p>
<p>（6）执行延迟</p>
<p>Hive在查询数据的时候，由于没有索引，需要扫描整个表。因此延迟较高。由于Hive底层使用的MR框架，而MR本身具有较高的延迟，因此 在利用MR执行Hive查询的时候，也有较高的延迟。</p>
<p>（7）数据规模</p>
<p>由于Hive简历在集群上可以利用MR进行并行计算，因此可以支持很大规模的数据。对应的，数据库可以支持的数据规模较小。</p>
<h4 id="三、Hive架构"><a href="#三、Hive架构" class="headerlink" title="三、Hive架构"></a>三、Hive架构</h4><p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271704024.png" alt="image-20231207093230761"></p>
<h4 id="四、Hive安装-启动"><a href="#四、Hive安装-启动" class="headerlink" title="四、Hive安装&amp;启动"></a>四、Hive安装&amp;启动</h4><p>（1）上传压缩包，解压</p>
<p>………..</p>
<p>（2）配置环境变量</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop101 hive]# <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hive</span><br><span class="line">[root@hadoop101 hive]# vim /etc/profile</span><br></pre></td></tr></table></figure>

<p>配置内容：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># hive环境配置</span></span><br><span class="line"><span class="built_in">export</span> HIVE_HOME=/opt/module/hive</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$HIVE_HOME</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>

<p>使其生效：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop101 hive]# <span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure>



<p>（3）解决日志Jar包冲突</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 lib]# <span class="built_in">mv</span> log4j-slf4j-impl-2.10.0.jar log4j-slf4j-impl-2.10.0.bak</span><br></pre></td></tr></table></figure>



<p>（4）初始化元数据库</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 hive]# bin/schematool -dbType derby -initSchema </span><br></pre></td></tr></table></figure>



<p><strong>[注意]</strong></p>
<p>问题1：hive初始化报错</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">【bigdata@master hive】bin/schematool -dbType derby -initSchema</span><br><span class="line">Exception <span class="keyword">in</span> thread <span class="string">&quot;main&quot;</span> java.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument(ZLjava/lang/String;Ljava/lang/Object;)</span><br></pre></td></tr></table></figure>

<p>处理办法：<br>原因：hadoop和hive的两个guava.jar版本不一致<br>两个位置分别位于下面两个目录：<br>- &#x2F;opt&#x2F;module&#x2F;hive&#x2F;lib&#x2F;<br>- &#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib<br>删除低版本的那个，将高版本的复制到低版本目录下	</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">【bigdata@master hive】 <span class="built_in">ls</span> -l /opt/module/hadoop/share/hadoop/common/lib | grep guava*</span><br><span class="line">【bigdata@master hive】 <span class="built_in">ls</span> -l /opt/module/hive/lib/ | grep guava*</span><br><span class="line">【bigdata@master hive】 <span class="built_in">mv</span> /opt/module/hive/lib/guava-19.0.jar /opt/module/hive/lib/guava-19.0.bak</span><br><span class="line">【bigdata@master hive】 <span class="built_in">cp</span> /opt/module/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar /opt/module/hive/lib/guava-27.0-jre.jar</span><br></pre></td></tr></table></figure>



<p>重新初始化</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 hive]# bin/schematool -dbType derby -initSchema                 SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line">Metastore connection URL:        jdbc:derby:;databaseName=metastore_db;create=<span class="literal">true</span></span><br><span class="line">Metastore Connection Driver :    org.apache.derby.jdbc.EmbeddedDriver</span><br><span class="line">Metastore connection User:       APP</span><br><span class="line">Starting metastore schema initialization to 3.1.0</span><br><span class="line">Initialization script hive-schema-3.1.0.derby.sql</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Initialization script completed</span><br><span class="line">schemaTool completed</span><br></pre></td></tr></table></figure>



<p>（5）启动hadoop</p>
<p>等待退出安全模式</p>
<p>（6）使用hive</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 hive]# bin/hive</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line"><span class="built_in">which</span>: no hbase <span class="keyword">in</span> (/opt/module/hive/bin:.:/opt/module/mysql/bin:.:/opt/module/hadoop/bin:/opt/module/hadoop/sbin:/opt/module/hive/bin:.:/opt/module/mysql/bin:.:/opt/module/hadoop/bin:/opt/module/hadoop/sbin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/module/jdk/bin:/root/bin:/opt/module/jdk/bin)</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line">Hive Session ID = 3851be03-5678-4023-bd3f-fd2401ffd5b0</span><br><span class="line"></span><br><span class="line">Logging initialized using configuration <span class="keyword">in</span> jar:file:/opt/module/hive/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: <span class="literal">true</span></span><br><span class="line">Hive-on-MR is deprecated <span class="keyword">in</span> Hive 2 and may not be available <span class="keyword">in</span> the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.</span><br><span class="line">Hive Session ID = 448043f3-3f9a-466b-9eb9-90da56da6924</span><br><span class="line">hive&gt; show databases;</span><br><span class="line">OK</span><br><span class="line">default</span><br><span class="line">Time taken: 1.256 seconds, Fetched: 1 row(s)</span><br><span class="line">hive&gt; show tables;</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.077 seconds</span><br><span class="line">hive&gt;</span><br></pre></td></tr></table></figure>



<h4 id="五、Hive元数据配置MySQL"><a href="#五、Hive元数据配置MySQL" class="headerlink" title="五、Hive元数据配置MySQL"></a>五、Hive元数据配置MySQL</h4><p>（1）拷贝驱动</p>
<p>将MySQL的JDBC驱动拷贝到Hive的lib目录下</p>
<p>Ctrl + C 退出hive</p>
<p>（2）配置文件</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 hive]# <span class="built_in">cd</span> conf/</span><br><span class="line">[root@hadoop301 conf]# ll</span><br><span class="line">总用量 332</span><br><span class="line">-rw-r--r--. 1 root root   1596 8月  23 2019 beeline-log4j2.properties.template</span><br><span class="line">-rw-r--r--. 1 root root 300482 8月  23 2019 hive-default.xml.template</span><br><span class="line">-rw-r--r--. 1 root root   2365 8月  23 2019 hive-env.sh.template</span><br><span class="line">-rw-r--r--. 1 root root   2274 8月  23 2019 hive-exec-log4j2.properties.template</span><br><span class="line">-rw-r--r--. 1 root root   3086 8月  23 2019 hive-log4j2.properties.template</span><br><span class="line">-rw-r--r--. 1 root root   2060 8月  23 2019 ivysettings.xml</span><br><span class="line">-rw-r--r--. 1 root root   3558 8月  23 2019 llap-cli-log4j2.properties.template</span><br><span class="line">-rw-r--r--. 1 root root   7163 8月  23 2019 llap-daemon-log4j2.properties.templa        te</span><br><span class="line">-rw-r--r--. 1 root root   2662 8月  23 2019 parquet-logging.properties</span><br><span class="line">[root@hadoop301 conf]# vim hive-site.xml</span><br></pre></td></tr></table></figure>

<p>配置内容如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span> standalone=<span class="string">&quot;no&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- jdbc连接的URL --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://hadoop301:3306/metastore?useSSL=false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!-- jdbc连接的Driver --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!-- jdbc连接的username --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!-- jdbc连接的password --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!-- hive 元数据存储版本的验证 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.schema.verification<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!-- 元数据存储授权 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.event.db.notification.api.auth<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!-- hive 默认在HDFS的工作目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>



<p>（3）安装配置MySQL</p>
<p>参考：<a target="_blank" rel="noopener" href="https://blog.csdn.net/li1325169021/article/details/121515102#SnippetTab">https://blog.csdn.net/li1325169021/article/details/121515102#SnippetTab</a></p>
<p>或B站：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1EZ4y1G7iL?p=17&vd_source=f0e29db1fb2c27102c4aaaab8ed9c6a7">https://www.bilibili.com/video/BV1EZ4y1G7iL?p=17&amp;vd_source=f0e29db1fb2c27102c4aaaab8ed9c6a7</a></p>
<p>省略….</p>
<p>（4）登录MySQL</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 conf]# mysql -uroot -p123456</span><br><span class="line">mysql: [Warning] Using a password on the command line interface can be insecure.</span><br><span class="line">Welcome to the MySQL monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 75</span><br><span class="line">Server version: 5.7.33 MySQL Community Server (GPL)</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2021, Oracle and/or its affiliates.</span><br><span class="line"></span><br><span class="line">Oracle is a registered trademark of Oracle Corporation and/or its</span><br><span class="line">affiliates. Other names may be trademarks of their respective</span><br><span class="line">owners.</span><br><span class="line"></span><br><span class="line">Type &#x27;help;&#x27; or &#x27;\h&#x27; for help. Type &#x27;\c&#x27; to clear the current input statement.</span><br><span class="line"></span><br><span class="line">mysql&gt; show databases;</span><br><span class="line">+--------------------+</span><br><span class="line">| Database           |</span><br><span class="line">+--------------------+</span><br><span class="line">| information_schema |</span><br><span class="line">| mysql              |</span><br><span class="line">| performance_schema |</span><br><span class="line">| sys                |</span><br><span class="line">| test_mata          |</span><br><span class="line">+--------------------+</span><br><span class="line">5 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure>



<p>（5）新建Hive元数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; create database metastore;</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; show databases;</span><br><span class="line">+--------------------+</span><br><span class="line">| Database           |</span><br><span class="line">+--------------------+</span><br><span class="line">| information_schema |</span><br><span class="line">| metastore          |</span><br><span class="line">| mysql              |</span><br><span class="line">| performance_schema |</span><br><span class="line">| sys                |</span><br><span class="line">| test_mata          |</span><br><span class="line">+--------------------+</span><br><span class="line">6 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; exit;</span><br></pre></td></tr></table></figure>



<p>（6）初始化Hive元数据</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 hive]# schematool -initSchema -dbType mysql -verbose</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line">Metastore connection URL:        jdbc:mysql://hadoop301:3306/metastore?useSSL=<span class="literal">false</span></span><br><span class="line">Metastore Connection Driver :    com.mysql.jdbc.Driver</span><br><span class="line">Metastore connection User:       root</span><br><span class="line">Starting metastore schema initialization to 3.1.0</span><br><span class="line">Initialization script hive-schema-3.1.0.mysql.sql</span><br><span class="line">Connecting to jdbc:mysql://hadoop301:3306/metastore?useSSL=<span class="literal">false</span></span><br><span class="line">Connected to: MySQL (version 5.7.33)</span><br><span class="line">Driver: MySQL Connector Java (version mysql-connector-java-5.1.38 ( Revision: fe541c166cec739c74cc727c5da96c1028b4834a ))</span><br><span class="line"></span><br><span class="line">.......</span><br><span class="line"></span><br><span class="line">No rows affected (0.002 seconds)</span><br><span class="line">0: jdbc:mysql://hadoop301:3306/metastore&gt; /*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */</span><br><span class="line">No rows affected (0.001 seconds)</span><br><span class="line">0: jdbc:mysql://hadoop301:3306/metastore&gt; /*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */</span><br><span class="line">No rows affected (0.001 seconds)</span><br><span class="line">0: jdbc:mysql://hadoop301:3306/metastore&gt; /*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */</span><br><span class="line">No rows affected (0.001 seconds)</span><br><span class="line">0: jdbc:mysql://hadoop301:3306/metastore&gt; /*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */</span><br><span class="line">No rows affected (0.001 seconds)</span><br><span class="line">0: jdbc:mysql://hadoop301:3306/metastore&gt; /*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */</span><br><span class="line">No rows affected (0.001 seconds)</span><br><span class="line">0: jdbc:mysql://hadoop301:3306/metastore&gt; !closeall</span><br><span class="line">Closing: 0: jdbc:mysql://hadoop301:3306/metastore?useSSL=<span class="literal">false</span></span><br><span class="line">beeline&gt;</span><br><span class="line">beeline&gt; Initialization script completed</span><br><span class="line">schemaTool completed</span><br></pre></td></tr></table></figure>



<p>（7）进入Hive</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 hive]# bin/hive</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line"><span class="built_in">which</span>: no hbase <span class="keyword">in</span> (/opt/module/hive/bin:.:/opt/module/mysql/bin:.:/opt/module/hadoop/bin:/opt/module/hadoop/sbin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/module/jdk/bin:/root/bin)</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line">Hive Session ID = 669e2e36-4d63-43e3-ad90-f33bbba9bbb1</span><br><span class="line"></span><br><span class="line">Logging initialized using configuration <span class="keyword">in</span> jar:file:/opt/module/hive/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: <span class="literal">true</span></span><br><span class="line">Hive-on-MR is deprecated <span class="keyword">in</span> Hive 2 and may not be available <span class="keyword">in</span> the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.</span><br><span class="line">Hive Session ID = 2f6c4cb6-3df7-437a-94e8-195585806755</span><br><span class="line">hive&gt;</span><br></pre></td></tr></table></figure>

<p>测试一下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; show tables;</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.365 seconetds</span><br><span class="line">hive&gt; create table <span class="built_in">test</span>(<span class="built_in">id</span> string);</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.733 seconds</span><br><span class="line">hive&gt; <span class="keyword">select</span> * from <span class="built_in">test</span>;</span><br><span class="line">OK</span><br><span class="line">Time taken: 2.034 seconds</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 hive]# vim id.txt</span><br><span class="line">[root@hadoop301 hive]# hdfs dfs -put id.txt /user/hive/warehouse/test</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; <span class="keyword">select</span> * from <span class="built_in">test</span>;</span><br><span class="line">OK</span><br><span class="line">11111</span><br><span class="line">22222</span><br><span class="line">Time taken: 0.269 seconds, Fetched: 2 row(s)</span><br></pre></td></tr></table></figure>



<p>（8）使用元数据服务的方式访问Hive</p>
<ol>
<li>在hive-site.xml文件中添加如下配置信息</li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定存储元数据要连接的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>thrift://hadoop301:9083<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>



<ol start="2">
<li>启动metastore</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 hive]# bin/hive --service metastore</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line">2023-12-18 15:15:38: Starting Hive Metastore Server</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>注意会一直被占用，重新启一个服务（关不了）</strong></p>
<ol start="3">
<li>启动hive</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 hive]# bin/hive</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line"><span class="built_in">which</span>: no hbase <span class="keyword">in</span> (/opt/module/hive/bin:.:/opt/module/mysql/bin:.:/opt/module/hadoop/bin:/opt/module/hadoop/sbin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/module/jdk/bin:/root/bin)</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line">Hive Session ID = d0213e7d-8440-4529-b3ba-205f134b1b4a</span><br><span class="line"></span><br><span class="line">Logging initialized using configuration <span class="keyword">in</span> jar:file:/opt/module/hive/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: <span class="literal">true</span></span><br><span class="line">Hive-on-MR is deprecated <span class="keyword">in</span> Hive 2 and may not be available <span class="keyword">in</span> the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.</span><br><span class="line">Hive Session ID = 481bcaf4-8c0b-4987-a06d-e712c13a5806</span><br><span class="line">hive&gt; show tables;</span><br><span class="line">OK</span><br><span class="line"><span class="built_in">test</span></span><br><span class="line">Time taken: 0.756 seconds, Fetched: 1 row(s)</span><br><span class="line">hive&gt; <span class="keyword">select</span> * from <span class="built_in">test</span>;</span><br><span class="line">OK</span><br><span class="line">11111</span><br><span class="line">22222</span><br><span class="line">Time taken: 2.806 seconds, Fetched: 2 row(s)</span><br><span class="line">hive&gt;</span><br></pre></td></tr></table></figure>



<p>（9）使用JDBC方式访问Hive</p>
<ol>
<li>在hive-site.xml文件中添加如下配置信息</li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定hiveserver2连接的host --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.bind.host<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop301<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定hiveserver2连接的端口号 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>10000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>并启动元数据访问</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 hive]# bin/hive --service metastore</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line">2023-12-18 15:31:24: Starting Hive Metastore Server</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<ol start="2">
<li>启动hiveserver2</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 hive]# bin/hive --service hiveserver2</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line"><span class="built_in">which</span>: no hbase <span class="keyword">in</span> (/opt/module/hive/bin:.:/opt/module/mysql/bin:.:/opt/module/hadoop/bin:/opt/module/hadoop/sbin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/module/jdk/bin:/root/bin)</span><br><span class="line">2023-12-18 15:34:32: Starting HiveServer2</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line">Hive Session ID = 1d56762d-4a28-47e4-9670-3683eb9c6d36</span><br><span class="line">Hive Session ID = 62b32922-487b-4668-9d0e-6a59ff053a51</span><br><span class="line">Hive Session ID = cb9695dd-0015-4128-8308-50e1a05706f4</span><br><span class="line">Hive Session ID = f2a8784b-1f9b-444d-919a-dac2bda3d454</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>注意会一直被占用，重新启一个服务（关不了）</strong></p>
<ol start="3">
<li>启动beeline客户端（需要多等待一会）</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 hive]# bin/beeline -u jdbc:hive2://hadoop301:10000 -n atguigu</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line">Connecting to jdbc:hive2://hadoop301:10000</span><br><span class="line">Connected to: Apache Hive (version 3.1.2)</span><br><span class="line">Driver: Hive JDBC (version 3.1.2)</span><br><span class="line">Transaction isolation: TRANSACTION_REPEATABLE_READ</span><br><span class="line">Beeline version 3.1.2 by Apache Hive</span><br><span class="line">0: jdbc:hive2://hadoop301:10000&gt; show tables;</span><br><span class="line">+-----------+</span><br><span class="line">| tab_name  |</span><br><span class="line">+-----------+</span><br><span class="line">| <span class="built_in">test</span>      |</span><br><span class="line">+-----------+</span><br><span class="line">1 row selected (1.815 seconds)</span><br><span class="line">0: jdbc:hive2://hadoop301:10000&gt; Closing: 0: jdbc:hive2://hadoop301:10000</span><br></pre></td></tr></table></figure>

<p><strong>注意如果报错参考：<a target="_blank" rel="noopener" href="https://blog.csdn.net/u011495642/article/details/84305944">https://blog.csdn.net/u011495642/article/details/84305944</a></strong></p>
<p>可以使用nohup hive –service metastore 2&gt;&amp;1 &amp;但不建议</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 hive]# <span class="built_in">nohup</span> hive --service metastore 2&gt;&amp;1 &amp;</span><br><span class="line">[1] 5532</span><br><span class="line">[root@hadoop301 hive]# <span class="built_in">nohup</span>: 忽略输入并把输出追加到<span class="string">&quot;nohup.out&quot;</span></span><br><span class="line"></span><br><span class="line">[root@hadoop301 hive]# jps</span><br><span class="line">2643 DataNode</span><br><span class="line">2485 NameNode</span><br><span class="line">5654 Jps</span><br><span class="line">5111 RunJar</span><br><span class="line">5532 RunJar</span><br><span class="line">2991 NodeManager</span><br><span class="line">[root@hadoop301 hive]# <span class="built_in">kill</span> -9 5111</span><br><span class="line">[root@hadoop301 hive]# <span class="built_in">kill</span> -9 5532</span><br><span class="line">[root@hadoop301 hive]# jps</span><br><span class="line">2643 DataNode</span><br><span class="line">2485 NameNode</span><br><span class="line">5673 Jps</span><br><span class="line">2991 NodeManager</span><br><span class="line">[1]+  已杀死               <span class="built_in">nohup</span> hive --service metastore 2&gt;&amp;1</span><br></pre></td></tr></table></figure>





<p>（10）元数据服务(脚本封装)</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">HIVE_LOG_DIR=<span class="variable">$HIVE_HOME</span>/logs</span><br><span class="line"></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="variable">$HIVE_LOG_DIR</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#检查进程是否运行正常，参数1为进程名，参数2为进程端口</span></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">check_process</span></span>()</span><br><span class="line">&#123;</span><br><span class="line">    pid=$(ps -ef 2&gt;/dev/null | grep -v grep | grep -i <span class="variable">$1</span> | awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span>)</span><br><span class="line">    ppid=$(netstat -nltp 2&gt;/dev/null | grep <span class="variable">$2</span> | awk <span class="string">&#x27;&#123;print $7&#125;&#x27;</span> | <span class="built_in">cut</span> -d <span class="string">&#x27;/&#x27;</span> -f 1)</span><br><span class="line">    <span class="built_in">echo</span> <span class="variable">$pid</span></span><br><span class="line">    [[ <span class="string">&quot;<span class="variable">$pid</span>&quot;</span> =~ <span class="string">&quot;<span class="variable">$ppid</span>&quot;</span> ]] &amp;&amp; [ <span class="string">&quot;<span class="variable">$ppid</span>&quot;</span> ] &amp;&amp; <span class="built_in">return</span> 0 || <span class="built_in">return</span> 1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">hive_start</span></span>()</span><br><span class="line">&#123;</span><br><span class="line">    metapid=$(check_process HiveMetastore 9083)</span><br><span class="line">    cmd=<span class="string">&quot;nohup hive --service metastore &gt;<span class="variable">$HIVE_LOG_DIR</span>/metastore.log 2&gt;&amp;1 &amp;&quot;</span></span><br><span class="line">    cmd=<span class="variable">$cmd</span><span class="string">&quot; sleep 4; hdfs dfsadmin -safemode wait &gt;/dev/null 2&gt;&amp;1&quot;</span></span><br><span class="line">    [ -z <span class="string">&quot;<span class="variable">$metapid</span>&quot;</span> ] &amp;&amp; <span class="built_in">eval</span> <span class="variable">$cmd</span> || <span class="built_in">echo</span> <span class="string">&quot;Metastroe服务已启动&quot;</span></span><br><span class="line">    server2pid=$(check_process HiveServer2 10000)</span><br><span class="line">    cmd=<span class="string">&quot;nohup hive --service hiveserver2 &gt;<span class="variable">$HIVE_LOG_DIR</span>/hiveServer2.log 2&gt;&amp;1 &amp;&quot;</span></span><br><span class="line">    [ -z <span class="string">&quot;<span class="variable">$server2pid</span>&quot;</span> ] &amp;&amp; <span class="built_in">eval</span> <span class="variable">$cmd</span> || <span class="built_in">echo</span> <span class="string">&quot;HiveServer2服务已启动&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">hive_stop</span></span>()</span><br><span class="line">&#123;</span><br><span class="line">    metapid=$(check_process HiveMetastore 9083)</span><br><span class="line">    [ <span class="string">&quot;<span class="variable">$metapid</span>&quot;</span> ] &amp;&amp; <span class="built_in">kill</span> <span class="variable">$metapid</span> || <span class="built_in">echo</span> <span class="string">&quot;Metastore服务未启动&quot;</span></span><br><span class="line">    server2pid=$(check_process HiveServer2 10000)</span><br><span class="line">    [ <span class="string">&quot;<span class="variable">$server2pid</span>&quot;</span> ] &amp;&amp; <span class="built_in">kill</span> <span class="variable">$server2pid</span> || <span class="built_in">echo</span> <span class="string">&quot;HiveServer2服务未启动&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="variable">$1</span> <span class="keyword">in</span></span><br><span class="line"><span class="string">&quot;start&quot;</span>)</span><br><span class="line">    hive_start</span><br><span class="line">    ;;</span><br><span class="line"><span class="string">&quot;stop&quot;</span>)</span><br><span class="line">    hive_stop</span><br><span class="line">    ;;</span><br><span class="line"><span class="string">&quot;restart&quot;</span>)</span><br><span class="line">    hive_stop</span><br><span class="line">    <span class="built_in">sleep</span> 2</span><br><span class="line">    hive_start</span><br><span class="line">    ;;</span><br><span class="line"><span class="string">&quot;status&quot;</span>)</span><br><span class="line">    check_process HiveMetastore 9083 &gt;/dev/null &amp;&amp; <span class="built_in">echo</span> <span class="string">&quot;Metastore服务运行正常&quot;</span> || <span class="built_in">echo</span> <span class="string">&quot;Metastore服务运行异常&quot;</span></span><br><span class="line">    check_process HiveServer2 10000 &gt;/dev/null &amp;&amp; <span class="built_in">echo</span> <span class="string">&quot;HiveServer2服务运行正常&quot;</span> || <span class="built_in">echo</span> <span class="string">&quot;HiveServer2服务运行异常&quot;</span></span><br><span class="line">    ;;</span><br><span class="line">*)</span><br><span class="line">    <span class="built_in">echo</span> Invalid Args!</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&#x27;Usage: &#x27;</span>$(<span class="built_in">basename</span> <span class="variable">$0</span>)<span class="string">&#x27; start|stop|restart|status&#x27;</span></span><br><span class="line">    ;;</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure>



<p>（11）<strong>启动脚本(启动元数据服务)</strong></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 hive]# bin/hiveservice.sh start</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 hive]# bin/hiveservice.sh start</span><br><span class="line">[root@hadoop301 hive]# bin/hiveservice.sh status</span><br><span class="line">Metastore服务运行正常</span><br><span class="line">HiveServer2服务运行异常</span><br><span class="line"><span class="comment"># 需要等一下</span></span><br><span class="line">[root@hadoop301 hive]# bin/hiveservice.sh status</span><br><span class="line">Metastore服务运行正常</span><br><span class="line">HiveServer2服务运行正常</span><br></pre></td></tr></table></figure>



<p>关闭服务命令</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 hive]# bin/hiveservice.sh stop</span><br><span class="line">[root@hadoop301 hive]# bin/hiveservice.sh status</span><br><span class="line">Metastore服务运行异常</span><br><span class="line">HiveServer2服务运行异常</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>（12）启动beeline客户端</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 hive]# bin/beeline -u jdbc:hive2://hadoop301:10000 -n atguigu</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line">Connecting to jdbc:hive2://hadoop301:10000</span><br><span class="line">Connected to: Apache Hive (version 3.1.2)</span><br><span class="line">Driver: Hive JDBC (version 3.1.2)</span><br><span class="line">Transaction isolation: TRANSACTION_REPEATABLE_READ</span><br><span class="line">Beeline version 3.1.2 by Apache Hive</span><br><span class="line">0: jdbc:hive2://hadoop301:10000&gt;</span><br></pre></td></tr></table></figure>



<p>（13）其它交互方式</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 hive]# bin/hive -<span class="built_in">help</span></span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line"><span class="built_in">which</span>: no hbase <span class="keyword">in</span> (/opt/module/hive/bin:.:/opt/module/mysql/bin:.:/opt/module/hadoop/bin:/opt/module/hadoop/sbin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/module/jdk/bin:/root/bin)</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line">Hive Session ID = 44da0620-5c90-4a71-be68-bfdcf1f45544</span><br><span class="line">usage: hive</span><br><span class="line"> -d,--define &lt;key=value&gt;          Variable substitution to apply to Hive</span><br><span class="line">                                  commands. e.g. -d A=B or --define A=B</span><br><span class="line">    --database &lt;databasename&gt;     Specify the database to use</span><br><span class="line"> -e &lt;quoted-query-string&gt;         SQL from <span class="built_in">command</span> line</span><br><span class="line"> -f &lt;filename&gt;                    SQL from files</span><br><span class="line"> -H,--<span class="built_in">help</span>                        Print <span class="built_in">help</span> information</span><br><span class="line">    --hiveconf &lt;property=value&gt;   Use value <span class="keyword">for</span> given property</span><br><span class="line">    --hivevar &lt;key=value&gt;         Variable substitution to apply to Hive</span><br><span class="line">                                  commands. e.g. --hivevar A=B</span><br><span class="line"> -i &lt;filename&gt;                    Initialization SQL file</span><br><span class="line"> -S,--silent                      Silent mode <span class="keyword">in</span> interactive shell</span><br><span class="line"> -v,--verbose                     Verbose mode (<span class="built_in">echo</span> executed SQL to the</span><br><span class="line">                                  console)</span><br></pre></td></tr></table></figure>

<ol>
<li>直接运行sql语句</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 hive]# bin/hive -e <span class="string">&quot;select * from test;&quot;</span></span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line"><span class="built_in">which</span>: no hbase <span class="keyword">in</span> (/opt/module/hive/bin:.:/opt/module/mysql/bin:.:/opt/module/hadoop/bin:/opt/module/hadoop/sbin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/module/jdk/bin:/root/bin)</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line">Hive Session ID = 11a55c47-83d9-4809-bc09-d81c721bbdfb</span><br><span class="line"></span><br><span class="line">Logging initialized using configuration <span class="keyword">in</span> jar:file:/opt/module/hive/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: <span class="literal">true</span></span><br><span class="line">Hive Session ID = 0abd3b57-c0f6-484c-a169-3271c79c0bcb</span><br><span class="line">OK</span><br><span class="line">11111</span><br><span class="line">22222</span><br><span class="line">Time taken: 9.479 seconds, Fetched: 2 row(s)</span><br></pre></td></tr></table></figure>



<ol start="2">
<li>运行sql脚本</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 hive]# vim hive.sql</span><br><span class="line"></span><br><span class="line"><span class="comment"># 内容如下：</span></span><br><span class="line"><span class="keyword">select</span> * from <span class="built_in">test</span>;</span><br><span class="line"><span class="keyword">select</span> count(*) from <span class="built_in">test</span>;</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 hive]# bin/hive -f hive.sql</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line"><span class="built_in">which</span>: no hbase <span class="keyword">in</span> (/opt/module/hive/bin:.:/opt/module/mysql/bin:.:/opt/module/hadoop/bin:/opt/module/hadoop/sbin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/module/jdk/bin:/root/bin)</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line">Hive Session ID = 2ff25f8f-403f-4488-b67d-9d1c196859bd</span><br><span class="line"></span><br><span class="line">Logging initialized using configuration <span class="keyword">in</span> jar:file:/opt/module/hive/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: <span class="literal">true</span></span><br><span class="line">Hive Session ID = eb7a9115-42b4-449d-821b-77a64d3c8bac</span><br><span class="line">OK</span><br><span class="line">11111</span><br><span class="line">22222</span><br><span class="line">Time taken: 6.07 seconds, Fetched: 2 row(s)</span><br><span class="line">OK</span><br><span class="line">0</span><br><span class="line">Time taken: 2.232 seconds, Fetched: 1 row(s)</span><br></pre></td></tr></table></figure>



<ol start="3">
<li>在hive cli 命令窗口中如何查看hdfs 文件系统</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 hive]# bin/beeline -u jdbc:hive2://hadoop301:10000 -n atguigu</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line">Connecting to jdbc:hive2://hadoop301:10000</span><br><span class="line">Connected to: Apache Hive (version 3.1.2)</span><br><span class="line">Driver: Hive JDBC (version 3.1.2)</span><br><span class="line">Transaction isolation: TRANSACTION_REPEATABLE_READ</span><br><span class="line">Beeline version 3.1.2 by Apache Hive</span><br><span class="line">0: jdbc:hive2://hadoop301:10000&gt; dfs -<span class="built_in">ls</span> /;</span><br><span class="line">+----------------------------------------------------+</span><br><span class="line">|                     DFS Output                     |</span><br><span class="line">+----------------------------------------------------+</span><br><span class="line">| Found 4 items                                      |</span><br><span class="line">| drwxr-xr-x   - root supergroup          0 2023-12-13 16:50 /directory |</span><br><span class="line">| drwxrwxrwx   - root supergroup          0 2023-12-07 11:17 /tem |</span><br><span class="line">| drwx-wx-wx   - root supergroup          0 2023-12-18 11:01 /tmp |</span><br><span class="line">| drwxr-xr-x   - root supergroup          0 2023-12-13 16:19 /user |</span><br><span class="line">+----------------------------------------------------+</span><br><span class="line">5 rows selected (0.34 seconds)</span><br><span class="line">0: jdbc:hive2://hadoop301:10000&gt;</span><br></pre></td></tr></table></figure>



<ol start="4">
<li>查看在hive中输入的所有历史命令</li>
</ol>
<p>(1)进入到当前用户的根目录 &#x2F;root  或&#x2F;home&#x2F;arguigu</p>
<p>(2)查看 .hivehistory 文件</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 ~]# <span class="built_in">cat</span> .hivehistory</span><br></pre></td></tr></table></figure>





<p>（14）Hive 运行日志信息配置</p>
<ol>
<li>hive 的默认存放在：&#x2F;tmp&#x2F;root&#x2F;hive.log 目录下</li>
<li>修改hive的log存放日志到&#x2F;opt&#x2F;module&#x2F;hive&#x2F;logs</li>
</ol>
<p>修改 &#x2F;opt&#x2F;module&#x2F;hive&#x2F;conf&#x2F;hive-log4j2.properties.template 文件名称为 hive-log4j2.properties</p>
<p>在hive-log4j2.properties 文件中修改log存放的位置</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">property.hive.log.dir</span> = <span class="string">/opt/module/hive/logs</span></span><br></pre></td></tr></table></figure>



<p>（15）打印当前库和表头</p>
<p>在hive-site.xml中加入如下两个配置:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.header<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.current.db<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>



<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 hive]# bin/hive</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line"><span class="built_in">which</span>: no hbase <span class="keyword">in</span> (/opt/module/hive/bin:.:/opt/module/mysql/bin:.:/opt/module/hadoop/bin:/opt/module/hadoop/sbin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/module/jdk/bin:/root/bin)</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line">Hive Session ID = 1e735514-8f8f-4818-9eaf-21f3a578506d</span><br><span class="line"></span><br><span class="line">Logging initialized using configuration <span class="keyword">in</span> file:/opt/module/hive/conf/hive-log4j2.properties Async: <span class="literal">true</span></span><br><span class="line">Hive-on-MR is deprecated <span class="keyword">in</span> Hive 2 and may not be available <span class="keyword">in</span> the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.</span><br><span class="line">Hive Session ID = 5e438f4b-5779-4a91-88f7-1cf59ed04714</span><br><span class="line">hive (default)&gt; use hive;</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.597 seconds</span><br><span class="line">hive (hive)&gt;</span><br></pre></td></tr></table></figure>

<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271704738.png" alt="image-20231218200007233"></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; <span class="keyword">select</span> * from <span class="built_in">test</span>;</span><br><span class="line">OK</span><br><span class="line">test.id</span><br><span class="line">11111</span><br><span class="line">22222</span><br><span class="line">Time taken: 2.576 seconds, Fetched: 2 row(s)</span><br><span class="line">hive (default)&gt;</span><br></pre></td></tr></table></figure>

<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271705087.png" alt="image-20231218200220774"></p>
<p>（16）配置信息位置</p>
<ol>
<li>查看当前所有的配置信息</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 hive]# bin/hive</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line"><span class="built_in">which</span>: no hbase <span class="keyword">in</span> (/opt/module/hive/bin:.:/opt/module/mysql/bin:.:/opt/module/hadoop/bin:/opt/module/hadoop/sbin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/module/jdk/bin:/root/bin)</span><br><span class="line"></span><br><span class="line">......</span><br><span class="line"></span><br><span class="line">system:sun.management.compiler=HotSpot 64-Bit Tiered Compilers</span><br><span class="line">system:sun.os.patch.level=unknown</span><br><span class="line">system:user.country=CN</span><br><span class="line">system:user.dir=/opt/module/hive</span><br><span class="line">system:user.home=/root</span><br><span class="line">system:user.language=zh</span><br><span class="line">system:user.name=root</span><br><span class="line">system:user.timezone=Asia/Shanghai</span><br><span class="line">system:yarn.home.dir=/opt/module/hadoop</span><br><span class="line">system:yarn.log.dir=/opt/module/hadoop/logs</span><br><span class="line">system:yarn.log.file=hadoop.log</span><br><span class="line">system:yarn.root.logger=INFO,console</span><br><span class="line">hive (default)&gt;</span><br></pre></td></tr></table></figure>



<ol start="2">
<li>参数的配置三种方式</li>
</ol>
<p>1)配置文件方式</p>
<p>默认配置文件：hive-default.xml</p>
<p>用户自定义配置文件: hive-site.xmI</p>
<p>注意:用户自定义配置会覆盖默认配置。另外，Hive也会读入Hadoop的配置，因为Hive是作为Hadoop的客户端启动的，Hive的配置会覆盖Hadoop 的配置。配置文件的设定对本机启动的所有Hive进程都有效。</p>
<p>2)命令行参数方式</p>
<p>启动Hive时，可以在命令行添加 -hiveconf param&#x3D;value 来设置参数。</p>
<p>例如</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 hive]# bin/hive -hiveconf hive.cli.print.current.db=<span class="literal">true</span>;</span><br></pre></td></tr></table></figure>

<p><strong>注意：仅对本次hive启动有效</strong></p>
<p>查看参数设置</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set mapred.reduce.tasks;</span><br><span class="line">mapred.reduce.tasks=-1</span><br><span class="line">hive (default)&gt;</span><br></pre></td></tr></table></figure>



<p>3)参数声明方式</p>
<p>可以在HQL中使用SET关键字设定参数</p>
<p>例如</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">set</span> mapred.reduce.tasks<span class="operator">=</span><span class="number">100</span>;</span><br></pre></td></tr></table></figure>

<p><strong>注意：仅对本次hive启动有效</strong></p>
<p>查看参数设置</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set mapred.reduce.tasks;</span><br><span class="line">mapred.reduce.tasks=100</span><br><span class="line">hive (default)&gt;</span><br></pre></td></tr></table></figure>

<pre><code>	上述三种设定方式的优先级依次递增。即配置文件&lt;命令行参数&lt;参数声明。注意某些系统级的参数，例如 log4j相关的设定，必须用前两种方式设定，因为那些参数的读取在会话建立以前已经完成了。
</code></pre>
<h4 id="六、Hive-数据类型"><a href="#六、Hive-数据类型" class="headerlink" title="六、Hive 数据类型"></a>六、Hive 数据类型</h4><p>(1) 基本数据类型</p>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271705840.png" alt="image-20231219094620683"></p>
<p>（2）集合数据类型</p>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271727159.png" alt="image-20231219094821621"></p>
<h4 id="七、DDL数据定义"><a href="#七、DDL数据定义" class="headerlink" title="七、DDL数据定义"></a>七、DDL数据定义</h4><p>（1）创建数据库</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">show</span> <span class="keyword">create table</span> test;</span><br><span class="line">OK</span><br><span class="line">createtab_stmt</span><br><span class="line"><span class="keyword">CREATE TABLE</span> `test`(</span><br><span class="line">  `id` string)</span><br><span class="line"><span class="type">ROW</span> FORMAT SERDE</span><br><span class="line">  <span class="string">&#x27;org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe&#x27;</span></span><br><span class="line">STORED <span class="keyword">AS</span> INPUTFORMAT</span><br><span class="line">  <span class="string">&#x27;org.apache.hadoop.mapred.TextInputFormat&#x27;</span></span><br><span class="line">OUTPUTFORMAT</span><br><span class="line">  <span class="string">&#x27;org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat&#x27;</span></span><br><span class="line">LOCATION</span><br><span class="line">  <span class="string">&#x27;hdfs://hadoop301:8020/user/hive/warehouse/test&#x27;</span></span><br><span class="line">TBLPROPERTIES (</span><br><span class="line">  <span class="string">&#x27;bucketing_version&#x27;</span><span class="operator">=</span><span class="string">&#x27;2&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;transient_lastDdlTime&#x27;</span><span class="operator">=</span><span class="string">&#x27;1702881754&#x27;</span>)</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">1.125</span> seconds, Fetched: <span class="number">13</span> <span class="type">row</span>(s)</span><br><span class="line"></span><br><span class="line"># 创建数据库</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">create</span> database if <span class="keyword">not</span> <span class="keyword">exists</span> hive;</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.425</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



<p>（2）创建一个数据库，指定数据库在HDFS上存放的位置</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">create</span> database if <span class="keyword">not</span> <span class="keyword">exists</span> db_hive2 location <span class="string">&#x27;/db_hive2.db&#x27;</span>;</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.106</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>

<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271705881.png" alt="image-20231219111137096"></p>
<p>（3）查询数据库</p>
<ol>
<li>显示数据库</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">show</span> databases;</span><br><span class="line">OK</span><br><span class="line">database_name</span><br><span class="line">db_hive</span><br><span class="line">db_hive2</span><br><span class="line">db_hive3</span><br><span class="line"><span class="keyword">default</span></span><br><span class="line">hive</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.107</span> seconds, Fetched: <span class="number">5</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



<ol start="2">
<li>过滤显示查询的数据库</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">show</span> databases <span class="keyword">like</span> <span class="string">&#x27;db_hive*&#x27;</span>;</span><br><span class="line">OK</span><br><span class="line">database_name</span><br><span class="line">db_hive</span><br><span class="line">db_hive2</span><br><span class="line">db_hive3</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.095</span> seconds, Fetched: <span class="number">3</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



<p>（4）查看数据库详情</p>
<ol>
<li>显示数据库信息</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hive (hive)<span class="operator">&gt;</span> <span class="keyword">desc</span> database hive;</span><br><span class="line">OK</span><br><span class="line">db_name comment location        owner_name      owner_type      parameters</span><br><span class="line">hive            hdfs:<span class="operator">/</span><span class="operator">/</span>hadoop301:<span class="number">8020</span><span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>hive.db       root    <span class="keyword">USER</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.062</span> seconds, Fetched: <span class="number">1</span> <span class="type">row</span>(s)</span><br><span class="line">hive (hive)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>显示数据库详细信息，extended</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hive (hive)<span class="operator">&gt;</span> <span class="keyword">desc</span> database extended hive;</span><br><span class="line">OK</span><br><span class="line">db_name comment location        owner_name      owner_type      parameters</span><br><span class="line">hive            hdfs:<span class="operator">/</span><span class="operator">/</span>hadoop301:<span class="number">8020</span><span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>hive.db       root    <span class="keyword">USER</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.053</span> seconds, Fetched: <span class="number">1</span> <span class="type">row</span>(s)</span><br><span class="line">hive (hive)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



<p>（5）切换当前数据库</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (hive)<span class="operator">&gt;</span> use db_hive;</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.048</span> seconds</span><br><span class="line">hive (db_hive)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



<p>（6）修改数据库</p>
<p>​		用户可以使用ALTER DATABASE 命令为某个数据库的DBPROPERTIES设置键-值对属性值，来描述这个数据库的属性信息。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">alter</span> database hive <span class="keyword">set</span> dbproperties(&quot;createTime&quot;<span class="operator">=</span>&quot;2023-12-19&quot;);</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.14</span> seconds</span><br><span class="line"></span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">desc</span> database extended hive;</span><br><span class="line">OK</span><br><span class="line">db_name comment location        owner_name      owner_type      parameters</span><br><span class="line">hive            hdfs:<span class="operator">/</span><span class="operator">/</span>hadoop301:<span class="number">8020</span><span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>hive.db       root    <span class="keyword">USER</span>    &#123;createTime<span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-19</span>&#125;</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.044</span> seconds, Fetched: <span class="number">1</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



<p>（7）修改数据库</p>
<ol>
<li>删除空数据库</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">drop</span> database db_hive3;</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">1.227</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>如果删除的数据库不存在，最好采用 if exists 判断数据库是否存在</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">drop</span> database db_hive3;</span><br><span class="line">FAILED: SemanticException [Error <span class="number">10072</span>]: Database does <span class="keyword">not</span> exist: db_hive3</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">drop</span> database if <span class="keyword">exists</span> db_hive3;</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.019</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>如果数据库不为空，可以采用 cascade 命令，强制删除</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (db_hive)<span class="operator">&gt;</span> <span class="keyword">drop</span> database db_hive cascade;</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.301</span> seconds</span><br><span class="line">hive (db_hive)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



<p>（8）创建表</p>
<ol>
<li>创建语法</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> [<span class="keyword">EXTERNAL</span>] <span class="keyword">TABLE</span> [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] table_name</span><br><span class="line">[(col_name data_type [COMMENT col_comment], ...)]</span><br><span class="line">[COMMENT table_comment]</span><br><span class="line">[PARTITIONED <span class="keyword">BY</span> (col_name data_type [COMMENT col_comment], ...)]</span><br><span class="line">[CLUSTERED <span class="keyword">BY</span> (col_name, col_name, ...</span><br><span class="line">[SORTED <span class="keyword">BY</span> (col_name [<span class="keyword">ASC</span><span class="operator">|</span><span class="keyword">DESC</span>], ...)] <span class="keyword">INTO</span> num_buckets BUCKETS]</span><br><span class="line">[<span class="type">ROW</span> FORMAT row_format]</span><br><span class="line">[STORED <span class="keyword">AS</span> file_format]</span><br><span class="line">[LOCATION hdfs_path]</span><br><span class="line">[TBLPROPERTIES (property_name<span class="operator">=</span>property_valu, ....)]</span><br><span class="line">[<span class="keyword">AS</span> select_statement]</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>字段解释说明</li>
</ol>
<p>1）[EXTERNAL] ：外部的  –&gt; Hive中的表会有内外之分</p>
<p>2）PARTITIONED BY ：分区表</p>
<p>3）CLUSTERED BY ：分桶表</p>
<p>4）[SORTED BY (col_name [ASC|DESC], …)] INTO num_buckets BUCKETS] ：分桶表</p>
<p>5）[ROW FORMAT row_format] ：定义行的格式</p>
<p>6）[STORED AS file_format] ：指定文件格式</p>
<p>7）[LOCATION hdfs_path] ：指定表的位置信息</p>
<p>8）[TBLPROPERTIES (property_name&#x3D;property_valu, ….)] ：额外属性</p>
<p>9）[AS select_statement] ：</p>
<p>（9）管理表</p>
<ol>
<li>理论</li>
</ol>
<p>​		默认创建的表都是所谓的管理表，有时也被称为内部表。因为这种表，Hive 会(或多或少地）控制着数据的生命周期。Hive 默认情况下会将这些表的数据存储在由配置hive.metastore.warehouse.dir(例如，&#x2F;user&#x2F;hive&#x2F;warehouse)所定义的目录的子目录下。<br>当我们删除一个管理表时，Hive也会删除这个表中的数据。管理表不适合和其他工具共享数据。</p>
<p>（10）管理表与外部表的相互转换</p>
<ol>
<li>查询表的类型</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">desc</span> formatted test;</span><br><span class="line">.....</span><br><span class="line"><span class="keyword">Table</span> Type:             MANAGED_TABLE</span><br><span class="line">.....</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>修改内部表为外部表</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">alter table</span> test <span class="keyword">set</span> tblproperties(<span class="string">&#x27;EXTERNAL&#x27;</span><span class="operator">=</span><span class="string">&#x27;TRUE&#x27;</span>);</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.262</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">desc</span> formatted test;</span><br><span class="line">.....</span><br><span class="line"><span class="keyword">Table</span> Type:             EXTERNAL_TABLE</span><br><span class="line">.....</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>

<p>EXTERNAL’&#x3D;’TRUE : 外部表</p>
<p>EXTERNAL’&#x3D;’FALSE : 内部表</p>
<p><strong>注意：(EXTERNAL’&#x3D;’TRUE )和(EXTERNAL’&#x3D;’FALSE) 为固定写法，区分大小写！</strong></p>
<p>（11）建表时指定字段分隔符</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">create table test6(id int,age int)</span><br><span class="line">row format delimited</span><br><span class="line">fields terminated by &#x27;,&#x27;;</span><br></pre></td></tr></table></figure>



<p>（12）重命名表名</p>
<p>语法：ALTER TABLE table_name RENAME TO new_table_name;</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">show</span> tables;</span><br><span class="line">OK</span><br><span class="line">tab_name</span><br><span class="line">test</span><br><span class="line">test2</span><br><span class="line">test3</span><br><span class="line">test4</span><br><span class="line">test5</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.052</span> seconds, Fetched: <span class="number">5</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">alter table</span> test rename <span class="keyword">to</span> test1;</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">1.641</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">show</span> tables;</span><br><span class="line">OK</span><br><span class="line">tab_name</span><br><span class="line">test1</span><br><span class="line">test2</span><br><span class="line">test3</span><br><span class="line">test4</span><br><span class="line">test5</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.042</span> seconds, Fetched: <span class="number">5</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



<p>（13）增加&#x2F;修改&#x2F;替换列信息</p>
<ol>
<li>语法</li>
</ol>
<p>1）更新列</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER TABLE</span> table_name CHANGE [<span class="keyword">COLUMN</span>] clo_old_name col_new_name</span><br><span class="line">column_type [COMMENT col_comment] [<span class="keyword">FIRST</span><span class="operator">|</span>AFTER column_name]</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> test6;</span><br><span class="line">OK</span><br><span class="line">test6.id        test6.age</span><br><span class="line"><span class="number">112</span>     <span class="number">12</span></span><br><span class="line"><span class="number">113</span>     <span class="number">13</span></span><br><span class="line"><span class="number">114</span>     <span class="number">14</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.198</span> seconds, Fetched: <span class="number">3</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">desc</span> test6;</span><br><span class="line">OK</span><br><span class="line">col_name        data_type       comment</span><br><span class="line">id                      <span class="type">int</span></span><br><span class="line">age                     <span class="type">int</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.084</span> seconds, Fetched: <span class="number">2</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">alter table</span> test6 change id stu_id string;</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.284</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> test6;</span><br><span class="line">OK</span><br><span class="line">test6.stu_id    test6.age</span><br><span class="line"><span class="number">112</span>     <span class="number">12</span></span><br><span class="line"><span class="number">113</span>     <span class="number">13</span></span><br><span class="line"><span class="number">114</span>     <span class="number">14</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.158</span> seconds, Fetched: <span class="number">3</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



<p>2)增加和替换列</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER TABLE</span> table_name <span class="keyword">ADD</span><span class="operator">|</span>REPLACE COLUMNS (col_name data_type [COMMENT col_comment], ...)</span><br></pre></td></tr></table></figure>

<p>注：ADD是代表新增一字段，字段位置在所有列后面(partition 列明)，</p>
<p>REPLACE 则是表示替换表中所有字段</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"># 添加列</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">alter table</span> test6 <span class="keyword">add</span> columns (name string);</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.164</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">desc</span> test6;</span><br><span class="line">OK</span><br><span class="line">col_name        data_type       comment</span><br><span class="line">stu_id                  string</span><br><span class="line">age                     <span class="type">int</span></span><br><span class="line">name                    string</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.046</span> seconds, Fetched: <span class="number">3</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> test6;</span><br><span class="line">OK</span><br><span class="line">test6.stu_id    test6.age       test6.name</span><br><span class="line"><span class="number">112</span>     <span class="number">12</span>      <span class="keyword">NULL</span></span><br><span class="line"><span class="number">113</span>     <span class="number">13</span>      <span class="keyword">NULL</span></span><br><span class="line"><span class="number">114</span>     <span class="number">14</span>      <span class="keyword">NULL</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.194</span> seconds, Fetched: <span class="number">3</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br><span class="line"></span><br><span class="line"># 替换列（可以当删除用）</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">alter table</span> test6 replace columns (stu_id  string, age <span class="type">int</span>);</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.148</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> test6;</span><br><span class="line">OK</span><br><span class="line">test6.stu_id    test6.age</span><br><span class="line"><span class="number">112</span>     <span class="number">12</span></span><br><span class="line"><span class="number">113</span>     <span class="number">13</span></span><br><span class="line"><span class="number">114</span>     <span class="number">14</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.144</span> seconds, Fetched: <span class="number">3</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



<p>（14）删除表</p>
<p>语法：drop table dept;</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">show</span> tables;</span><br><span class="line">OK</span><br><span class="line">tab_name</span><br><span class="line">test1</span><br><span class="line">test2</span><br><span class="line">test5</span><br><span class="line">test6</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.024</span> seconds, Fetched: <span class="number">4</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">drop</span> <span class="keyword">table</span> test2;</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.19</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">show</span> tables;</span><br><span class="line">OK</span><br><span class="line">tab_name</span><br><span class="line">test1</span><br><span class="line">test5</span><br><span class="line">test6</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.022</span> seconds, Fetched: <span class="number">3</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>





<h4 id="八、DML数据操作"><a href="#八、DML数据操作" class="headerlink" title="八、DML数据操作"></a>八、DML数据操作</h4><p>（1）向表中装载数据（Load）</p>
<ol>
<li>语法： load data [local] inpath ‘数据的path’ [overwrite] into table student [partition (partcoll&#x3D;vall, …)];</li>
</ol>
<p>1）load data : 代表加载数据</p>
<p>2）local : 表示从本地加载数据到hive表，否则从HDFS加载数据到hive表</p>
<p>3）inpath : 表示加载数据的路径</p>
<p>4）overwrite : 表示覆盖表中已有数据，否则表示追加</p>
<p>5）into table : 表示加载到哪张表</p>
<p>6）student : 表示具体的表</p>
<p>7）partition : 表示上传到指定分区</p>
<ol start="2">
<li>创建一张student表</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">create table</span> student(id string, name string) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span>;</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.094</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/opt/module/hive/student.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> student;</span><br><span class="line">Loading data <span class="keyword">to</span> <span class="keyword">table</span> default.student</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.348</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student;</span><br><span class="line">OK</span><br><span class="line">student.id      student.name</span><br><span class="line"><span class="number">20220001</span>         张三</span><br><span class="line"><span class="number">20220002</span>         李四</span><br><span class="line"><span class="number">20220003</span>         王五</span><br><span class="line"><span class="number">20220004</span>         马六</span><br><span class="line"><span class="number">20220005</span>         李八</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.136</span> seconds, Fetched: <span class="number">5</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



<p>（2）通过查询语句向表中插入数据（Insert）</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student1;</span><br><span class="line">OK</span><br><span class="line">student1.id     student1.name</span><br><span class="line"><span class="number">20220006</span>         周莒</span><br><span class="line"><span class="number">20220007</span>         宋交</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.121</span> seconds, Fetched: <span class="number">2</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">insert into</span> student</span><br><span class="line">              <span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student1;</span><br><span class="line">Query ID <span class="operator">=</span> root_20231219195754_6d187e86<span class="number">-1528</span><span class="number">-4</span>ce0<span class="operator">-</span>a748<span class="number">-1</span>b6daf9508c9</span><br><span class="line">Total jobs <span class="operator">=</span> <span class="number">3</span></span><br><span class="line">Launching Job <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">3</span></span><br><span class="line">Number <span class="keyword">of</span> reduce tasks determined <span class="keyword">at</span> compile <span class="type">time</span>: <span class="number">1</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> limit the maximum number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.max<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">set</span> a constant number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line">Starting Job <span class="operator">=</span> job_1702967178714_0003, Tracking URL <span class="operator">=</span> http:<span class="operator">/</span><span class="operator">/</span>hadoop302:<span class="number">8088</span><span class="operator">/</span>proxy<span class="operator">/</span>application_1702967178714_0003<span class="operator">/</span></span><br><span class="line">Kill Command <span class="operator">=</span> <span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>hadoop<span class="operator">/</span>bin<span class="operator">/</span>mapred job  <span class="operator">-</span>kill job_1702967178714_0003</span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage<span class="number">-1</span>: number <span class="keyword">of</span> mappers: <span class="number">1</span>; number <span class="keyword">of</span> reducers: <span class="number">1</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-19</span> <span class="number">19</span>:<span class="number">58</span>:<span class="number">20</span>,<span class="number">182</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-19</span> <span class="number">19</span>:<span class="number">58</span>:<span class="number">56</span>,<span class="number">139</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span></span><br><span class="line">Ended Job <span class="operator">=</span> job_1702967178714_0003 <span class="keyword">with</span> errors</span><br><span class="line">Error during job, obtaining debugging information...</span><br><span class="line">Examining task ID: task_1702967178714_0003_m_000000 (<span class="keyword">and</span> more) <span class="keyword">from</span> job job_1702967178714_0003</span><br><span class="line"></span><br><span class="line">Task <span class="keyword">with</span> the most failures(<span class="number">4</span>):</span><br><span class="line"><span class="comment">-----</span></span><br><span class="line">Task ID:</span><br><span class="line">  task_1702967178714_0003_m_000000</span><br><span class="line"></span><br><span class="line">URL:</span><br><span class="line">  http:<span class="operator">/</span><span class="operator">/</span>hadoop302:<span class="number">8088</span><span class="operator">/</span>taskdetails.jsp?jobid<span class="operator">=</span>job_1702967178714_0003<span class="operator">&amp;</span>tipid<span class="operator">=</span>task_1702967178714_0003_m_000000</span><br><span class="line"><span class="comment">-----</span></span><br><span class="line">Diagnostic Messages <span class="keyword">for</span> this Task:</span><br><span class="line">[<span class="number">2023</span><span class="number">-12</span><span class="number">-19</span> <span class="number">19</span>:<span class="number">58</span>:<span class="number">54.547</span>]Container [pid<span class="operator">=</span><span class="number">7087</span>,containerID<span class="operator">=</span>container_1702967178714_0003_01_000005] <span class="keyword">is</span> <span class="keyword">running</span> <span class="number">268880384</span>B beyond the <span class="string">&#x27;VIRTUAL&#x27;</span> memory limit. <span class="keyword">Current</span> usage: <span class="number">175.9</span> MB <span class="keyword">of</span> <span class="number">1</span> GB physical memory used; <span class="number">2.4</span> GB <span class="keyword">of</span> <span class="number">2.1</span> GB virtual memory used. Killing container.</span><br><span class="line">Dump <span class="keyword">of</span> the process<span class="operator">-</span>tree <span class="keyword">for</span> container_1702967178714_0003_01_000005 :</span><br><span class="line">        <span class="operator">|</span><span class="operator">-</span> PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) <span class="built_in">SYSTEM_TIME</span>(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE</span><br><span class="line">        <span class="operator">|</span><span class="operator">-</span> <span class="number">7099</span> <span class="number">7087</span> <span class="number">7087</span> <span class="number">7087</span> (java) <span class="number">466</span> <span class="number">85</span> <span class="number">2513940480</span> <span class="number">44743</span> <span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>jdk<span class="operator">/</span>bin<span class="operator">/</span>java <span class="operator">-</span>Djava.net.preferIPv4Stack<span class="operator">=</span><span class="literal">true</span> <span class="operator">-</span>Dhadoop.metrics.log.level<span class="operator">=</span>WARN <span class="operator">-</span>Xmx820m <span class="operator">-</span>Djava.io.tmpdir<span class="operator">=</span><span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>hadoop<span class="operator">/</span>data<span class="operator">/</span>nm<span class="operator">-</span><span class="keyword">local</span><span class="operator">-</span>dir<span class="operator">/</span>usercache<span class="operator">/</span>root<span class="operator">/</span>appcache<span class="operator">/</span>application_1702967178714_0003<span class="operator">/</span>container_1702967178714_0003_01_000005<span class="operator">/</span>tmp <span class="operator">-</span>Dlog4j.configuration<span class="operator">=</span>container<span class="operator">-</span>log4j.properties <span class="operator">-</span>Dyarn.app.container.log.dir<span class="operator">=</span><span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>hadoop<span class="operator">/</span>logs<span class="operator">/</span>userlogs<span class="operator">/</span>application_1702967178714_0003<span class="operator">/</span>container_1702967178714_0003_01_000005 <span class="operator">-</span>Dyarn.app.container.log.filesize<span class="operator">=</span><span class="number">0</span> <span class="operator">-</span>Dhadoop.root.logger<span class="operator">=</span>INFO,CLA <span class="operator">-</span>Dhadoop.root.logfile<span class="operator">=</span>syslog org.apache.hadoop.mapred.YarnChild <span class="number">192.168</span><span class="number">.137</span><span class="number">.138</span> <span class="number">46636</span> attempt_1702967178714_0003_m_000000_3 <span class="number">5</span></span><br><span class="line">        <span class="operator">|</span><span class="operator">-</span> <span class="number">7087</span> <span class="number">7086</span> <span class="number">7087</span> <span class="number">7087</span> (bash) <span class="number">0</span> <span class="number">0</span> <span class="number">9797632</span> <span class="number">287</span> <span class="operator">/</span>bin<span class="operator">/</span>bash <span class="operator">-</span>c <span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>jdk<span class="operator">/</span>bin<span class="operator">/</span>java <span class="operator">-</span>Djava.net.preferIPv4Stack<span class="operator">=</span><span class="literal">true</span> <span class="operator">-</span>Dhadoop.metrics.log.level<span class="operator">=</span>WARN   <span class="operator">-</span>Xmx820m <span class="operator">-</span>Djava.io.tmpdir<span class="operator">=</span><span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>hadoop<span class="operator">/</span>data<span class="operator">/</span>nm<span class="operator">-</span><span class="keyword">local</span><span class="operator">-</span>dir<span class="operator">/</span>usercache<span class="operator">/</span>root<span class="operator">/</span>appcache<span class="operator">/</span>application_1702967178714_0003<span class="operator">/</span>container_1702967178714_0003_01_000005<span class="operator">/</span>tmp <span class="operator">-</span>Dlog4j.configuration<span class="operator">=</span>container<span class="operator">-</span>log4j.properties <span class="operator">-</span>Dyarn.app.container.log.dir<span class="operator">=</span><span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>hadoop<span class="operator">/</span>logs<span class="operator">/</span>userlogs<span class="operator">/</span>application_1702967178714_0003<span class="operator">/</span>container_1702967178714_0003_01_000005 <span class="operator">-</span>Dyarn.app.container.log.filesize<span class="operator">=</span><span class="number">0</span> <span class="operator">-</span>Dhadoop.root.logger<span class="operator">=</span>INFO,CLA <span class="operator">-</span>Dhadoop.root.logfile<span class="operator">=</span>syslog org.apache.hadoop.mapred.YarnChild <span class="number">192.168</span><span class="number">.137</span><span class="number">.138</span> <span class="number">46636</span> attempt_1702967178714_0003_m_000000_3 <span class="number">5</span> <span class="number">1</span><span class="operator">&gt;</span><span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>hadoop<span class="operator">/</span>logs<span class="operator">/</span>userlogs<span class="operator">/</span>application_1702967178714_0003<span class="operator">/</span>container_1702967178714_0003_01_000005<span class="operator">/</span>stdout <span class="number">2</span><span class="operator">&gt;</span><span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>hadoop<span class="operator">/</span>logs<span class="operator">/</span>userlogs<span class="operator">/</span>application_1702967178714_0003<span class="operator">/</span>container_1702967178714_0003_01_000005<span class="operator">/</span>stderr</span><br><span class="line"></span><br><span class="line">[<span class="number">2023</span><span class="number">-12</span><span class="number">-19</span> <span class="number">19</span>:<span class="number">58</span>:<span class="number">54.712</span>]Container killed <span class="keyword">on</span> request. Exit code <span class="keyword">is</span> <span class="number">143</span></span><br><span class="line">[<span class="number">2023</span><span class="number">-12</span><span class="number">-19</span> <span class="number">19</span>:<span class="number">58</span>:<span class="number">54.716</span>]Container exited <span class="keyword">with</span> a non<span class="operator">-</span>zero exit code <span class="number">143.</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">FAILED: Execution Error, <span class="keyword">return</span> code <span class="number">2</span> <span class="keyword">from</span> org.apache.hadoop.hive.ql.exec.mr.MapRedTask</span><br><span class="line">MapReduce Jobs Launched:</span><br><span class="line">Stage<span class="operator">-</span>Stage<span class="number">-1</span>: Map: <span class="number">1</span>  Reduce: <span class="number">1</span>   HDFS Read: <span class="number">0</span> HDFS Write: <span class="number">0</span> FAIL</span><br><span class="line">Total MapReduce CPU <span class="type">Time</span> Spent: <span class="number">0</span> msec</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">insert into</span> student <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student1;</span><br><span class="line">Query ID <span class="operator">=</span> root_20231219195923_1cf00028<span class="number">-0</span>c40<span class="number">-4e3</span>f<span class="operator">-</span>a18b<span class="number">-06210</span>d725967</span><br><span class="line">Total jobs <span class="operator">=</span> <span class="number">3</span></span><br><span class="line">Launching Job <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">3</span></span><br><span class="line">Number <span class="keyword">of</span> reduce tasks determined <span class="keyword">at</span> compile <span class="type">time</span>: <span class="number">1</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> limit the maximum number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.max<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">set</span> a constant number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line">Starting Job <span class="operator">=</span> job_1702967178714_0004, Tracking URL <span class="operator">=</span> http:<span class="operator">/</span><span class="operator">/</span>hadoop302:<span class="number">8088</span><span class="operator">/</span>proxy<span class="operator">/</span>application_1702967178714_0004<span class="operator">/</span></span><br><span class="line">Kill Command <span class="operator">=</span> <span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>hadoop<span class="operator">/</span>bin<span class="operator">/</span>mapred job  <span class="operator">-</span>kill job_1702967178714_0004</span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage<span class="number">-1</span>: number <span class="keyword">of</span> mappers: <span class="number">1</span>; number <span class="keyword">of</span> reducers: <span class="number">1</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-19</span> <span class="number">19</span>:<span class="number">59</span>:<span class="number">34</span>,<span class="number">533</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-19</span> <span class="number">19</span>:<span class="number">59</span>:<span class="number">48</span>,<span class="number">078</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>, Cumulative CPU <span class="number">1.23</span> sec</span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-19</span> <span class="number">19</span>:<span class="number">59</span>:<span class="number">55</span>,<span class="number">415</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>, Cumulative CPU <span class="number">2.9</span> sec</span><br><span class="line">MapReduce Total cumulative CPU <span class="type">time</span>: <span class="number">2</span> seconds <span class="number">900</span> msec</span><br><span class="line">Ended Job <span class="operator">=</span> job_1702967178714_0004</span><br><span class="line">Stage<span class="number">-4</span> <span class="keyword">is</span> selected <span class="keyword">by</span> <span class="keyword">condition</span> resolver.</span><br><span class="line">Stage<span class="number">-3</span> <span class="keyword">is</span> filtered <span class="keyword">out</span> <span class="keyword">by</span> <span class="keyword">condition</span> resolver.</span><br><span class="line">Stage<span class="number">-5</span> <span class="keyword">is</span> filtered <span class="keyword">out</span> <span class="keyword">by</span> <span class="keyword">condition</span> resolver.</span><br><span class="line">Moving data <span class="keyword">to</span> directory hdfs:<span class="operator">/</span><span class="operator">/</span>hadoop301:<span class="number">8020</span><span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>student<span class="operator">/</span>.hive<span class="operator">-</span>staging_hive_2023<span class="number">-12</span><span class="number">-19</span>_19<span class="number">-59</span><span class="number">-23</span>_302_4974531779442527462<span class="number">-1</span><span class="operator">/</span><span class="operator">-</span>ext<span class="number">-10000</span></span><br><span class="line">Loading data <span class="keyword">to</span> <span class="keyword">table</span> default.student</span><br><span class="line">MapReduce Jobs Launched:</span><br><span class="line">Stage<span class="operator">-</span>Stage<span class="number">-1</span>: Map: <span class="number">1</span>  Reduce: <span class="number">1</span>   Cumulative CPU: <span class="number">2.9</span> sec   HDFS Read: <span class="number">12982</span> HDFS Write: <span class="number">280</span> SUCCESS</span><br><span class="line">Total MapReduce CPU <span class="type">Time</span> Spent: <span class="number">2</span> seconds <span class="number">900</span> msec</span><br><span class="line">OK</span><br><span class="line">student1.id     student1.name</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">33.929</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student;</span><br><span class="line">OK</span><br><span class="line">student.id      student.name</span><br><span class="line"><span class="number">20220006</span>         周莒</span><br><span class="line"><span class="number">20220007</span>         宋交</span><br><span class="line"><span class="number">20220001</span>         张三</span><br><span class="line"><span class="number">20220002</span>         李四</span><br><span class="line"><span class="number">20220003</span>         王五</span><br><span class="line"><span class="number">20220004</span>         马六</span><br><span class="line"><span class="number">20220005</span>         李八</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.108</span> seconds, Fetched: <span class="number">7</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



<p>（3）查询语句中创建表并加载数据（As Select）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; create table student6</span><br><span class="line">              &gt; as</span><br><span class="line">              &gt; select id, name from student;</span><br><span class="line">Query ID = root_20231220151817_d4429601-40a2-49e5-b96e-fe607118c492</span><br><span class="line">Total jobs = 3</span><br><span class="line">Launching Job 1 out of 3</span><br><span class="line">Number of reduce tasks is set to 0 since there&#x27;s no reduce operator</span><br><span class="line">Starting Job = job_1703052903664_0001, Tracking URL = http://hadoop302:8088/proxy/application_1703052903664_0001/</span><br><span class="line">Kill Command = /opt/module/hadoop/bin/mapred job  -kill job_1703052903664_0001</span><br><span class="line">Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0</span><br><span class="line">2023-12-20 15:18:42,953 Stage-1 map = 0%,  reduce = 0%</span><br><span class="line">2023-12-20 15:19:04,039 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.15 sec</span><br><span class="line">MapReduce Total cumulative CPU time: 2 seconds 150 msec</span><br><span class="line">Ended Job = job_1703052903664_0001</span><br><span class="line">Stage-4 is selected by condition resolver.</span><br><span class="line">Stage-3 is filtered out by condition resolver.</span><br><span class="line">Stage-5 is filtered out by condition resolver.</span><br><span class="line">Moving data to directory hdfs://hadoop301:8020/user/hive/warehouse/.hive-staging_hive_2023-12-20_15-18-17_297_1964929230240087285-1/-ext-10002</span><br><span class="line">Moving data to directory hdfs://hadoop301:8020/user/hive/warehouse/student6</span><br><span class="line">MapReduce Jobs Launched:</span><br><span class="line">Stage-Stage-1: Map: 1   Cumulative CPU: 2.15 sec   HDFS Read: 4883 HDFS Write: 192 SUCCESS</span><br><span class="line">Total MapReduce CPU Time Spent: 2 seconds 150 msec</span><br><span class="line">OK</span><br><span class="line">id      name</span><br><span class="line">Time taken: 52.991 seconds</span><br><span class="line">student6.id     student6.name</span><br><span class="line">20220006         周莒</span><br><span class="line">20220007         宋交</span><br><span class="line">20220001         张三</span><br><span class="line">20220002         李四</span><br><span class="line">20220003         王五</span><br><span class="line">20220004         马六</span><br><span class="line">20220005         李八</span><br><span class="line">Time taken: 0.16 seconds, Fetched: 7 row(s)</span><br><span class="line">hive (default)&gt;</span><br></pre></td></tr></table></figure>



<p>（4）创建表是通过Location指定加载数据路径</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 hive]# hdfs dfs -<span class="built_in">mkdir</span> /student22</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line">[root@hadoop301 hive]# hdfs dfs -put student.txt /student22</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line">[root@hadoop301 hive]#</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">create table</span> student22(id string, name string) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span> location <span class="string">&#x27;/student22&#x27;</span>;</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.239</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student22;</span><br><span class="line">OK</span><br><span class="line">student22.id    student22.name</span><br><span class="line"><span class="number">20220001</span>         张三</span><br><span class="line"><span class="number">20220002</span>         李四</span><br><span class="line"><span class="number">20220003</span>         王五</span><br><span class="line"><span class="number">20220004</span>         马六</span><br><span class="line"><span class="number">20220005</span>         李八</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.24</span> seconds, Fetched: <span class="number">5</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



<p>（5）数据导出</p>
<ol>
<li>Insert 导出</li>
</ol>
<p>1）将查询的结果导出到本地</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">insert</span> overwrite <span class="keyword">local</span> directory <span class="string">&#x27;/opt/module/hive/student&#x27;</span></span><br><span class="line"> 			  <span class="operator">&gt;</span> <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line">              <span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student6;</span><br></pre></td></tr></table></figure>



<ol start="2">
<li>Hadoop 命令导出到本地</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> dfs <span class="operator">-</span><span class="keyword">get</span> <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>student22<span class="operator">/</span>student.txt</span><br><span class="line"><span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>hive<span class="operator">/</span>student<span class="operator">/</span>student.txt;</span><br></pre></td></tr></table></figure>



<ol start="3">
<li>Hive Shell 命令导出</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 hive]# bin/hive -e <span class="string">&#x27;select * from default.student6;&#x27;</span> &gt; /opt/module/hive/student/student4.txt;</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line"><span class="built_in">which</span>: no hbase <span class="keyword">in</span> (/opt/module/hive/bin:.:/opt/module/mysql/bin:.:/opt/module/hadoop/bin:/opt/module/hadoop/sbin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/module/jdk/bin:/root/bin)</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line">Hive Session ID = abafbe66-a1bb-420e-b01a-cc99e4ff61d2</span><br><span class="line"></span><br><span class="line">Logging initialized using configuration <span class="keyword">in</span> file:/opt/module/hive/conf/hive-log4j2.properties Async: <span class="literal">true</span></span><br><span class="line">Hive Session ID = 0fc9fe17-2e7e-4791-acff-a2d8f2cc0433</span><br><span class="line">OK</span><br><span class="line">Time taken: 8.49 seconds, Fetched: 7 row(s)</span><br><span class="line">[root@hadoop301 hive]# <span class="built_in">cd</span> student/</span><br><span class="line">[root@hadoop301 student]# ll</span><br><span class="line">总用量 4</span><br><span class="line">-rw-r--r--. 1 root root 145 12月 20 16:20 student4.txt</span><br><span class="line">[root@hadoop301 student]# <span class="built_in">cat</span> student4.txt</span><br><span class="line">student6.id     student6.name</span><br><span class="line">20220006         周莒</span><br><span class="line">20220007         宋交</span><br><span class="line">20220001         张三</span><br><span class="line">20220002         李四</span><br><span class="line">20220003         王五</span><br><span class="line">20220004         马六</span><br><span class="line">20220005         李八</span><br><span class="line">[root@hadoop301 student]#</span><br></pre></td></tr></table></figure>



<p>（6）清空表中的数据（Truncate）</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">truncate</span> <span class="keyword">table</span> student;</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">2.108</span> seconds</span><br><span class="line">hive(<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>

<p>注意：Truncate 只能删除管理表，不能删除外部表中数据</p>
<h4 id="九、查询"><a href="#九、查询" class="headerlink" title="九、查询"></a>九、查询</h4><p>（1）数据准备：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 module]# <span class="built_in">cd</span> data/</span><br><span class="line">[root@hadoop301 data]# vim dept.txt</span><br><span class="line">[root@hadoop301 data]# <span class="built_in">cat</span> dept.txt</span><br><span class="line">10      ACCOUNTING      1700</span><br><span class="line">20      RESEARCH        1800</span><br><span class="line">30      SALES   1900</span><br><span class="line">40      OPERATIONS      1700</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@hadoop301 data]# vim emp.txt</span><br><span class="line">[root@hadoop301 data]# <span class="built_in">cat</span> emp.txt</span><br><span class="line">7369    SMITH   CLERK   7902    1980-12-17      800.00          20</span><br><span class="line">7499    ALLEN   SALESMAN        7689    1981-2-20       1600.00 300.00  30</span><br><span class="line">7521    WARD    SALESMAN        7698    1981-2-22       1250.00 500.00  30</span><br><span class="line">7566    JONES   MANAGER 7839    1981-4-2        2975.00         20</span><br><span class="line">7654    MARTIN  SALESMAN        7689    1981-8-28       1250.00 1400.00 30</span><br><span class="line">7698    BLAKE   MANAGER 7839    1981-5-1        2850.00         30</span><br><span class="line">7782    CLARK   MANARER 7829    1981-6-9        2450.00         10</span><br><span class="line">7788    SCOTT   ANALYST 7566    1987-4-19       3000.00         20</span><br><span class="line">7839    KING    PRESIDENT       1981-11-17      5000.00                 10</span><br><span class="line">7844    TURNER  SALESMAN        7698    1981-9-8        1500.00 0.00    30</span><br><span class="line">7876    ADAMS   CLERK   7788    1987-5-23       1100.00         20</span><br><span class="line">7900    JAMES   CLERK   7698    1981-12-3       950.00          30</span><br><span class="line">7902    FORD    ANALYST 7566    1981-12-3       3000.00         20</span><br><span class="line">79934   MILLER  CLERK   7782    1982-1-23       1300.00         10</span><br><span class="line">[root@hadoop301 data]#</span><br></pre></td></tr></table></figure>

<ol>
<li>创建表名表</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">create table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> dept(deptno <span class="type">int</span>, dname string, loc <span class="type">int</span>) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">1.837</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>创建员工表</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">create table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> emp(empno <span class="type">int</span>, ename string, job string, mgr <span class="type">int</span>, hiredate string, sal <span class="keyword">double</span>, comm <span class="keyword">double</span>, deptno <span class="type">int</span>) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.106</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>导入数据</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/opt/module/data/dept.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> dept;</span><br><span class="line">Loading data <span class="keyword">to</span> <span class="keyword">table</span> default.dept</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">1.036</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> dept;</span><br><span class="line">OK</span><br><span class="line">dept.deptno     dept.dname      dept.loc</span><br><span class="line"><span class="number">10</span>      ACCOUNTING      <span class="number">1700</span></span><br><span class="line"><span class="number">20</span>      RESEARCH        <span class="number">1800</span></span><br><span class="line"><span class="number">30</span>      SALES   <span class="number">1900</span></span><br><span class="line"><span class="number">40</span>      OPERATIONS      <span class="number">1700</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">2.971</span> seconds, Fetched: <span class="number">4</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/opt/module/data/emp.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> emp;</span><br><span class="line">Loading data <span class="keyword">to</span> <span class="keyword">table</span> default.emp</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.646</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp;</span><br><span class="line">OK</span><br><span class="line">emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno</span><br><span class="line"><span class="number">7369</span>    SMITH   CLERK   <span class="number">7902</span>    <span class="number">1980</span><span class="number">-12</span><span class="number">-17</span>      <span class="number">800.0</span>   <span class="keyword">NULL</span>    <span class="number">20</span></span><br><span class="line"><span class="number">7499</span>    ALLEN   SALESMAN        <span class="number">7689</span>    <span class="number">1981</span><span class="number">-2</span><span class="number">-20</span>       <span class="number">1600.0</span>  <span class="number">300.0</span>   <span class="number">30</span></span><br><span class="line"><span class="number">7521</span>    WARD    SALESMAN        <span class="number">7698</span>    <span class="number">1981</span><span class="number">-2</span><span class="number">-22</span>       <span class="number">1250.0</span>  <span class="number">500.0</span>   <span class="number">30</span></span><br><span class="line"><span class="number">7566</span>    JONES   MANAGER <span class="number">7839</span>    <span class="number">1981</span><span class="number">-4</span><span class="number">-2</span>        <span class="number">2975.0</span>  <span class="keyword">NULL</span>    <span class="number">20</span></span><br><span class="line"><span class="number">7654</span>    MARTIN  SALESMAN        <span class="number">7689</span>    <span class="number">1981</span><span class="number">-8</span><span class="number">-28</span>       <span class="number">1250.0</span>  <span class="number">1400.0</span>  <span class="number">30</span></span><br><span class="line"><span class="number">7698</span>    BLAKE   MANAGER <span class="number">7839</span>    <span class="number">1981</span><span class="number">-5</span><span class="number">-1</span>        <span class="number">2850.0</span>  <span class="keyword">NULL</span>    <span class="number">30</span></span><br><span class="line"><span class="number">7782</span>    CLARK   MANARER <span class="number">7829</span>    <span class="number">1981</span><span class="number">-6</span><span class="number">-9</span>        <span class="number">2450.0</span>  <span class="keyword">NULL</span>    <span class="number">10</span></span><br><span class="line"><span class="number">7788</span>    SCOTT   ANALYST <span class="number">7566</span>    <span class="number">1987</span><span class="number">-4</span><span class="number">-19</span>       <span class="number">3000.0</span>  <span class="keyword">NULL</span>    <span class="number">20</span></span><br><span class="line"><span class="number">7839</span>    KING    PRESIDENT       <span class="keyword">NULL</span>    <span class="number">5000.00</span> <span class="keyword">NULL</span>    <span class="keyword">NULL</span>    <span class="number">10</span></span><br><span class="line"><span class="number">7844</span>    TURNER  SALESMAN        <span class="number">7698</span>    <span class="number">1981</span><span class="number">-9</span><span class="number">-8</span>        <span class="number">1500.0</span>  <span class="number">0.0</span>     <span class="number">30</span></span><br><span class="line"><span class="number">7876</span>    ADAMS   CLERK   <span class="number">7788</span>    <span class="number">1987</span><span class="number">-5</span><span class="number">-23</span>       <span class="number">1100.0</span>  <span class="keyword">NULL</span>    <span class="number">20</span></span><br><span class="line"><span class="number">7900</span>    JAMES   CLERK   <span class="number">7698</span>    <span class="number">1981</span><span class="number">-12</span><span class="number">-3</span>       <span class="number">950.0</span>   <span class="keyword">NULL</span>    <span class="number">30</span></span><br><span class="line"><span class="number">7902</span>    FORD    ANALYST <span class="number">7566</span>    <span class="number">1981</span><span class="number">-12</span><span class="number">-3</span>       <span class="number">3000.0</span>  <span class="keyword">NULL</span>    <span class="number">20</span></span><br><span class="line"><span class="number">79934</span>   MILLER  CLERK   <span class="number">7782</span>    <span class="number">1982</span><span class="number">-1</span><span class="number">-23</span>       <span class="number">1300.0</span>  <span class="keyword">NULL</span>    <span class="number">10</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.238</span> seconds, Fetched: <span class="number">14</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



<p>（2）全表查询</p>
<p>略……..</p>
<p>（3）列取别名</p>
<p>略……..</p>
<p>（4）算术运算符</p>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271727322.png" alt="image-20231220190659770"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> ename, sal <span class="operator">+</span> <span class="number">1000</span> <span class="keyword">from</span> emp;</span><br><span class="line">OK</span><br><span class="line">ename   _c1</span><br><span class="line">SMITH   <span class="number">1800.0</span></span><br><span class="line">ALLEN   <span class="number">2600.0</span></span><br><span class="line">WARD    <span class="number">2250.0</span></span><br><span class="line">JONES   <span class="number">3975.0</span></span><br><span class="line">MARTIN  <span class="number">2250.0</span></span><br><span class="line">BLAKE   <span class="number">3850.0</span></span><br><span class="line">CLARK   <span class="number">3450.0</span></span><br><span class="line">SCOTT   <span class="number">4000.0</span></span><br><span class="line">KING    <span class="keyword">NULL</span></span><br><span class="line">TURNER  <span class="number">2500.0</span></span><br><span class="line">ADAMS   <span class="number">2100.0</span></span><br><span class="line">JAMES   <span class="number">1950.0</span></span><br><span class="line">FORD    <span class="number">4000.0</span></span><br><span class="line">MILLER  <span class="number">2300.0</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.909</span> seconds, Fetched: <span class="number">14</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



<p>（5）常用函数</p>
<ol>
<li>求总行数（count）</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">from</span> emp;</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>求工资的最大值（max）</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">max</span>(sal) <span class="keyword">from</span> emp;</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>求工资的最小值（min）</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">min</span>(sal) <span class="keyword">from</span> emp;</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>求工资的总和（sum）</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">sum</span>(sal) <span class="keyword">from</span> emp;</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>求工资的平均值（avg）</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">avg</span>(sal) <span class="keyword">from</span> emp;</span><br></pre></td></tr></table></figure>



<p>（6）Limit 语句</p>
<p>略………</p>
<p>（7）Where语句</p>
<p>略………</p>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271705040.png" alt="image-20231220192059045"></p>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271706806.png" alt="image-20231220192256820"></p>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271706861.png" alt="image-20231220192416279"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> ename <span class="operator">=</span> <span class="string">&#x27;ALLEN&#x27;</span>;</span><br><span class="line">OK</span><br><span class="line">emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno</span><br><span class="line"><span class="number">7499</span>    ALLEN   SALESMAN        <span class="number">7689</span>    <span class="number">1981</span><span class="number">-2</span><span class="number">-20</span>       <span class="number">1600.0</span>  <span class="number">300.0</span>   <span class="number">30</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">6.775</span> seconds, Fetched: <span class="number">1</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> sal <span class="keyword">between</span> <span class="number">800</span> <span class="keyword">and</span> <span class="number">1100</span>;</span><br><span class="line">OK</span><br><span class="line">emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno</span><br><span class="line"><span class="number">7369</span>    SMITH   CLERK   <span class="number">7902</span>    <span class="number">1980</span><span class="number">-12</span><span class="number">-17</span>      <span class="number">800.0</span>   <span class="keyword">NULL</span>    <span class="number">20</span></span><br><span class="line"><span class="number">7876</span>    ADAMS   CLERK   <span class="number">7788</span>    <span class="number">1987</span><span class="number">-5</span><span class="number">-23</span>       <span class="number">1100.0</span>  <span class="keyword">NULL</span>    <span class="number">20</span></span><br><span class="line"><span class="number">7900</span>    JAMES   CLERK   <span class="number">7698</span>    <span class="number">1981</span><span class="number">-12</span><span class="number">-3</span>       <span class="number">950.0</span>   <span class="keyword">NULL</span>    <span class="number">30</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.359</span> seconds, Fetched: <span class="number">3</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> comm <span class="keyword">is</span> <span class="keyword">null</span>;</span><br><span class="line">OK</span><br><span class="line">emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno</span><br><span class="line"><span class="number">7369</span>    SMITH   CLERK   <span class="number">7902</span>    <span class="number">1980</span><span class="number">-12</span><span class="number">-17</span>      <span class="number">800.0</span>   <span class="keyword">NULL</span>    <span class="number">20</span></span><br><span class="line"><span class="number">7566</span>    JONES   MANAGER <span class="number">7839</span>    <span class="number">1981</span><span class="number">-4</span><span class="number">-2</span>        <span class="number">2975.0</span>  <span class="keyword">NULL</span>    <span class="number">20</span></span><br><span class="line"><span class="number">7698</span>    BLAKE   MANAGER <span class="number">7839</span>    <span class="number">1981</span><span class="number">-5</span><span class="number">-1</span>        <span class="number">2850.0</span>  <span class="keyword">NULL</span>    <span class="number">30</span></span><br><span class="line"><span class="number">7782</span>    CLARK   MANARER <span class="number">7829</span>    <span class="number">1981</span><span class="number">-6</span><span class="number">-9</span>        <span class="number">2450.0</span>  <span class="keyword">NULL</span>    <span class="number">10</span></span><br><span class="line"><span class="number">7788</span>    SCOTT   ANALYST <span class="number">7566</span>    <span class="number">1987</span><span class="number">-4</span><span class="number">-19</span>       <span class="number">3000.0</span>  <span class="keyword">NULL</span>    <span class="number">20</span></span><br><span class="line"><span class="number">7839</span>    KING    PRESIDENT       <span class="keyword">NULL</span>    <span class="number">5000.00</span> <span class="keyword">NULL</span>    <span class="keyword">NULL</span>    <span class="number">10</span></span><br><span class="line"><span class="number">7876</span>    ADAMS   CLERK   <span class="number">7788</span>    <span class="number">1987</span><span class="number">-5</span><span class="number">-23</span>       <span class="number">1100.0</span>  <span class="keyword">NULL</span>    <span class="number">20</span></span><br><span class="line"><span class="number">7900</span>    JAMES   CLERK   <span class="number">7698</span>    <span class="number">1981</span><span class="number">-12</span><span class="number">-3</span>       <span class="number">950.0</span>   <span class="keyword">NULL</span>    <span class="number">30</span></span><br><span class="line"><span class="number">7902</span>    FORD    ANALYST <span class="number">7566</span>    <span class="number">1981</span><span class="number">-12</span><span class="number">-3</span>       <span class="number">3000.0</span>  <span class="keyword">NULL</span>    <span class="number">20</span></span><br><span class="line"><span class="number">79934</span>   MILLER  CLERK   <span class="number">7782</span>    <span class="number">1982</span><span class="number">-1</span><span class="number">-23</span>       <span class="number">1300.0</span>  <span class="keyword">NULL</span>    <span class="number">10</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.25</span> seconds, Fetched: <span class="number">10</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> sal <span class="keyword">in</span> (<span class="number">1500</span>, <span class="number">5000</span>);</span><br><span class="line">OK</span><br><span class="line">emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno</span><br><span class="line"><span class="number">7839</span>    KING    PRESIDENT       <span class="keyword">NULL</span>    <span class="number">1981</span><span class="number">-11</span><span class="number">-17</span>      <span class="number">5000.0</span>  <span class="keyword">NULL</span>    <span class="number">10</span></span><br><span class="line"><span class="number">7844</span>    TURNER  SALESMAN        <span class="number">7698</span>    <span class="number">1981</span><span class="number">-9</span><span class="number">-8</span>        <span class="number">1500.0</span>  <span class="number">0.0</span>     <span class="number">30</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.319</span> seconds, Fetched: <span class="number">2</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> sal<span class="operator">=</span><span class="number">1500</span> <span class="keyword">or</span> sal <span class="operator">=</span> <span class="number">5000</span>;</span><br><span class="line">OK</span><br><span class="line">emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno</span><br><span class="line"><span class="number">7839</span>    KING    PRESIDENT       <span class="keyword">NULL</span>    <span class="number">1981</span><span class="number">-11</span><span class="number">-17</span>      <span class="number">5000.0</span>  <span class="keyword">NULL</span>    <span class="number">10</span></span><br><span class="line"><span class="number">7844</span>    TURNER  SALESMAN        <span class="number">7698</span>    <span class="number">1981</span><span class="number">-9</span><span class="number">-8</span>        <span class="number">1500.0</span>  <span class="number">0.0</span>     <span class="number">30</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.275</span> seconds, Fetched: <span class="number">2</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>





<p>（8）Like 和 RLike</p>
<ol>
<li>使用LIKE 运算选择类似的值</li>
<li>选择条件可以包含字符或数字</li>
</ol>
<p>“%” 代表零个或多个字符（任意个字符）</p>
<p>“_”   代表一个字符</p>
<ol start="3">
<li>RLIKE子句</li>
</ol>
<p>RLIKE 子句是Hive中这个功能的一个扩展，其可以通过Java的正则表达式这个更强大的语言来指定匹配条件。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"># 查询名字以A开头的员工信息</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> ename <span class="keyword">like</span> <span class="string">&#x27;A%&#x27;</span>;</span><br><span class="line">OK</span><br><span class="line">emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno</span><br><span class="line"><span class="number">7499</span>    ALLEN   SALESMAN        <span class="number">7689</span>    <span class="number">1981</span><span class="number">-2</span><span class="number">-20</span>       <span class="number">1600.0</span>  <span class="number">300.0</span>   <span class="number">30</span></span><br><span class="line"><span class="number">7876</span>    ADAMS   CLERK   <span class="number">7788</span>    <span class="number">1987</span><span class="number">-5</span><span class="number">-23</span>       <span class="number">1100.0</span>  <span class="keyword">NULL</span>    <span class="number">20</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.258</span> seconds, Fetched: <span class="number">2</span> <span class="type">row</span>(s)</span><br><span class="line"></span><br><span class="line"># 查询名字中第二个字母为A的员工信息</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> ename <span class="keyword">like</span> <span class="string">&#x27;_A%&#x27;</span>;</span><br><span class="line">OK</span><br><span class="line">emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno</span><br><span class="line"><span class="number">7521</span>    WARD    SALESMAN        <span class="number">7698</span>    <span class="number">1981</span><span class="number">-2</span><span class="number">-22</span>       <span class="number">1250.0</span>  <span class="number">500.0</span>   <span class="number">30</span></span><br><span class="line"><span class="number">7654</span>    MARTIN  SALESMAN        <span class="number">7689</span>    <span class="number">1981</span><span class="number">-8</span><span class="number">-28</span>       <span class="number">1250.0</span>  <span class="number">1400.0</span>  <span class="number">30</span></span><br><span class="line"><span class="number">7900</span>    JAMES   CLERK   <span class="number">7698</span>    <span class="number">1981</span><span class="number">-12</span><span class="number">-3</span>       <span class="number">950.0</span>   <span class="keyword">NULL</span>    <span class="number">30</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.266</span> seconds, Fetched: <span class="number">3</span> <span class="type">row</span>(s)</span><br><span class="line"></span><br><span class="line"># 查询名字中带有A的员工信息 法一</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> ename rlike <span class="string">&#x27;[A]&#x27;</span>;</span><br><span class="line">OK</span><br><span class="line">emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno</span><br><span class="line"><span class="number">7499</span>    ALLEN   SALESMAN        <span class="number">7689</span>    <span class="number">1981</span><span class="number">-2</span><span class="number">-20</span>       <span class="number">1600.0</span>  <span class="number">300.0</span>   <span class="number">30</span></span><br><span class="line"><span class="number">7521</span>    WARD    SALESMAN        <span class="number">7698</span>    <span class="number">1981</span><span class="number">-2</span><span class="number">-22</span>       <span class="number">1250.0</span>  <span class="number">500.0</span>   <span class="number">30</span></span><br><span class="line"><span class="number">7654</span>    MARTIN  SALESMAN        <span class="number">7689</span>    <span class="number">1981</span><span class="number">-8</span><span class="number">-28</span>       <span class="number">1250.0</span>  <span class="number">1400.0</span>  <span class="number">30</span></span><br><span class="line"><span class="number">7698</span>    BLAKE   MANAGER <span class="number">7839</span>    <span class="number">1981</span><span class="number">-5</span><span class="number">-1</span>        <span class="number">2850.0</span>  <span class="keyword">NULL</span>    <span class="number">30</span></span><br><span class="line"><span class="number">7782</span>    CLARK   MANARER <span class="number">7829</span>    <span class="number">1981</span><span class="number">-6</span><span class="number">-9</span>        <span class="number">2450.0</span>  <span class="keyword">NULL</span>    <span class="number">10</span></span><br><span class="line"><span class="number">7876</span>    ADAMS   CLERK   <span class="number">7788</span>    <span class="number">1987</span><span class="number">-5</span><span class="number">-23</span>       <span class="number">1100.0</span>  <span class="keyword">NULL</span>    <span class="number">20</span></span><br><span class="line"><span class="number">7900</span>    JAMES   CLERK   <span class="number">7698</span>    <span class="number">1981</span><span class="number">-12</span><span class="number">-3</span>       <span class="number">950.0</span>   <span class="keyword">NULL</span>    <span class="number">30</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.187</span> seconds, Fetched: <span class="number">7</span> <span class="type">row</span>(s)</span><br><span class="line"></span><br><span class="line"># 查询名字中带有A的员工信息 法二</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> ename <span class="keyword">like</span> <span class="string">&#x27;%A%&#x27;</span>;</span><br><span class="line">OK</span><br><span class="line">emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno</span><br><span class="line"><span class="number">7499</span>    ALLEN   SALESMAN        <span class="number">7689</span>    <span class="number">1981</span><span class="number">-2</span><span class="number">-20</span>       <span class="number">1600.0</span>  <span class="number">300.0</span>   <span class="number">30</span></span><br><span class="line"><span class="number">7521</span>    WARD    SALESMAN        <span class="number">7698</span>    <span class="number">1981</span><span class="number">-2</span><span class="number">-22</span>       <span class="number">1250.0</span>  <span class="number">500.0</span>   <span class="number">30</span></span><br><span class="line"><span class="number">7654</span>    MARTIN  SALESMAN        <span class="number">7689</span>    <span class="number">1981</span><span class="number">-8</span><span class="number">-28</span>       <span class="number">1250.0</span>  <span class="number">1400.0</span>  <span class="number">30</span></span><br><span class="line"><span class="number">7698</span>    BLAKE   MANAGER <span class="number">7839</span>    <span class="number">1981</span><span class="number">-5</span><span class="number">-1</span>        <span class="number">2850.0</span>  <span class="keyword">NULL</span>    <span class="number">30</span></span><br><span class="line"><span class="number">7782</span>    CLARK   MANARER <span class="number">7829</span>    <span class="number">1981</span><span class="number">-6</span><span class="number">-9</span>        <span class="number">2450.0</span>  <span class="keyword">NULL</span>    <span class="number">10</span></span><br><span class="line"><span class="number">7876</span>    ADAMS   CLERK   <span class="number">7788</span>    <span class="number">1987</span><span class="number">-5</span><span class="number">-23</span>       <span class="number">1100.0</span>  <span class="keyword">NULL</span>    <span class="number">20</span></span><br><span class="line"><span class="number">7900</span>    JAMES   CLERK   <span class="number">7698</span>    <span class="number">1981</span><span class="number">-12</span><span class="number">-3</span>       <span class="number">950.0</span>   <span class="keyword">NULL</span>    <span class="number">30</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.183</span> seconds, Fetched: <span class="number">7</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



<p>（9）逻辑运算符（And&#x2F;Or&#x2F;Not）</p>
<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271706429.png" alt="image-20231220195301873"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> sal <span class="operator">&gt;</span> <span class="number">1000</span> <span class="keyword">and</span> deptno <span class="operator">=</span> <span class="number">30</span>;</span><br><span class="line">OK</span><br><span class="line">emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno</span><br><span class="line"><span class="number">7499</span>    ALLEN   SALESMAN        <span class="number">7689</span>    <span class="number">1981</span><span class="number">-2</span><span class="number">-20</span>       <span class="number">1600.0</span>  <span class="number">300.0</span>   <span class="number">30</span></span><br><span class="line"><span class="number">7521</span>    WARD    SALESMAN        <span class="number">7698</span>    <span class="number">1981</span><span class="number">-2</span><span class="number">-22</span>       <span class="number">1250.0</span>  <span class="number">500.0</span>   <span class="number">30</span></span><br><span class="line"><span class="number">7654</span>    MARTIN  SALESMAN        <span class="number">7689</span>    <span class="number">1981</span><span class="number">-8</span><span class="number">-28</span>       <span class="number">1250.0</span>  <span class="number">1400.0</span>  <span class="number">30</span></span><br><span class="line"><span class="number">7698</span>    BLAKE   MANAGER <span class="number">7839</span>    <span class="number">1981</span><span class="number">-5</span><span class="number">-1</span>        <span class="number">2850.0</span>  <span class="keyword">NULL</span>    <span class="number">30</span></span><br><span class="line"><span class="number">7844</span>    TURNER  SALESMAN        <span class="number">7698</span>    <span class="number">1981</span><span class="number">-9</span><span class="number">-8</span>        <span class="number">1500.0</span>  <span class="number">0.0</span>     <span class="number">30</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.265</span> seconds, Fetched: <span class="number">5</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> comm <span class="keyword">is</span> <span class="keyword">not null</span>;</span><br><span class="line">OK</span><br><span class="line">emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno</span><br><span class="line"><span class="number">7499</span>    ALLEN   SALESMAN        <span class="number">7689</span>    <span class="number">1981</span><span class="number">-2</span><span class="number">-20</span>       <span class="number">1600.0</span>  <span class="number">300.0</span>   <span class="number">30</span></span><br><span class="line"><span class="number">7521</span>    WARD    SALESMAN        <span class="number">7698</span>    <span class="number">1981</span><span class="number">-2</span><span class="number">-22</span>       <span class="number">1250.0</span>  <span class="number">500.0</span>   <span class="number">30</span></span><br><span class="line"><span class="number">7654</span>    MARTIN  SALESMAN        <span class="number">7689</span>    <span class="number">1981</span><span class="number">-8</span><span class="number">-28</span>       <span class="number">1250.0</span>  <span class="number">1400.0</span>  <span class="number">30</span></span><br><span class="line"><span class="number">7844</span>    TURNER  SALESMAN        <span class="number">7698</span>    <span class="number">1981</span><span class="number">-9</span><span class="number">-8</span>        <span class="number">1500.0</span>  <span class="number">0.0</span>     <span class="number">30</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.227</span> seconds, Fetched: <span class="number">4</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> deptno <span class="keyword">not</span> <span class="keyword">in</span> (<span class="number">30</span>, <span class="number">20</span>);</span><br><span class="line">OK</span><br><span class="line">emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno</span><br><span class="line"><span class="number">7782</span>    CLARK   MANARER <span class="number">7829</span>    <span class="number">1981</span><span class="number">-6</span><span class="number">-9</span>        <span class="number">2450.0</span>  <span class="keyword">NULL</span>    <span class="number">10</span></span><br><span class="line"><span class="number">7839</span>    KING    PRESIDENT       <span class="keyword">NULL</span>    <span class="number">1981</span><span class="number">-11</span><span class="number">-17</span>      <span class="number">5000.0</span>  <span class="keyword">NULL</span>    <span class="number">10</span></span><br><span class="line"><span class="number">79934</span>   MILLER  CLERK   <span class="number">7782</span>    <span class="number">1982</span><span class="number">-1</span><span class="number">-23</span>       <span class="number">1300.0</span>  <span class="keyword">NULL</span>    <span class="number">10</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.191</span> seconds, Fetched: <span class="number">3</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



<p>（10）分组</p>
<ol>
<li>Group By 语句</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> t.deptno, <span class="built_in">avg</span>(t.sal) avg_sal <span class="keyword">from</span> emp t <span class="keyword">group</span> <span class="keyword">by</span> t.deptno;</span><br><span class="line">Query ID <span class="operator">=</span> root_20231221094038_4bd1d586<span class="number">-20</span>f4<span class="number">-412</span>d<span class="number">-868</span>d<span class="number">-1</span>df0701852f4</span><br><span class="line">Total jobs <span class="operator">=</span> <span class="number">1</span></span><br><span class="line">Launching Job <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">1</span></span><br><span class="line">Number <span class="keyword">of</span> reduce tasks <span class="keyword">not</span> specified. Estimated <span class="keyword">from</span> input data size: <span class="number">1</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> limit the maximum number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.max<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">set</span> a constant number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line">Starting Job <span class="operator">=</span> job_1703122484268_0002, Tracking URL <span class="operator">=</span> http:<span class="operator">/</span><span class="operator">/</span>hadoop302:<span class="number">8088</span><span class="operator">/</span>proxy<span class="operator">/</span>application_1703122484268_0002<span class="operator">/</span></span><br><span class="line">Kill Command <span class="operator">=</span> <span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>hadoop<span class="operator">/</span>bin<span class="operator">/</span>mapred job  <span class="operator">-</span>kill job_1703122484268_0002</span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage<span class="number">-1</span>: number <span class="keyword">of</span> mappers: <span class="number">1</span>; number <span class="keyword">of</span> reducers: <span class="number">1</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">09</span>:<span class="number">40</span>:<span class="number">50</span>,<span class="number">899</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">09</span>:<span class="number">41</span>:<span class="number">13</span>,<span class="number">491</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>, Cumulative CPU <span class="number">3.29</span> sec</span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">09</span>:<span class="number">41</span>:<span class="number">20</span>,<span class="number">737</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>, Cumulative CPU <span class="number">7.97</span> sec</span><br><span class="line">MapReduce Total cumulative CPU <span class="type">time</span>: <span class="number">7</span> seconds <span class="number">970</span> msec</span><br><span class="line">Ended Job <span class="operator">=</span> job_1703122484268_0002</span><br><span class="line">MapReduce Jobs Launched:</span><br><span class="line">Stage<span class="operator">-</span>Stage<span class="number">-1</span>: Map: <span class="number">1</span>  Reduce: <span class="number">1</span>   Cumulative CPU: <span class="number">7.97</span> sec   HDFS Read: <span class="number">16441</span> HDFS Write: <span class="number">177</span> SUCCESS</span><br><span class="line">Total MapReduce CPU <span class="type">Time</span> Spent: <span class="number">7</span> seconds <span class="number">970</span> msec</span><br><span class="line">OK</span><br><span class="line">t.deptno        avg_sal</span><br><span class="line"><span class="number">10</span>      <span class="number">2916.6666666666665</span></span><br><span class="line"><span class="number">20</span>      <span class="number">2175.0</span></span><br><span class="line"><span class="number">30</span>      <span class="number">1566.6666666666667</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">43.428</span> seconds, Fetched: <span class="number">3</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>

<p>略……….</p>
<p>（11）Join 语句</p>
<ol>
<li>内连接</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> e.empno, e.ename, d.dname <span class="keyword">from</span> emp e <span class="keyword">join</span> dept d <span class="keyword">on</span> e.deptno <span class="operator">=</span> d.deptno;</span><br><span class="line">Query ID <span class="operator">=</span> root_20231221093825_108b61bc<span class="number">-4</span>c2c<span class="number">-4644</span><span class="number">-9</span>f77<span class="number">-069</span>eae03a65f</span><br><span class="line">Total jobs <span class="operator">=</span> <span class="number">1</span></span><br><span class="line">Execution completed successfully</span><br><span class="line">MapredLocal task succeeded</span><br><span class="line">Launching Job <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">1</span></span><br><span class="line">Number <span class="keyword">of</span> reduce tasks <span class="keyword">is</span> <span class="keyword">set</span> <span class="keyword">to</span> <span class="number">0</span> since there<span class="string">&#x27;s no reduce operator</span></span><br><span class="line"><span class="string">Starting Job = job_1703122484268_0001, Tracking URL = http://hadoop302:8088/proxy/application_1703122484268_0001/</span></span><br><span class="line"><span class="string">Kill Command = /opt/module/hadoop/bin/mapred job  -kill job_1703122484268_0001</span></span><br><span class="line"><span class="string">Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 0</span></span><br><span class="line"><span class="string">2023-12-21 09:38:59,833 Stage-3 map = 0%,  reduce = 0%</span></span><br><span class="line"><span class="string">2023-12-21 09:39:15,516 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 4.99 sec</span></span><br><span class="line"><span class="string">MapReduce Total cumulative CPU time: 4 seconds 990 msec</span></span><br><span class="line"><span class="string">Ended Job = job_1703122484268_0001</span></span><br><span class="line"><span class="string">MapReduce Jobs Launched:</span></span><br><span class="line"><span class="string">Stage-Stage-3: Map: 1   Cumulative CPU: 4.99 sec   HDFS Read: 10241 HDFS Write: 524 SUCCESS</span></span><br><span class="line"><span class="string">Total MapReduce CPU Time Spent: 4 seconds 990 msec</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">e.empno e.ename d.dname</span></span><br><span class="line"><span class="string">7369    SMITH   RESEARCH</span></span><br><span class="line"><span class="string">7499    ALLEN   SALES</span></span><br><span class="line"><span class="string">7521    WARD    SALES</span></span><br><span class="line"><span class="string">7566    JONES   RESEARCH</span></span><br><span class="line"><span class="string">7654    MARTIN  SALES</span></span><br><span class="line"><span class="string">7698    BLAKE   SALES</span></span><br><span class="line"><span class="string">7782    CLARK   ACCOUNTING</span></span><br><span class="line"><span class="string">7788    SCOTT   RESEARCH</span></span><br><span class="line"><span class="string">7839    KING    ACCOUNTING</span></span><br><span class="line"><span class="string">7844    TURNER  SALES</span></span><br><span class="line"><span class="string">7876    ADAMS   RESEARCH</span></span><br><span class="line"><span class="string">7900    JAMES   SALES</span></span><br><span class="line"><span class="string">7902    FORD    RESEARCH</span></span><br><span class="line"><span class="string">79934   MILLER  ACCOUNTING</span></span><br><span class="line"><span class="string">Time taken: 52.22 seconds, Fetched: 14 row(s)</span></span><br><span class="line"><span class="string">hive (default)&gt;</span></span><br></pre></td></tr></table></figure>



<ol start="2">
<li>左外连接</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">/</span><span class="operator">/</span> 根据员工表和部门表中的部门编号相等，查询员工编号、员工名称、部门编号和部门名称：</span><br><span class="line"><span class="operator">/</span><span class="operator">/</span> 如果没有部门名称则补充<span class="keyword">NULL</span></span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> e.empno, e.ename, e.deptno, d.dname <span class="keyword">from</span> emp e <span class="keyword">left</span> <span class="keyword">join</span> dept d <span class="keyword">on</span> e.deptno <span class="operator">=</span> d.deptno;</span><br><span class="line">Query ID <span class="operator">=</span> root_20231221095305_d026527e<span class="number">-0</span>b87<span class="number">-4136</span><span class="number">-8</span>d4f<span class="operator">-</span>f93c90fd78fa</span><br><span class="line">Total jobs <span class="operator">=</span> <span class="number">1</span></span><br><span class="line">Execution completed successfully</span><br><span class="line">MapredLocal task succeeded</span><br><span class="line">Launching Job <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">1</span></span><br><span class="line">Number <span class="keyword">of</span> reduce tasks <span class="keyword">is</span> <span class="keyword">set</span> <span class="keyword">to</span> <span class="number">0</span> since there<span class="string">&#x27;s no reduce operator</span></span><br><span class="line"><span class="string">Starting Job = job_1703122484268_0004, Tracking URL = http://hadoop302:8088/proxy/application_1703122484268_0004/</span></span><br><span class="line"><span class="string">Kill Command = /opt/module/hadoop/bin/mapred job  -kill job_1703122484268_0004</span></span><br><span class="line"><span class="string">Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 0</span></span><br><span class="line"><span class="string">2023-12-21 09:53:28,779 Stage-3 map = 0%,  reduce = 0%</span></span><br><span class="line"><span class="string">2023-12-21 09:53:37,005 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.59 sec</span></span><br><span class="line"><span class="string">MapReduce Total cumulative CPU time: 3 seconds 590 msec</span></span><br><span class="line"><span class="string">Ended Job = job_1703122484268_0004</span></span><br><span class="line"><span class="string">MapReduce Jobs Launched:</span></span><br><span class="line"><span class="string">Stage-Stage-3: Map: 1   Cumulative CPU: 3.59 sec   HDFS Read: 9822 HDFS Write: 566 SUCCESS</span></span><br><span class="line"><span class="string">Total MapReduce CPU Time Spent: 3 seconds 590 msec</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">e.empno e.ename e.deptno        d.dname</span></span><br><span class="line"><span class="string">7369    SMITH   20      RESEARCH</span></span><br><span class="line"><span class="string">7499    ALLEN   30      SALES</span></span><br><span class="line"><span class="string">7521    WARD    30      SALES</span></span><br><span class="line"><span class="string">7566    JONES   20      RESEARCH</span></span><br><span class="line"><span class="string">7654    MARTIN  30      SALES</span></span><br><span class="line"><span class="string">7698    BLAKE   30      SALES</span></span><br><span class="line"><span class="string">7782    CLARK   10      ACCOUNTING</span></span><br><span class="line"><span class="string">7788    SCOTT   20      RESEARCH</span></span><br><span class="line"><span class="string">7839    KING    10      ACCOUNTING</span></span><br><span class="line"><span class="string">7844    TURNER  30      SALES</span></span><br><span class="line"><span class="string">7876    ADAMS   20      RESEARCH</span></span><br><span class="line"><span class="string">7900    JAMES   30      SALES</span></span><br><span class="line"><span class="string">7902    FORD    20      RESEARCH</span></span><br><span class="line"><span class="string">79934   MILLER  10      ACCOUNTING</span></span><br><span class="line"><span class="string">Time taken: 33.29 seconds, Fetched: 14 row(s)</span></span><br><span class="line"><span class="string">hive (default)&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>右外连接</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select e.empno, e.ename, e.deptno, d.dname from emp e right join dept d on e.deptno = d.deptno;</span><br><span class="line">Query ID = root_20231221095544_5e8e0e94-6706-4503-b33c-fa98d6e75ada</span><br><span class="line">Total jobs = 1</span><br><span class="line">SLF4J: Failed to load class &quot;org.slf4j.impl.StaticMDCBinder&quot;.</span><br><span class="line">SLF4J: Defaulting to no-operation MDCAdapter implementation.</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#no_static_mdc_binder for further details.</span><br><span class="line">2023-12-21 09:55:59     Starting to launch local task to process map join;      maximum memory = 239075328</span><br><span class="line">2023-12-21 09:56:01     Dump the side-table for tag: 0 with group count: 3 into file: file:/tmp/root/52bffc3a-4871-43d6-b430-9fac03092d41/hive_2023-12-21_09-55-44_863_5586462525119549729-1/-local-10004/HashTable-Stage-3/MapJoin-mapfile30--.hashtable</span><br><span class="line">2023-12-21 09:56:01     Uploaded 1 File to: file:/tmp/root/52bffc3a-4871-43d6-b430-9fac03092d41/hive_2023-12-21_09-55-44_863_5586462525119549729-1/-local-10004/HashTable-Stage-3/MapJoin-mapfile30--.hashtable (499 bytes)</span><br><span class="line">2023-12-21 09:56:01     End of local task; Time Taken: 1.689 sec.</span><br><span class="line">Execution completed successfully</span><br><span class="line">MapredLocal task succeeded</span><br><span class="line">Launching Job 1 out of 1</span><br><span class="line">Number of reduce tasks is set to 0 since there&#x27;s no reduce operator</span><br><span class="line">Starting Job = job_1703122484268_0005, Tracking URL = http://hadoop302:8088/proxy/application_1703122484268_0005/</span><br><span class="line">Kill Command = /opt/module/hadoop/bin/mapred job  -kill job_1703122484268_0005</span><br><span class="line">Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 0</span><br><span class="line">2023-12-21 09:56:12,596 Stage-3 map = 0%,  reduce = 0%</span><br><span class="line">2023-12-21 09:56:20,909 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 4.05 sec</span><br><span class="line">MapReduce Total cumulative CPU time: 4 seconds 50 msec</span><br><span class="line">Ended Job = job_1703122484268_0005</span><br><span class="line">MapReduce Jobs Launched:</span><br><span class="line">Stage-Stage-3: Map: 1   Cumulative CPU: 4.05 sec   HDFS Read: 8794 HDFS Write: 598 SUCCESS</span><br><span class="line">Total MapReduce CPU Time Spent: 4 seconds 50 msec</span><br><span class="line">OK</span><br><span class="line">e.empno e.ename e.deptno        d.dname</span><br><span class="line">7782    CLARK   10      ACCOUNTING</span><br><span class="line">7839    KING    10      ACCOUNTING</span><br><span class="line">79934   MILLER  10      ACCOUNTING</span><br><span class="line">7369    SMITH   20      RESEARCH</span><br><span class="line">7566    JONES   20      RESEARCH</span><br><span class="line">7788    SCOTT   20      RESEARCH</span><br><span class="line">7876    ADAMS   20      RESEARCH</span><br><span class="line">7902    FORD    20      RESEARCH</span><br><span class="line">7499    ALLEN   30      SALES</span><br><span class="line">7521    WARD    30      SALES</span><br><span class="line">7654    MARTIN  30      SALES</span><br><span class="line">7698    BLAKE   30      SALES</span><br><span class="line">7844    TURNER  30      SALES</span><br><span class="line">7900    JAMES   30      SALES</span><br><span class="line">NULL    NULL    NULL    OPERATIONS</span><br><span class="line">Time taken: 37.219 seconds, Fetched: 15 row(s)</span><br><span class="line">hive (default)&gt;</span><br></pre></td></tr></table></figure>

<p>4. </p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">  <span class="operator">/</span><span class="operator">/</span> 查询所有员工信息以及所有部门信息</span><br><span class="line">  hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> e.empno, e.ename, d.deptno, d.dname <span class="keyword">from</span> emp e <span class="keyword">full</span> <span class="keyword">join</span> dept d <span class="keyword">on</span> e.deptno <span class="operator">=</span> d.deptno;</span><br><span class="line">Query ID <span class="operator">=</span> root_20231221101601_1bee9494<span class="number">-012</span>c<span class="number">-4</span>df2<span class="number">-991</span>e<span class="operator">-</span>a20af78fcf58</span><br><span class="line">Total jobs <span class="operator">=</span> <span class="number">1</span></span><br><span class="line">Launching Job <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">1</span></span><br><span class="line">Number <span class="keyword">of</span> reduce tasks <span class="keyword">not</span> specified. Estimated <span class="keyword">from</span> input data size: <span class="number">1</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> limit the maximum number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.max<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">set</span> a constant number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line">Starting Job <span class="operator">=</span> job_1703122484268_0007, Tracking URL <span class="operator">=</span> http:<span class="operator">/</span><span class="operator">/</span>hadoop302:<span class="number">8088</span><span class="operator">/</span>proxy<span class="operator">/</span>application_1703122484268_0007<span class="operator">/</span></span><br><span class="line">Kill Command <span class="operator">=</span> <span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>hadoop<span class="operator">/</span>bin<span class="operator">/</span>mapred job  <span class="operator">-</span>kill job_1703122484268_0007</span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage<span class="number">-1</span>: number <span class="keyword">of</span> mappers: <span class="number">2</span>; number <span class="keyword">of</span> reducers: <span class="number">1</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">10</span>:<span class="number">16</span>:<span class="number">12</span>,<span class="number">295</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">10</span>:<span class="number">16</span>:<span class="number">27</span>,<span class="number">940</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">50</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>, Cumulative CPU <span class="number">2.81</span> sec</span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">10</span>:<span class="number">16</span>:<span class="number">28</span>,<span class="number">974</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>, Cumulative CPU <span class="number">6.38</span> sec</span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">10</span>:<span class="number">16</span>:<span class="number">34</span>,<span class="number">175</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>, Cumulative CPU <span class="number">9.15</span> sec</span><br><span class="line">MapReduce Total cumulative CPU <span class="type">time</span>: <span class="number">9</span> seconds <span class="number">150</span> msec</span><br><span class="line">Ended Job <span class="operator">=</span> job_1703122484268_0007</span><br><span class="line">MapReduce Jobs Launched:</span><br><span class="line">Stage<span class="operator">-</span>Stage<span class="number">-1</span>: Map: <span class="number">2</span>  Reduce: <span class="number">1</span>   Cumulative CPU: <span class="number">9.15</span> sec   HDFS Read: <span class="number">17623</span> HDFS Write: <span class="number">598</span> SUCCESS</span><br><span class="line">Total MapReduce CPU <span class="type">Time</span> Spent: <span class="number">9</span> seconds <span class="number">150</span> msec</span><br><span class="line">OK</span><br><span class="line">e.empno e.ename d.deptno        d.dname</span><br><span class="line"><span class="number">79934</span>   MILLER  <span class="number">10</span>      ACCOUNTING</span><br><span class="line"><span class="number">7839</span>    KING    <span class="number">10</span>      ACCOUNTING</span><br><span class="line"><span class="number">7782</span>    CLARK   <span class="number">10</span>      ACCOUNTING</span><br><span class="line"><span class="number">7876</span>    ADAMS   <span class="number">20</span>      RESEARCH</span><br><span class="line"><span class="number">7788</span>    SCOTT   <span class="number">20</span>      RESEARCH</span><br><span class="line"><span class="number">7369</span>    SMITH   <span class="number">20</span>      RESEARCH</span><br><span class="line"><span class="number">7566</span>    JONES   <span class="number">20</span>      RESEARCH</span><br><span class="line"><span class="number">7902</span>    FORD    <span class="number">20</span>      RESEARCH</span><br><span class="line"><span class="number">7844</span>    TURNER  <span class="number">30</span>      SALES</span><br><span class="line"><span class="number">7499</span>    ALLEN   <span class="number">30</span>      SALES</span><br><span class="line"><span class="number">7698</span>    BLAKE   <span class="number">30</span>      SALES</span><br><span class="line"><span class="number">7654</span>    MARTIN  <span class="number">30</span>      SALES</span><br><span class="line"><span class="number">7521</span>    WARD    <span class="number">30</span>      SALES</span><br><span class="line"><span class="number">7900</span>    JAMES   <span class="number">30</span>      SALES</span><br><span class="line"><span class="keyword">NULL</span>    <span class="keyword">NULL</span>    <span class="number">40</span>      OPERATIONS</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">35.046</span> seconds, Fetched: <span class="number">15</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="operator">/</span><span class="operator">/</span> 查询所有员工信息所在部门信息为<span class="keyword">NULL</span></span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> e.empno, e.ename, d.deptno, d.dname <span class="keyword">from</span> emp e <span class="keyword">left</span> <span class="keyword">join</span> dept d <span class="keyword">on</span> e.deptno <span class="operator">=</span> d.deptno <span class="keyword">where</span> d.deptno <span class="keyword">is</span> <span class="keyword">null</span>;</span><br><span class="line">Query ID <span class="operator">=</span> root_20231221103812_fee8a1db<span class="number">-5</span>a16<span class="number">-414</span>e<span class="operator">-</span>b09d<span class="number">-76536</span>a276019</span><br><span class="line">Total jobs <span class="operator">=</span> <span class="number">1</span></span><br><span class="line">Execution completed successfully</span><br><span class="line">MapredLocal task succeeded</span><br><span class="line">Launching Job <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">1</span></span><br><span class="line">Number <span class="keyword">of</span> reduce tasks <span class="keyword">is</span> <span class="keyword">set</span> <span class="keyword">to</span> <span class="number">0</span> since there<span class="string">&#x27;s no reduce operator</span></span><br><span class="line"><span class="string">Starting Job = job_1703122484268_0008, Tracking URL = http://hadoop302:8088/proxy/application_1703122484268_0008/</span></span><br><span class="line"><span class="string">Kill Command = /opt/module/hadoop/bin/mapred job  -kill job_1703122484268_0008</span></span><br><span class="line"><span class="string">Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 0</span></span><br><span class="line"><span class="string">2023-12-21 10:38:35,993 Stage-3 map = 0%,  reduce = 0%</span></span><br><span class="line"><span class="string">2023-12-21 10:39:02,913 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 5.12 sec</span></span><br><span class="line"><span class="string">MapReduce Total cumulative CPU time: 5 seconds 120 msec</span></span><br><span class="line"><span class="string">Ended Job = job_1703122484268_0008</span></span><br><span class="line"><span class="string">MapReduce Jobs Launched:</span></span><br><span class="line"><span class="string">Stage-Stage-3: Map: 1   Cumulative CPU: 5.12 sec   HDFS Read: 10507 HDFS Write: 87 SUCCESS</span></span><br><span class="line"><span class="string">Total MapReduce CPU Time Spent: 5 seconds 120 msec</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">e.empno e.ename d.deptno        d.dname</span></span><br><span class="line"><span class="string">Time taken: 51.322 seconds</span></span><br><span class="line"><span class="string">hive (default)&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">注意：</span></span><br><span class="line"><span class="string">union ：去重</span></span><br><span class="line"><span class="string">union all ：不去重</span></span><br><span class="line"><span class="string">如果需求本身不存在重复数据，使用union,和union all 效果相同，使用union sll 性能高</span></span><br></pre></td></tr></table></figure>



<ol start="5">
<li>多表连接</li>
</ol>
<p>数据准备</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1700    Beijing</span><br><span class="line">1800    London</span><br><span class="line">1900    Tokyo</span><br></pre></td></tr></table></figure>

<p>1）创建表</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">create table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> location(loc <span class="type">int</span>, loc_name string) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">1.453</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>

<p>2）导入数据</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/opt/module/data/loc.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> location;</span><br><span class="line">Loading data <span class="keyword">to</span> <span class="keyword">table</span> default.location</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.418</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> location;</span><br><span class="line">OK</span><br><span class="line">location.loc    location.loc_name</span><br><span class="line"><span class="number">1700</span>    Beijing</span><br><span class="line"><span class="number">1800</span>    London</span><br><span class="line"><span class="number">1900</span>    Tokyo</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.147</span> seconds, Fetched: <span class="number">3</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



<p>3）多表连接查询</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">/</span><span class="operator">/</span> 查询员工姓名、部门名称、以及部门所在城市名称</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> e.ename, d.dname, l.loc_name <span class="keyword">from</span> emp e <span class="keyword">join</span> dept d <span class="keyword">on</span> e.deptno <span class="operator">=</span> d.deptno <span class="keyword">join</span> location l <span class="keyword">on</span> d.loc <span class="operator">=</span> l.loc;</span><br><span class="line"><span class="keyword">No</span> Stats <span class="keyword">for</span> <span class="keyword">default</span><span class="variable">@emp</span>, Columns: ename, deptno</span><br><span class="line"><span class="keyword">No</span> Stats <span class="keyword">for</span> <span class="keyword">default</span><span class="variable">@dept</span>, Columns: loc, dname, deptno</span><br><span class="line"><span class="keyword">No</span> Stats <span class="keyword">for</span> <span class="keyword">default</span><span class="variable">@location</span>, Columns: loc, loc_name</span><br><span class="line">Query ID <span class="operator">=</span> root_20231221112134_0bf5d559<span class="operator">-</span>c3bd<span class="number">-4e61</span><span class="number">-9386</span><span class="operator">-</span>deb92bd4f883</span><br><span class="line">Total jobs <span class="operator">=</span> <span class="number">1</span></span><br><span class="line">Execution completed successfully</span><br><span class="line">MapredLocal task succeeded</span><br><span class="line">Launching Job <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">1</span></span><br><span class="line">Number <span class="keyword">of</span> reduce tasks <span class="keyword">is</span> <span class="keyword">set</span> <span class="keyword">to</span> <span class="number">0</span> since there<span class="string">&#x27;s no reduce operator</span></span><br><span class="line"><span class="string">Starting Job = job_1703122484268_0014, Tracking URL = http://hadoop302:8088/proxy/application_1703122484268_0014/</span></span><br><span class="line"><span class="string">Kill Command = /opt/module/hadoop/bin/mapred job  -kill job_1703122484268_0014</span></span><br><span class="line"><span class="string">Hadoop job information for Stage-5: number of mappers: 1; number of reducers: 0</span></span><br><span class="line"><span class="string">2023-12-21 11:21:54,820 Stage-5 map = 0%,  reduce = 0%</span></span><br><span class="line"><span class="string">2023-12-21 11:22:03,166 Stage-5 map = 100%,  reduce = 0%, Cumulative CPU 4.78 sec</span></span><br><span class="line"><span class="string">MapReduce Total cumulative CPU time: 4 seconds 780 msec</span></span><br><span class="line"><span class="string">Ended Job = job_1703122484268_0014</span></span><br><span class="line"><span class="string">MapReduce Jobs Launched:</span></span><br><span class="line"><span class="string">Stage-Stage-5: Map: 1   Cumulative CPU: 4.78 sec   HDFS Read: 12121 HDFS Write: 548 SUCCESS</span></span><br><span class="line"><span class="string">Total MapReduce CPU Time Spent: 4 seconds 780 msec</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">e.ename d.dname l.loc_name</span></span><br><span class="line"><span class="string">SMITH   RESEARCH        London</span></span><br><span class="line"><span class="string">ALLEN   SALES   Tokyo</span></span><br><span class="line"><span class="string">WARD    SALES   Tokyo</span></span><br><span class="line"><span class="string">JONES   RESEARCH        London</span></span><br><span class="line"><span class="string">MARTIN  SALES   Tokyo</span></span><br><span class="line"><span class="string">BLAKE   SALES   Tokyo</span></span><br><span class="line"><span class="string">CLARK   ACCOUNTING      Beijing</span></span><br><span class="line"><span class="string">SCOTT   RESEARCH        London</span></span><br><span class="line"><span class="string">KING    ACCOUNTING      Beijing</span></span><br><span class="line"><span class="string">TURNER  SALES   Tokyo</span></span><br><span class="line"><span class="string">ADAMS   RESEARCH        London</span></span><br><span class="line"><span class="string">JAMES   SALES   Tokyo</span></span><br><span class="line"><span class="string">FORD    RESEARCH        London</span></span><br><span class="line"><span class="string">MILLER  ACCOUNTING      Beijing</span></span><br><span class="line"><span class="string">Time taken: 30.331 seconds, Fetched: 14 row(s)</span></span><br><span class="line"><span class="string">hive (default)&gt;</span></span><br></pre></td></tr></table></figure>



<ol start="6">
<li>笛卡儿积</li>
</ol>
<ul>
<li>省略连接条件</li>
<li>连接条件无效</li>
<li>所有表中的所有行互相连接</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> empno, dname <span class="keyword">from</span> emp, dept;</span><br><span class="line">Warning: Map <span class="keyword">Join</span> MAPJOIN[<span class="number">9</span>][bigTable<span class="operator">=</span>?] <span class="keyword">in</span> task <span class="string">&#x27;Stage-3:MAPRED&#x27;</span> <span class="keyword">is</span> a <span class="keyword">cross</span> product</span><br><span class="line">Query ID <span class="operator">=</span> root_20231221112554_2ceb7bb1<span class="number">-86</span>df<span class="number">-4</span>b96<span class="operator">-</span>bd83<span class="operator">-</span>b96a7faceec1</span><br><span class="line">Total jobs <span class="operator">=</span> <span class="number">1</span></span><br><span class="line">SLF4J: Failed <span class="keyword">to</span> load class &quot;org.slf4j.impl.StaticLoggerBinder&quot;.</span><br><span class="line">SLF4J: Defaulting <span class="keyword">to</span> <span class="keyword">no</span><span class="operator">-</span>operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http:<span class="operator">/</span><span class="operator">/</span>www.slf4j.org<span class="operator">/</span>codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line">SLF4J: Failed <span class="keyword">to</span> load class &quot;org.slf4j.impl.StaticMDCBinder&quot;.</span><br><span class="line">SLF4J: Defaulting <span class="keyword">to</span> <span class="keyword">no</span><span class="operator">-</span>operation MDCAdapter implementation.</span><br><span class="line">SLF4J: See http:<span class="operator">/</span><span class="operator">/</span>www.slf4j.org<span class="operator">/</span>codes.html#no_static_mdc_binder <span class="keyword">for</span> further details.</span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">11</span>:<span class="number">26</span>:<span class="number">03</span>     Starting <span class="keyword">to</span> launch <span class="keyword">local</span> task <span class="keyword">to</span> process map <span class="keyword">join</span>;      maximum memory <span class="operator">=</span> <span class="number">239075328</span></span><br><span class="line">Execution completed successfully</span><br><span class="line">MapredLocal task succeeded</span><br><span class="line">Launching Job <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">1</span></span><br><span class="line">Number <span class="keyword">of</span> reduce tasks <span class="keyword">is</span> <span class="keyword">set</span> <span class="keyword">to</span> <span class="number">0</span> since there<span class="string">&#x27;s no reduce operator</span></span><br><span class="line"><span class="string">Starting Job = job_1703122484268_0015, Tracking URL = http://hadoop302:8088/proxy/application_1703122484268_0015/</span></span><br><span class="line"><span class="string">Kill Command = /opt/module/hadoop/bin/mapred job  -kill job_1703122484268_0015</span></span><br><span class="line"><span class="string">Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 0</span></span><br><span class="line"><span class="string">2023-12-21 11:26:15,583 Stage-3 map = 0%,  reduce = 0%</span></span><br><span class="line"><span class="string">2023-12-21 11:26:30,060 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.97 sec</span></span><br><span class="line"><span class="string">MapReduce Total cumulative CPU time: 3 seconds 970 msec</span></span><br><span class="line"><span class="string">Ended Job = job_1703122484268_0015</span></span><br><span class="line"><span class="string">MapReduce Jobs Launched:</span></span><br><span class="line"><span class="string">Stage-Stage-3: Map: 1   Cumulative CPU: 3.97 sec   HDFS Read: 9231 HDFS Write: 1561 SUCCESS</span></span><br><span class="line"><span class="string">Total MapReduce CPU Time Spent: 3 seconds 970 msec</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">empno   dname</span></span><br><span class="line"><span class="string">7369    ACCOUNTING</span></span><br><span class="line"><span class="string">7369    RESEARCH</span></span><br><span class="line"><span class="string">7369    SALES</span></span><br><span class="line"><span class="string">7369    OPERATIONS</span></span><br><span class="line"><span class="string">7499    ACCOUNTING</span></span><br><span class="line"><span class="string">7499    RESEARCH</span></span><br><span class="line"><span class="string">7499    SALES</span></span><br><span class="line"><span class="string">7499    OPERATIONS</span></span><br><span class="line"><span class="string">7521    ACCOUNTING</span></span><br><span class="line"><span class="string">7521    RESEARCH</span></span><br><span class="line"><span class="string">7521    SALES</span></span><br><span class="line"><span class="string">7521    OPERATIONS</span></span><br><span class="line"><span class="string">7566    ACCOUNTING</span></span><br><span class="line"><span class="string">7566    RESEARCH</span></span><br><span class="line"><span class="string">7566    SALES</span></span><br><span class="line"><span class="string">7566    OPERATIONS</span></span><br><span class="line"><span class="string">7654    ACCOUNTING</span></span><br><span class="line"><span class="string">7654    RESEARCH</span></span><br><span class="line"><span class="string">7654    SALES</span></span><br><span class="line"><span class="string">7654    OPERATIONS</span></span><br><span class="line"><span class="string">7698    ACCOUNTING</span></span><br><span class="line"><span class="string">7698    RESEARCH</span></span><br><span class="line"><span class="string">7698    SALES</span></span><br><span class="line"><span class="string">7698    OPERATIONS</span></span><br><span class="line"><span class="string">7782    ACCOUNTING</span></span><br><span class="line"><span class="string">7782    RESEARCH</span></span><br><span class="line"><span class="string">7782    SALES</span></span><br><span class="line"><span class="string">7782    OPERATIONS</span></span><br><span class="line"><span class="string">7788    ACCOUNTING</span></span><br><span class="line"><span class="string">7788    RESEARCH</span></span><br><span class="line"><span class="string">7788    SALES</span></span><br><span class="line"><span class="string">7788    OPERATIONS</span></span><br><span class="line"><span class="string">7839    ACCOUNTING</span></span><br><span class="line"><span class="string">7839    RESEARCH</span></span><br><span class="line"><span class="string">7839    SALES</span></span><br><span class="line"><span class="string">7839    OPERATIONS</span></span><br><span class="line"><span class="string">7844    ACCOUNTING</span></span><br><span class="line"><span class="string">7844    RESEARCH</span></span><br><span class="line"><span class="string">7844    SALES</span></span><br><span class="line"><span class="string">7844    OPERATIONS</span></span><br><span class="line"><span class="string">7876    ACCOUNTING</span></span><br><span class="line"><span class="string">7876    RESEARCH</span></span><br><span class="line"><span class="string">7876    SALES</span></span><br><span class="line"><span class="string">7876    OPERATIONS</span></span><br><span class="line"><span class="string">7900    ACCOUNTING</span></span><br><span class="line"><span class="string">7900    RESEARCH</span></span><br><span class="line"><span class="string">7900    SALES</span></span><br><span class="line"><span class="string">7900    OPERATIONS</span></span><br><span class="line"><span class="string">7902    ACCOUNTING</span></span><br><span class="line"><span class="string">7902    RESEARCH</span></span><br><span class="line"><span class="string">7902    SALES</span></span><br><span class="line"><span class="string">7902    OPERATIONS</span></span><br><span class="line"><span class="string">79934   ACCOUNTING</span></span><br><span class="line"><span class="string">79934   RESEARCH</span></span><br><span class="line"><span class="string">79934   SALES</span></span><br><span class="line"><span class="string">79934   OPERATIONS</span></span><br><span class="line"><span class="string">Time taken: 37.56 seconds, Fetched: 56 row(s)</span></span><br><span class="line"><span class="string">hive (default)&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">或</span></span><br><span class="line"><span class="string">hive (default)&gt; select e.ename, d.dname from emp e join dept d;</span></span><br><span class="line"><span class="string">Warning: Map Join MAPJOIN[9][bigTable=?] in task &#x27;</span>Stage<span class="number">-3</span>:MAPRED<span class="string">&#x27; is a cross product</span></span><br><span class="line"><span class="string">Query ID = root_20231221112743_0d68351b-3889-44cc-86bf-c5b63c9fcdcb</span></span><br><span class="line"><span class="string">Total jobs = 1</span></span><br><span class="line"><span class="string">Execution completed successfully</span></span><br><span class="line"><span class="string">MapredLocal task succeeded</span></span><br><span class="line"><span class="string">Launching Job 1 out of 1</span></span><br><span class="line"><span class="string">Number of reduce tasks is set to 0 since there&#x27;</span>s <span class="keyword">no</span> reduce operator</span><br><span class="line">Starting Job <span class="operator">=</span> job_1703122484268_0016, Tracking URL <span class="operator">=</span> http:<span class="operator">/</span><span class="operator">/</span>hadoop302:<span class="number">8088</span><span class="operator">/</span>proxy<span class="operator">/</span>application_1703122484268_0016<span class="operator">/</span></span><br><span class="line">Kill Command <span class="operator">=</span> <span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>hadoop<span class="operator">/</span>bin<span class="operator">/</span>mapred job  <span class="operator">-</span>kill job_1703122484268_0016</span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage<span class="number">-3</span>: number <span class="keyword">of</span> mappers: <span class="number">1</span>; number <span class="keyword">of</span> reducers: <span class="number">0</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">11</span>:<span class="number">28</span>:<span class="number">04</span>,<span class="number">841</span> Stage<span class="number">-3</span> map <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">11</span>:<span class="number">28</span>:<span class="number">21</span>,<span class="number">429</span> Stage<span class="number">-3</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>, Cumulative CPU <span class="number">3.25</span> sec</span><br><span class="line">MapReduce Total cumulative CPU <span class="type">time</span>: <span class="number">3</span> seconds <span class="number">250</span> msec</span><br><span class="line">Ended Job <span class="operator">=</span> job_1703122484268_0016</span><br><span class="line">MapReduce Jobs Launched:</span><br><span class="line">Stage<span class="operator">-</span>Stage<span class="number">-3</span>: Map: <span class="number">1</span>   Cumulative CPU: <span class="number">3.25</span> sec   HDFS Read: <span class="number">9253</span> HDFS Write: <span class="number">1613</span> SUCCESS</span><br><span class="line">Total MapReduce CPU <span class="type">Time</span> Spent: <span class="number">3</span> seconds <span class="number">250</span> msec</span><br><span class="line">OK</span><br><span class="line">e.ename d.dname</span><br><span class="line">SMITH   ACCOUNTING</span><br><span class="line">SMITH   RESEARCH</span><br><span class="line">SMITH   SALES</span><br><span class="line">SMITH   OPERATIONS</span><br><span class="line">ALLEN   ACCOUNTING</span><br><span class="line">ALLEN   RESEARCH</span><br><span class="line">ALLEN   SALES</span><br><span class="line">ALLEN   OPERATIONS</span><br><span class="line">WARD    ACCOUNTING</span><br><span class="line">WARD    RESEARCH</span><br><span class="line">WARD    SALES</span><br><span class="line">WARD    OPERATIONS</span><br><span class="line">JONES   ACCOUNTING</span><br><span class="line">JONES   RESEARCH</span><br><span class="line">JONES   SALES</span><br><span class="line">JONES   OPERATIONS</span><br><span class="line">MARTIN  ACCOUNTING</span><br><span class="line">MARTIN  RESEARCH</span><br><span class="line">MARTIN  SALES</span><br><span class="line">MARTIN  OPERATIONS</span><br><span class="line">BLAKE   ACCOUNTING</span><br><span class="line">BLAKE   RESEARCH</span><br><span class="line">BLAKE   SALES</span><br><span class="line">BLAKE   OPERATIONS</span><br><span class="line">CLARK   ACCOUNTING</span><br><span class="line">CLARK   RESEARCH</span><br><span class="line">CLARK   SALES</span><br><span class="line">CLARK   OPERATIONS</span><br><span class="line">SCOTT   ACCOUNTING</span><br><span class="line">SCOTT   RESEARCH</span><br><span class="line">SCOTT   SALES</span><br><span class="line">SCOTT   OPERATIONS</span><br><span class="line">KING    ACCOUNTING</span><br><span class="line">KING    RESEARCH</span><br><span class="line">KING    SALES</span><br><span class="line">KING    OPERATIONS</span><br><span class="line">TURNER  ACCOUNTING</span><br><span class="line">TURNER  RESEARCH</span><br><span class="line">TURNER  SALES</span><br><span class="line">TURNER  OPERATIONS</span><br><span class="line">ADAMS   ACCOUNTING</span><br><span class="line">ADAMS   RESEARCH</span><br><span class="line">ADAMS   SALES</span><br><span class="line">ADAMS   OPERATIONS</span><br><span class="line">JAMES   ACCOUNTING</span><br><span class="line">JAMES   RESEARCH</span><br><span class="line">JAMES   SALES</span><br><span class="line">JAMES   OPERATIONS</span><br><span class="line">FORD    ACCOUNTING</span><br><span class="line">FORD    RESEARCH</span><br><span class="line">FORD    SALES</span><br><span class="line">FORD    OPERATIONS</span><br><span class="line">MILLER  ACCOUNTING</span><br><span class="line">MILLER  RESEARCH</span><br><span class="line">MILLER  SALES</span><br><span class="line">MILLER  OPERATIONS</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">40.03</span> seconds, Fetched: <span class="number">56</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



<ol start="7">
<li>排序</li>
</ol>
<p>1）全局排序（Order By）</p>
<ul>
<li>ASC  : 升序</li>
<li>DESC  ：降序</li>
</ul>
<p>ORDER BY 子句在SELSCT 语句的结尾</p>
<p>2）按工资排序</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> ename, sal <span class="keyword">from</span> emp <span class="keyword">order</span> <span class="keyword">by</span> sal;</span><br><span class="line">Query ID <span class="operator">=</span> root_20231221113310_c6b5e678<span class="number">-3</span>d3d<span class="number">-4</span>d5e<span class="number">-860</span>c<span class="number">-083</span>bdcca9b07</span><br><span class="line">Total jobs <span class="operator">=</span> <span class="number">1</span></span><br><span class="line">Launching Job <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">1</span></span><br><span class="line">Number <span class="keyword">of</span> reduce tasks determined <span class="keyword">at</span> compile <span class="type">time</span>: <span class="number">1</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> limit the maximum number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.max<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">set</span> a constant number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line">Starting Job <span class="operator">=</span> job_1703122484268_0017, Tracking URL <span class="operator">=</span> http:<span class="operator">/</span><span class="operator">/</span>hadoop302:<span class="number">8088</span><span class="operator">/</span>proxy<span class="operator">/</span>application_1703122484268_0017<span class="operator">/</span></span><br><span class="line">Kill Command <span class="operator">=</span> <span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>hadoop<span class="operator">/</span>bin<span class="operator">/</span>mapred job  <span class="operator">-</span>kill job_1703122484268_0017</span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage<span class="number">-1</span>: number <span class="keyword">of</span> mappers: <span class="number">1</span>; number <span class="keyword">of</span> reducers: <span class="number">1</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">11</span>:<span class="number">33</span>:<span class="number">18</span>,<span class="number">533</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">11</span>:<span class="number">33</span>:<span class="number">31</span>,<span class="number">884</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>, Cumulative CPU <span class="number">4.21</span> sec</span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">11</span>:<span class="number">33</span>:<span class="number">48</span>,<span class="number">378</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>, Cumulative CPU <span class="number">8.28</span> sec</span><br><span class="line">MapReduce Total cumulative CPU <span class="type">time</span>: <span class="number">8</span> seconds <span class="number">280</span> msec</span><br><span class="line">Ended Job <span class="operator">=</span> job_1703122484268_0017</span><br><span class="line">MapReduce Jobs Launched:</span><br><span class="line">Stage<span class="operator">-</span>Stage<span class="number">-1</span>: Map: <span class="number">1</span>  Reduce: <span class="number">1</span>   Cumulative CPU: <span class="number">8.28</span> sec   HDFS Read: <span class="number">11488</span> HDFS Write: <span class="number">435</span> SUCCESS</span><br><span class="line">Total MapReduce CPU <span class="type">Time</span> Spent: <span class="number">8</span> seconds <span class="number">280</span> msec</span><br><span class="line">OK</span><br><span class="line">ename   sal</span><br><span class="line">SMITH   <span class="number">800.0</span></span><br><span class="line">JAMES   <span class="number">950.0</span></span><br><span class="line">ADAMS   <span class="number">1100.0</span></span><br><span class="line">WARD    <span class="number">1250.0</span></span><br><span class="line">MARTIN  <span class="number">1250.0</span></span><br><span class="line">MILLER  <span class="number">1300.0</span></span><br><span class="line">TURNER  <span class="number">1500.0</span></span><br><span class="line">ALLEN   <span class="number">1600.0</span></span><br><span class="line">CLARK   <span class="number">2450.0</span></span><br><span class="line">BLAKE   <span class="number">2850.0</span></span><br><span class="line">JONES   <span class="number">2975.0</span></span><br><span class="line">SCOTT   <span class="number">3000.0</span></span><br><span class="line">FORD    <span class="number">3000.0</span></span><br><span class="line">KING    <span class="number">5000.0</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">39.481</span> seconds, Fetched: <span class="number">14</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>

<p>3）多个列排序</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> ename, deptno, sal <span class="keyword">from</span> emp <span class="keyword">order</span> <span class="keyword">by</span> deptno, sal;</span><br><span class="line">Query ID <span class="operator">=</span> root_20231221114159_267adbc8<span class="number">-316</span>c<span class="number">-4708</span><span class="number">-8</span>fe2<span class="number">-5e65399</span>b1e5d</span><br><span class="line">Total jobs <span class="operator">=</span> <span class="number">1</span></span><br><span class="line">Launching Job <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">1</span></span><br><span class="line">Number <span class="keyword">of</span> reduce tasks determined <span class="keyword">at</span> compile <span class="type">time</span>: <span class="number">1</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> limit the maximum number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.max<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">set</span> a constant number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line">Starting Job <span class="operator">=</span> job_1703122484268_0019, Tracking URL <span class="operator">=</span> http:<span class="operator">/</span><span class="operator">/</span>hadoop302:<span class="number">8088</span><span class="operator">/</span>proxy<span class="operator">/</span>application_1703122484268_0019<span class="operator">/</span></span><br><span class="line">Kill Command <span class="operator">=</span> <span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>hadoop<span class="operator">/</span>bin<span class="operator">/</span>mapred job  <span class="operator">-</span>kill job_1703122484268_0019</span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage<span class="number">-1</span>: number <span class="keyword">of</span> mappers: <span class="number">1</span>; number <span class="keyword">of</span> reducers: <span class="number">1</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">11</span>:<span class="number">42</span>:<span class="number">07</span>,<span class="number">778</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">11</span>:<span class="number">42</span>:<span class="number">15</span>,<span class="number">008</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>, Cumulative CPU <span class="number">1.83</span> sec</span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">11</span>:<span class="number">42</span>:<span class="number">22</span>,<span class="number">272</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>, Cumulative CPU <span class="number">4.94</span> sec</span><br><span class="line">MapReduce Total cumulative CPU <span class="type">time</span>: <span class="number">4</span> seconds <span class="number">940</span> msec</span><br><span class="line">Ended Job <span class="operator">=</span> job_1703122484268_0019</span><br><span class="line">MapReduce Jobs Launched:</span><br><span class="line">Stage<span class="operator">-</span>Stage<span class="number">-1</span>: Map: <span class="number">1</span>  Reduce: <span class="number">1</span>   Cumulative CPU: <span class="number">4.94</span> sec   HDFS Read: <span class="number">11911</span> HDFS Write: <span class="number">477</span> SUCCESS</span><br><span class="line">Total MapReduce CPU <span class="type">Time</span> Spent: <span class="number">4</span> seconds <span class="number">940</span> msec</span><br><span class="line">OK</span><br><span class="line">ename   deptno  sal</span><br><span class="line">MILLER  <span class="number">10</span>      <span class="number">1300.0</span></span><br><span class="line">CLARK   <span class="number">10</span>      <span class="number">2450.0</span></span><br><span class="line">KING    <span class="number">10</span>      <span class="number">5000.0</span></span><br><span class="line">SMITH   <span class="number">20</span>      <span class="number">800.0</span></span><br><span class="line">ADAMS   <span class="number">20</span>      <span class="number">1100.0</span></span><br><span class="line">JONES   <span class="number">20</span>      <span class="number">2975.0</span></span><br><span class="line">SCOTT   <span class="number">20</span>      <span class="number">3000.0</span></span><br><span class="line">FORD    <span class="number">20</span>      <span class="number">3000.0</span></span><br><span class="line">JAMES   <span class="number">30</span>      <span class="number">950.0</span></span><br><span class="line">MARTIN  <span class="number">30</span>      <span class="number">1250.0</span></span><br><span class="line">WARD    <span class="number">30</span>      <span class="number">1250.0</span></span><br><span class="line">TURNER  <span class="number">30</span>      <span class="number">1500.0</span></span><br><span class="line">ALLEN   <span class="number">30</span>      <span class="number">1600.0</span></span><br><span class="line">BLAKE   <span class="number">30</span>      <span class="number">2850.0</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">23.79</span> seconds, Fetched: <span class="number">14</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



<p>4）每个Reduce 内部排序（Sort By）</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp sort <span class="keyword">by</span> deptno <span class="keyword">desc</span>;</span><br><span class="line">Query ID <span class="operator">=</span> root_20231221145510_2ebee977<span class="number">-01</span>d5<span class="number">-4</span>eb1<span class="number">-96</span>ca<span class="operator">-</span>d2f882654636</span><br><span class="line">Total jobs <span class="operator">=</span> <span class="number">1</span></span><br><span class="line">Launching Job <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">1</span></span><br><span class="line">Number <span class="keyword">of</span> reduce tasks <span class="keyword">not</span> specified. Estimated <span class="keyword">from</span> input data size: <span class="number">1</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> limit the maximum number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.max<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">set</span> a constant number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line">Starting Job <span class="operator">=</span> job_1703140954122_0001, Tracking URL <span class="operator">=</span> http:<span class="operator">/</span><span class="operator">/</span>hadoop302:<span class="number">8088</span><span class="operator">/</span>proxy<span class="operator">/</span>application_1703140954122_0001<span class="operator">/</span></span><br><span class="line">Kill Command <span class="operator">=</span> <span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>hadoop<span class="operator">/</span>bin<span class="operator">/</span>mapred job  <span class="operator">-</span>kill job_1703140954122_0001</span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage<span class="number">-1</span>: number <span class="keyword">of</span> mappers: <span class="number">1</span>; number <span class="keyword">of</span> reducers: <span class="number">1</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">14</span>:<span class="number">55</span>:<span class="number">30</span>,<span class="number">224</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">14</span>:<span class="number">55</span>:<span class="number">44</span>,<span class="number">794</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>, Cumulative CPU <span class="number">4.25</span> sec</span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">14</span>:<span class="number">56</span>:<span class="number">16</span>,<span class="number">855</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>, Cumulative CPU <span class="number">8.12</span> sec</span><br><span class="line">MapReduce Total cumulative CPU <span class="type">time</span>: <span class="number">8</span> seconds <span class="number">120</span> msec</span><br><span class="line">Ended Job <span class="operator">=</span> job_1703140954122_0001</span><br><span class="line">MapReduce Jobs Launched:</span><br><span class="line">Stage<span class="operator">-</span>Stage<span class="number">-1</span>: Map: <span class="number">1</span>  Reduce: <span class="number">1</span>   Cumulative CPU: <span class="number">8.12</span> sec   HDFS Read: <span class="number">13337</span> HDFS Write: <span class="number">917</span> SUCCESS</span><br><span class="line">Total MapReduce CPU <span class="type">Time</span> Spent: <span class="number">8</span> seconds <span class="number">120</span> msec</span><br><span class="line">OK</span><br><span class="line">emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno</span><br><span class="line"><span class="number">7521</span>    WARD    SALESMAN        <span class="number">7698</span>    <span class="number">1981</span><span class="number">-2</span><span class="number">-22</span>       <span class="number">1250.0</span>  <span class="number">500.0</span>   <span class="number">30</span></span><br><span class="line"><span class="number">7499</span>    ALLEN   SALESMAN        <span class="number">7689</span>    <span class="number">1981</span><span class="number">-2</span><span class="number">-20</span>       <span class="number">1600.0</span>  <span class="number">300.0</span>   <span class="number">30</span></span><br><span class="line"><span class="number">7900</span>    JAMES   CLERK   <span class="number">7698</span>    <span class="number">1981</span><span class="number">-12</span><span class="number">-3</span>       <span class="number">950.0</span>   <span class="keyword">NULL</span>    <span class="number">30</span></span><br><span class="line"><span class="number">7844</span>    TURNER  SALESMAN        <span class="number">7698</span>    <span class="number">1981</span><span class="number">-9</span><span class="number">-8</span>        <span class="number">1500.0</span>  <span class="number">0.0</span>     <span class="number">30</span></span><br><span class="line"><span class="number">7698</span>    BLAKE   MANAGER <span class="number">7839</span>    <span class="number">1981</span><span class="number">-5</span><span class="number">-1</span>        <span class="number">2850.0</span>  <span class="keyword">NULL</span>    <span class="number">30</span></span><br><span class="line"><span class="number">7654</span>    MARTIN  SALESMAN        <span class="number">7689</span>    <span class="number">1981</span><span class="number">-8</span><span class="number">-28</span>       <span class="number">1250.0</span>  <span class="number">1400.0</span>  <span class="number">30</span></span><br><span class="line"><span class="number">7876</span>    ADAMS   CLERK   <span class="number">7788</span>    <span class="number">1987</span><span class="number">-5</span><span class="number">-23</span>       <span class="number">1100.0</span>  <span class="keyword">NULL</span>    <span class="number">20</span></span><br><span class="line"><span class="number">7902</span>    FORD    ANALYST <span class="number">7566</span>    <span class="number">1981</span><span class="number">-12</span><span class="number">-3</span>       <span class="number">3000.0</span>  <span class="keyword">NULL</span>    <span class="number">20</span></span><br><span class="line"><span class="number">7788</span>    SCOTT   ANALYST <span class="number">7566</span>    <span class="number">1987</span><span class="number">-4</span><span class="number">-19</span>       <span class="number">3000.0</span>  <span class="keyword">NULL</span>    <span class="number">20</span></span><br><span class="line"><span class="number">7369</span>    SMITH   CLERK   <span class="number">7902</span>    <span class="number">1980</span><span class="number">-12</span><span class="number">-17</span>      <span class="number">800.0</span>   <span class="keyword">NULL</span>    <span class="number">20</span></span><br><span class="line"><span class="number">7566</span>    JONES   MANAGER <span class="number">7839</span>    <span class="number">1981</span><span class="number">-4</span><span class="number">-2</span>        <span class="number">2975.0</span>  <span class="keyword">NULL</span>    <span class="number">20</span></span><br><span class="line"><span class="number">79934</span>   MILLER  CLERK   <span class="number">7782</span>    <span class="number">1982</span><span class="number">-1</span><span class="number">-23</span>       <span class="number">1300.0</span>  <span class="keyword">NULL</span>    <span class="number">10</span></span><br><span class="line"><span class="number">7839</span>    KING    PRESIDENT       <span class="keyword">NULL</span>    <span class="number">1981</span><span class="number">-11</span><span class="number">-17</span>      <span class="number">5000.0</span>  <span class="keyword">NULL</span>    <span class="number">10</span></span><br><span class="line"><span class="number">7782</span>    CLARK   MANARER <span class="number">7829</span>    <span class="number">1981</span><span class="number">-6</span><span class="number">-9</span>        <span class="number">2450.0</span>  <span class="keyword">NULL</span>    <span class="number">10</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">68.678</span> seconds, Fetched: <span class="number">14</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br><span class="line"></span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> ename, deptno <span class="keyword">from</span> emp sort <span class="keyword">by</span> deptno <span class="keyword">desc</span>;</span><br><span class="line">Query ID <span class="operator">=</span> root_20231221145709_3e9d4a83<span class="number">-8821</span><span class="number">-445</span>b<span class="number">-88</span>ea<span class="number">-3</span>b3c28006b39</span><br><span class="line">Total jobs <span class="operator">=</span> <span class="number">1</span></span><br><span class="line">Launching Job <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">1</span></span><br><span class="line">Number <span class="keyword">of</span> reduce tasks <span class="keyword">not</span> specified. Estimated <span class="keyword">from</span> input data size: <span class="number">1</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> limit the maximum number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.max<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">set</span> a constant number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line">Starting Job <span class="operator">=</span> job_1703140954122_0002, Tracking URL <span class="operator">=</span> http:<span class="operator">/</span><span class="operator">/</span>hadoop302:<span class="number">8088</span><span class="operator">/</span>proxy<span class="operator">/</span>application_1703140954122_0002<span class="operator">/</span></span><br><span class="line">Kill Command <span class="operator">=</span> <span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>hadoop<span class="operator">/</span>bin<span class="operator">/</span>mapred job  <span class="operator">-</span>kill job_1703140954122_0002</span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage<span class="number">-1</span>: number <span class="keyword">of</span> mappers: <span class="number">1</span>; number <span class="keyword">of</span> reducers: <span class="number">1</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">14</span>:<span class="number">57</span>:<span class="number">20</span>,<span class="number">783</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">14</span>:<span class="number">57</span>:<span class="number">49</span>,<span class="number">894</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>, Cumulative CPU <span class="number">2.4</span> sec</span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">14</span>:<span class="number">57</span>:<span class="number">56</span>,<span class="number">118</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>, Cumulative CPU <span class="number">6.37</span> sec</span><br><span class="line">MapReduce Total cumulative CPU <span class="type">time</span>: <span class="number">6</span> seconds <span class="number">370</span> msec</span><br><span class="line">Ended Job <span class="operator">=</span> job_1703140954122_0002</span><br><span class="line">MapReduce Jobs Launched:</span><br><span class="line">Stage<span class="operator">-</span>Stage<span class="number">-1</span>: Map: <span class="number">1</span>  Reduce: <span class="number">1</span>   Cumulative CPU: <span class="number">6.37</span> sec   HDFS Read: <span class="number">11552</span> HDFS Write: <span class="number">381</span> SUCCESS</span><br><span class="line">Total MapReduce CPU <span class="type">Time</span> Spent: <span class="number">6</span> seconds <span class="number">370</span> msec</span><br><span class="line">OK</span><br><span class="line">ename   deptno</span><br><span class="line">WARD    <span class="number">30</span></span><br><span class="line">ALLEN   <span class="number">30</span></span><br><span class="line">JAMES   <span class="number">30</span></span><br><span class="line">TURNER  <span class="number">30</span></span><br><span class="line">BLAKE   <span class="number">30</span></span><br><span class="line">MARTIN  <span class="number">30</span></span><br><span class="line">ADAMS   <span class="number">20</span></span><br><span class="line">FORD    <span class="number">20</span></span><br><span class="line">SCOTT   <span class="number">20</span></span><br><span class="line">SMITH   <span class="number">20</span></span><br><span class="line">JONES   <span class="number">20</span></span><br><span class="line">MILLER  <span class="number">10</span></span><br><span class="line">KING    <span class="number">10</span></span><br><span class="line">CLARK   <span class="number">10</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">48.494</span> seconds, Fetched: <span class="number">14</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br><span class="line"></span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">insert</span> overwrite <span class="keyword">local</span> directory <span class="string">&#x27;./sort-by&#x27;</span> <span class="keyword">select</span> ename, deptno <span class="keyword">from</span> emp sort <span class="keyword">by</span> deptno <span class="keyword">desc</span></span><br><span class="line">Query ID <span class="operator">=</span> root_20231221150201_252fecc3<span class="number">-3392</span><span class="number">-4406</span><span class="number">-86</span>a9<span class="number">-16862118760</span>c</span><br><span class="line">Total jobs <span class="operator">=</span> <span class="number">1</span></span><br><span class="line">Launching Job <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">1</span></span><br><span class="line">Number <span class="keyword">of</span> reduce tasks <span class="keyword">not</span> specified. Estimated <span class="keyword">from</span> input data size: <span class="number">1</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> limit the maximum number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.max<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">set</span> a constant number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line">Starting Job <span class="operator">=</span> job_1703140954122_0003, Tracking URL <span class="operator">=</span> http:<span class="operator">/</span><span class="operator">/</span>hadoop302:<span class="number">8088</span><span class="operator">/</span>proxy<span class="operator">/</span>application_1703140954122_00</span><br><span class="line">Kill Command <span class="operator">=</span> <span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>hadoop<span class="operator">/</span>bin<span class="operator">/</span>mapred job  <span class="operator">-</span>kill job_1703140954122_0003</span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage<span class="number">-1</span>: number <span class="keyword">of</span> mappers: <span class="number">1</span>; number <span class="keyword">of</span> reducers: <span class="number">1</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">15</span>:<span class="number">02</span>:<span class="number">09</span>,<span class="number">624</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">15</span>:<span class="number">02</span>:<span class="number">16</span>,<span class="number">872</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>, Cumulative CPU <span class="number">2.31</span> sec</span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">15</span>:<span class="number">02</span>:<span class="number">32</span>,<span class="number">538</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>, Cumulative CPU <span class="number">6.96</span> sec</span><br><span class="line">MapReduce Total cumulative CPU <span class="type">time</span>: <span class="number">6</span> seconds <span class="number">960</span> msec</span><br><span class="line">Ended Job <span class="operator">=</span> job_1703140954122_0003</span><br><span class="line">Moving data <span class="keyword">to</span> <span class="keyword">local</span> directory sort<span class="operator">-</span><span class="keyword">by</span></span><br><span class="line">MapReduce Jobs Launched:</span><br><span class="line">Stage<span class="operator">-</span>Stage<span class="number">-1</span>: Map: <span class="number">1</span>  Reduce: <span class="number">1</span>   Cumulative CPU: <span class="number">6.96</span> sec   HDFS Read: <span class="number">11130</span> HDFS Write: <span class="number">126</span> SUCCESS</span><br><span class="line">Total MapReduce CPU <span class="type">Time</span> Spent: <span class="number">6</span> seconds <span class="number">960</span> msec</span><br><span class="line">OK</span><br><span class="line">ename   deptno</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">32.725</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> </span><br><span class="line"></span><br><span class="line">[root<span class="variable">@hadoop301</span> sort<span class="operator">-</span><span class="keyword">by</span>]# cat <span class="number">000000</span>_1</span><br><span class="line">WARD30</span><br><span class="line">ALLEN30</span><br><span class="line">JAMES30</span><br><span class="line">TURNER30</span><br><span class="line">BLAKE30</span><br><span class="line">MARTIN30</span><br><span class="line">ADAMS20</span><br><span class="line">FORD20</span><br><span class="line">SCOTT20</span><br><span class="line">SMITH20</span><br><span class="line">JONES20</span><br><span class="line">MILLER10</span><br><span class="line">KING10</span><br><span class="line">CLARK10</span><br></pre></td></tr></table></figure>



<p>5）分区（Distribute By）</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> deptno, ename, sal <span class="keyword">from</span> emp <span class="keyword">order</span> <span class="keyword">by</span> deptno, sal;</span><br><span class="line">Query ID <span class="operator">=</span> root_20231221151421_b2584182<span class="number">-0</span>f82<span class="number">-49</span>ae<span class="operator">-</span>a8fe<span class="number">-0</span>a7d5703fb17</span><br><span class="line">Total jobs <span class="operator">=</span> <span class="number">1</span></span><br><span class="line">Launching Job <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">1</span></span><br><span class="line">Number <span class="keyword">of</span> reduce tasks determined <span class="keyword">at</span> compile <span class="type">time</span>: <span class="number">1</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> limit the maximum number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.max<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">set</span> a constant number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line">Starting Job <span class="operator">=</span> job_1703140954122_0005, Tracking URL <span class="operator">=</span> http:<span class="operator">/</span><span class="operator">/</span>hadoop302:<span class="number">8088</span><span class="operator">/</span>proxy<span class="operator">/</span>application_1703140954122_0005<span class="operator">/</span></span><br><span class="line">Kill Command <span class="operator">=</span> <span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>hadoop<span class="operator">/</span>bin<span class="operator">/</span>mapred job  <span class="operator">-</span>kill job_1703140954122_0005</span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage<span class="number">-1</span>: number <span class="keyword">of</span> mappers: <span class="number">1</span>; number <span class="keyword">of</span> reducers: <span class="number">1</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">15</span>:<span class="number">14</span>:<span class="number">30</span>,<span class="number">435</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">15</span>:<span class="number">14</span>:<span class="number">37</span>,<span class="number">677</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>, Cumulative CPU <span class="number">2.73</span> sec</span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">15</span>:<span class="number">14</span>:<span class="number">53</span>,<span class="number">130</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>, Cumulative CPU <span class="number">5.72</span> sec</span><br><span class="line">MapReduce Total cumulative CPU <span class="type">time</span>: <span class="number">5</span> seconds <span class="number">720</span> msec</span><br><span class="line">Ended Job <span class="operator">=</span> job_1703140954122_0005</span><br><span class="line">MapReduce Jobs Launched:</span><br><span class="line">Stage<span class="operator">-</span>Stage<span class="number">-1</span>: Map: <span class="number">1</span>  Reduce: <span class="number">1</span>   Cumulative CPU: <span class="number">5.72</span> sec   HDFS Read: <span class="number">11918</span> HDFS Write: <span class="number">477</span> SUCCESS</span><br><span class="line">Total MapReduce CPU <span class="type">Time</span> Spent: <span class="number">5</span> seconds <span class="number">720</span> msec</span><br><span class="line">OK</span><br><span class="line">deptno  ename   sal</span><br><span class="line"><span class="number">10</span>      MILLER  <span class="number">1300.0</span></span><br><span class="line"><span class="number">10</span>      CLARK   <span class="number">2450.0</span></span><br><span class="line"><span class="number">10</span>      KING    <span class="number">5000.0</span></span><br><span class="line"><span class="number">20</span>      SMITH   <span class="number">800.0</span></span><br><span class="line"><span class="number">20</span>      ADAMS   <span class="number">1100.0</span></span><br><span class="line"><span class="number">20</span>      JONES   <span class="number">2975.0</span></span><br><span class="line"><span class="number">20</span>      SCOTT   <span class="number">3000.0</span></span><br><span class="line"><span class="number">20</span>      FORD    <span class="number">3000.0</span></span><br><span class="line"><span class="number">30</span>      JAMES   <span class="number">950.0</span></span><br><span class="line"><span class="number">30</span>      MARTIN  <span class="number">1250.0</span></span><br><span class="line"><span class="number">30</span>      WARD    <span class="number">1250.0</span></span><br><span class="line"><span class="number">30</span>      TURNER  <span class="number">1500.0</span></span><br><span class="line"><span class="number">30</span>      ALLEN   <span class="number">1600.0</span></span><br><span class="line"><span class="number">30</span>      BLAKE   <span class="number">2850.0</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">33.702</span> seconds, Fetched: <span class="number">14</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="number">4</span>;</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> deptno, ename, sal <span class="keyword">from</span> emp distribute <span class="keyword">by</span> deptno sort <span class="keyword">by</span> sal;</span><br><span class="line">Query ID <span class="operator">=</span> root_20231221151653_41be6520<span class="operator">-</span>c6b1<span class="number">-4</span>bf1<span class="number">-9174</span><span class="operator">-</span>e526b9e2e37b</span><br><span class="line">Total jobs <span class="operator">=</span> <span class="number">1</span></span><br><span class="line">Launching Job <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">1</span></span><br><span class="line">Number <span class="keyword">of</span> reduce tasks <span class="keyword">not</span> specified. Defaulting <span class="keyword">to</span> jobconf <span class="keyword">value</span> <span class="keyword">of</span>: <span class="number">4</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> limit the maximum number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.max<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">set</span> a constant number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line">Starting Job <span class="operator">=</span> job_1703140954122_0006, Tracking URL <span class="operator">=</span> http:<span class="operator">/</span><span class="operator">/</span>hadoop302:<span class="number">8088</span><span class="operator">/</span>proxy<span class="operator">/</span>application_1703140954122_0006<span class="operator">/</span></span><br><span class="line">Kill Command <span class="operator">=</span> <span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>hadoop<span class="operator">/</span>bin<span class="operator">/</span>mapred job  <span class="operator">-</span>kill job_1703140954122_0006</span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage<span class="number">-1</span>: number <span class="keyword">of</span> mappers: <span class="number">1</span>; number <span class="keyword">of</span> reducers: <span class="number">4</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">15</span>:<span class="number">17</span>:<span class="number">02</span>,<span class="number">248</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">15</span>:<span class="number">17</span>:<span class="number">19</span>,<span class="number">881</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>, Cumulative CPU <span class="number">1.67</span> sec</span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">15</span>:<span class="number">17</span>:<span class="number">27</span>,<span class="number">204</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">25</span><span class="operator">%</span>, Cumulative CPU <span class="number">1.67</span> sec</span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">15</span>:<span class="number">17</span>:<span class="number">34</span>,<span class="number">546</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">75</span><span class="operator">%</span>, Cumulative CPU <span class="number">14.58</span> sec</span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">15</span>:<span class="number">17</span>:<span class="number">37</span>,<span class="number">660</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>, Cumulative CPU <span class="number">14.58</span> sec</span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">15</span>:<span class="number">17</span>:<span class="number">38</span>,<span class="number">687</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">75</span><span class="operator">%</span>, Cumulative CPU <span class="number">14.58</span> sec</span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">15</span>:<span class="number">17</span>:<span class="number">44</span>,<span class="number">917</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>, Cumulative CPU <span class="number">17.78</span> sec</span><br><span class="line">MapReduce Total cumulative CPU <span class="type">time</span>: <span class="number">17</span> seconds <span class="number">780</span> msec</span><br><span class="line">Ended Job <span class="operator">=</span> job_1703140954122_0006</span><br><span class="line">MapReduce Jobs Launched:</span><br><span class="line">Stage<span class="operator">-</span>Stage<span class="number">-1</span>: Map: <span class="number">1</span>  Reduce: <span class="number">4</span>   Cumulative CPU: <span class="number">17.78</span> sec   HDFS Read: <span class="number">28696</span> HDFS Write: <span class="number">738</span> SUCCESS</span><br><span class="line">Total MapReduce CPU <span class="type">Time</span> Spent: <span class="number">17</span> seconds <span class="number">780</span> msec</span><br><span class="line">OK</span><br><span class="line">deptno  ename   sal</span><br><span class="line"><span class="number">20</span>      SMITH   <span class="number">800.0</span></span><br><span class="line"><span class="number">20</span>      ADAMS   <span class="number">1100.0</span></span><br><span class="line"><span class="number">20</span>      JONES   <span class="number">2975.0</span></span><br><span class="line"><span class="number">20</span>      FORD    <span class="number">3000.0</span></span><br><span class="line"><span class="number">20</span>      SCOTT   <span class="number">3000.0</span></span><br><span class="line"><span class="number">30</span>      JAMES   <span class="number">950.0</span></span><br><span class="line"><span class="number">30</span>      MARTIN  <span class="number">1250.0</span></span><br><span class="line"><span class="number">30</span>      WARD    <span class="number">1250.0</span></span><br><span class="line"><span class="number">10</span>      MILLER  <span class="number">1300.0</span></span><br><span class="line"><span class="number">30</span>      TURNER  <span class="number">1500.0</span></span><br><span class="line"><span class="number">30</span>      ALLEN   <span class="number">1600.0</span></span><br><span class="line"><span class="number">10</span>      CLARK   <span class="number">2450.0</span></span><br><span class="line"><span class="number">30</span>      BLAKE   <span class="number">2850.0</span></span><br><span class="line"><span class="number">10</span>      KING    <span class="number">5000.0</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">53.548</span> seconds, Fetched: <span class="number">14</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br><span class="line"></span><br><span class="line"># 查看具体分区情况：</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">insert</span> overwrite <span class="keyword">local</span> directory <span class="string">&#x27;./distribute-by&#x27;</span> <span class="keyword">select</span> deptno, ename, sal <span class="keyword">from</span> emp distribute <span class="keyword">by</span> deptno sort <span class="keyword">by</span> sal;</span><br><span class="line">Query ID <span class="operator">=</span> root_20231221151945_ecf1bbf7<span class="number">-0841</span><span class="number">-418</span>d<span class="number">-83</span>dc<span class="number">-8</span>aaa891e488c</span><br><span class="line">Total jobs <span class="operator">=</span> <span class="number">1</span></span><br><span class="line">Launching Job <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">1</span></span><br><span class="line">Number <span class="keyword">of</span> reduce tasks <span class="keyword">not</span> specified. Defaulting <span class="keyword">to</span> jobconf <span class="keyword">value</span> <span class="keyword">of</span>: <span class="number">4</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> limit the maximum number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.max<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">set</span> a constant number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line">Starting Job <span class="operator">=</span> job_1703140954122_0007, Tracking URL <span class="operator">=</span> http:<span class="operator">/</span><span class="operator">/</span>hadoop302:<span class="number">8088</span><span class="operator">/</span>proxy<span class="operator">/</span>application_1703140954122_0007<span class="operator">/</span></span><br><span class="line">Kill Command <span class="operator">=</span> <span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>hadoop<span class="operator">/</span>bin<span class="operator">/</span>mapred job  <span class="operator">-</span>kill job_1703140954122_0007</span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage<span class="number">-1</span>: number <span class="keyword">of</span> mappers: <span class="number">1</span>; number <span class="keyword">of</span> reducers: <span class="number">4</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">15</span>:<span class="number">19</span>:<span class="number">53</span>,<span class="number">619</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">15</span>:<span class="number">20</span>:<span class="number">10</span>,<span class="number">196</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>, Cumulative CPU <span class="number">2.9</span> sec</span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">15</span>:<span class="number">20</span>:<span class="number">35</span>,<span class="number">519</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">25</span><span class="operator">%</span>, Cumulative CPU <span class="number">6.78</span> sec</span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span> <span class="number">15</span>:<span class="number">20</span>:<span class="number">43</span>,<span class="number">914</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>, Cumulative CPU <span class="number">14.8</span> sec</span><br><span class="line">MapReduce Total cumulative CPU <span class="type">time</span>: <span class="number">14</span> seconds <span class="number">800</span> msec</span><br><span class="line">Ended Job <span class="operator">=</span> job_1703140954122_0007</span><br><span class="line">Moving data <span class="keyword">to</span> <span class="keyword">local</span> directory distribute<span class="operator">-</span><span class="keyword">by</span></span><br><span class="line">MapReduce Jobs Launched:</span><br><span class="line">Stage<span class="operator">-</span>Stage<span class="number">-1</span>: Map: <span class="number">1</span>  Reduce: <span class="number">4</span>   Cumulative CPU: <span class="number">14.8</span> sec   HDFS Read: <span class="number">27060</span> HDFS Write: <span class="number">222</span> SUCCESS</span><br><span class="line">Total MapReduce CPU <span class="type">Time</span> Spent: <span class="number">14</span> seconds <span class="number">800</span> msec</span><br><span class="line">OK</span><br><span class="line">deptno  ename   sal</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">60.688</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br><span class="line"></span><br><span class="line"># 分了<span class="number">4</span>个区，其中有两个是空的</span><br><span class="line">[root<span class="variable">@hadoop301</span> distribute<span class="operator">-</span><span class="keyword">by</span>]# ll</span><br><span class="line">总用量 <span class="number">8</span></span><br><span class="line"><span class="operator">-</span>rw<span class="operator">-</span>r<span class="comment">--r--. 1 root root  78 12月 21 15:20 000000_3</span></span><br><span class="line"><span class="operator">-</span>rw<span class="operator">-</span>r<span class="comment">--r--. 1 root root   0 12月 21 15:20 000001_3</span></span><br><span class="line"><span class="operator">-</span>rw<span class="operator">-</span>r<span class="comment">--r--. 1 root root 144 12月 21 15:20 000002_3</span></span><br><span class="line"><span class="operator">-</span>rw<span class="operator">-</span>r<span class="comment">--r--. 1 root root   0 12月 21 15:20 000003_2</span></span><br><span class="line">[root<span class="variable">@hadoop301</span> distribute<span class="operator">-</span><span class="keyword">by</span>]# cat <span class="number">000000</span>_3</span><br><span class="line"><span class="number">20</span>SMITH800<span class="number">.0</span></span><br><span class="line"><span class="number">20</span>ADAMS1100<span class="number">.0</span></span><br><span class="line"><span class="number">20</span>JONES2975<span class="number">.0</span></span><br><span class="line"><span class="number">20</span>FORD3000<span class="number">.0</span></span><br><span class="line"><span class="number">20</span>SCOTT3000<span class="number">.0</span></span><br><span class="line">[root<span class="variable">@hadoop301</span> distribute<span class="operator">-</span><span class="keyword">by</span>]# cat <span class="number">000002</span>_3</span><br><span class="line"><span class="number">30</span>JAMES950<span class="number">.0</span></span><br><span class="line"><span class="number">30</span>MARTIN1250<span class="number">.0</span></span><br><span class="line"><span class="number">30</span>WARD1250<span class="number">.0</span></span><br><span class="line"><span class="number">10</span>MILLER1300<span class="number">.0</span></span><br><span class="line"><span class="number">30</span>TURNER1500<span class="number">.0</span></span><br><span class="line"><span class="number">30</span>ALLEN1600<span class="number">.0</span></span><br><span class="line"><span class="number">10</span>CLARK2450<span class="number">.0</span></span><br><span class="line"><span class="number">30</span>BLAKE2850<span class="number">.0</span></span><br><span class="line"><span class="number">10</span>KING5000<span class="number">.0</span></span><br><span class="line">[root<span class="variable">@hadoop301</span> distribute<span class="operator">-</span><span class="keyword">by</span>]#</span><br></pre></td></tr></table></figure>



<p>6）Cluster By</p>
<p>当distribute by和 sorts by字段相同时，可以使用cluster by方式。</p>
<p>cluster by除了具有distribute by的功能外还兼具sort by的功能。但是排序只能是升序排序，不能指定排序规则为ASC 或者DESC。</p>
<h4 id="十、分区表"><a href="#十、分区表" class="headerlink" title="十、分区表"></a>十、分区表</h4><p>（1）分区表</p>
<p>​		分区表实际上就是对应一个HDFS文件系统上的独立的文件夹，该文件夹下是该分区所有的数据文件。<strong>Hive中的分区就是分目录</strong>，把一个大的数据集根据业务需要分割成小的数据集。在查询时通过 WHERE子句中的表达式选择查询所需要的指定的分区，这样的查询效率会提高很多。</p>
<p>（2）分区表基本操作</p>
<ol>
<li>引入分区表（需要根据日期对日志进行管理，通过部门信息模拟</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"># 创建dept_par表</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">create table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> dept_par(deptno <span class="type">int</span>, dname string, loc string) partitioned <span class="keyword">by</span> (<span class="keyword">day</span> string) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">1.87</span> seconds</span><br><span class="line"></span><br><span class="line"># 分别导入分区数据</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/opt/module/data/dept1.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> dept_par <span class="keyword">partition</span>(<span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;2023-12-21&#x27;</span>);</span><br><span class="line">Loading data <span class="keyword">to</span> <span class="keyword">table</span> default.dept_par <span class="keyword">partition</span> (<span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span>)</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">1.348</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/opt/module/data/dept2.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> dept_par <span class="keyword">partition</span>(<span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;2023-12-22&#x27;</span>);</span><br><span class="line">Loading data <span class="keyword">to</span> <span class="keyword">table</span> default.dept_par <span class="keyword">partition</span> (<span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span>)</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">1.096</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/opt/module/data/dept3.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> dept_par <span class="keyword">partition</span>(<span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;2023-12-23&#x27;</span>);</span><br><span class="line">Loading data <span class="keyword">to</span> <span class="keyword">table</span> default.dept_par <span class="keyword">partition</span> (<span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-23</span>)</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.539</span> seconds</span><br><span class="line"></span><br><span class="line"># 查看数据</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> dept_par;</span><br><span class="line">OK</span><br><span class="line">dept_par.deptno dept_par.dname  dept_par.loc    dept_par.day</span><br><span class="line"><span class="number">10</span>      ACCOUNTING      <span class="number">1700</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-21</span></span><br><span class="line"><span class="number">20</span>      RESEARCH        <span class="number">1800</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-21</span></span><br><span class="line"><span class="number">30</span>      SALES   <span class="number">1900</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-22</span></span><br><span class="line"><span class="number">40</span>      OPERATIONS      <span class="number">1700</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-22</span></span><br><span class="line"><span class="number">50</span>      TEST    <span class="number">2000</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-23</span></span><br><span class="line"><span class="number">60</span>      DEV     <span class="number">1900</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-23</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">1.678</span> seconds, Fetched: <span class="number">6</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br><span class="line"></span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> dept_par <span class="keyword">where</span> <span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;2023-12-22&#x27;</span>;</span><br><span class="line">OK</span><br><span class="line">dept_par.deptno dept_par.dname  dept_par.loc    dept_par.day</span><br><span class="line"><span class="number">30</span>      SALES   <span class="number">1900</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-22</span></span><br><span class="line"><span class="number">40</span>      OPERATIONS      <span class="number">1700</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-22</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.853</span> seconds, Fetched: <span class="number">2</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> dept_par <span class="keyword">where</span> deptno<span class="operator">=</span><span class="number">10</span> <span class="keyword">or</span> deptno<span class="operator">=</span><span class="number">20</span>;</span><br><span class="line">OK</span><br><span class="line">dept_par.deptno dept_par.dname  dept_par.loc    dept_par.day</span><br><span class="line"><span class="number">10</span>      ACCOUNTING      <span class="number">1700</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-21</span></span><br><span class="line"><span class="number">20</span>      RESEARCH        <span class="number">1800</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-21</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.194</span> seconds, Fetched: <span class="number">2</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 创建dept_par表</span><br><span class="line">hive (default)&gt; create table if not exists dept_par(deptno int, dname string, loc string) partitioned by (day string) row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line"></span><br><span class="line"># 增加分区</span><br><span class="line">hive (default)&gt; alter table dept_par add partition(day=&#x27;2023-12-24&#x27;) partition(day=&#x27;2023-12-25&#x27;) partition(day=&#x27;2023-12-26&#x27;);</span><br></pre></td></tr></table></figure>





<ol start="2">
<li>增加分区</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">alter table</span> dept_par <span class="keyword">add</span> <span class="keyword">partition</span>(<span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;2023-12-24&#x27;</span>) <span class="keyword">partition</span>(<span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;2023-12-25&#x27;</span>) <span class="keyword">partition</span>(<span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;2023-12-26&#x27;</span>);</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.232</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>

<p><img data-src="E:/typora%E5%9B%BE%E7%89%87/image-20231221163927708.png" alt="image-20231221163927708"></p>
<ol start="3">
<li>删除分区</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">alter table</span> dept_par <span class="keyword">drop</span> <span class="keyword">partition</span>(<span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;2023-12-26&#x27;</span>), <span class="keyword">partition</span>(<span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;2023-12-25&#x27;</span>);</span><br><span class="line">Dropped the <span class="keyword">partition</span> <span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-25</span></span><br><span class="line">Dropped the <span class="keyword">partition</span> <span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-26</span></span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.312</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>注意：添多个分区中间用空格，删除多个分区中间用‘，’逗号</strong></p>
<ol start="4">
<li>查看分区有多少个</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">show</span> partitions dept_par;</span><br><span class="line">OK</span><br><span class="line"><span class="keyword">partition</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-23</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-24</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.141</span> seconds, Fetched: <span class="number">4</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



<ol start="5">
<li>查看分区表结构</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">desc</span> formatted dept_par;</span><br><span class="line">OK</span><br><span class="line">col_name        data_type       comment</span><br><span class="line"># col_name              data_type               comment</span><br><span class="line">deptno                  <span class="type">int</span></span><br><span class="line">dname                   string</span><br><span class="line">loc                     string</span><br><span class="line"></span><br><span class="line"># <span class="keyword">Partition</span> Information</span><br><span class="line"># col_name              data_type               comment</span><br><span class="line"><span class="keyword">day</span>                     string</span><br><span class="line"></span><br><span class="line"># Detailed <span class="keyword">Table</span> Information</span><br><span class="line">Database:               <span class="keyword">default</span></span><br><span class="line">OwnerType:              <span class="keyword">USER</span></span><br><span class="line">Owner:                  root</span><br><span class="line">CreateTime:             Thu <span class="type">Dec</span> <span class="number">21</span> <span class="number">16</span>:<span class="number">23</span>:<span class="number">41</span> CST <span class="number">2023</span></span><br><span class="line">LastAccessTime:         <span class="literal">UNKNOWN</span></span><br><span class="line">Retention:              <span class="number">0</span></span><br><span class="line">Location:               hdfs:<span class="operator">/</span><span class="operator">/</span>hadoop301:<span class="number">8020</span><span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>dept_par</span><br><span class="line"><span class="keyword">Table</span> Type:             MANAGED_TABLE</span><br><span class="line"><span class="keyword">Table</span> Parameters:</span><br><span class="line">        bucketing_version       <span class="number">2</span></span><br><span class="line">        numFiles                <span class="number">3</span></span><br><span class="line">        numPartitions           <span class="number">4</span></span><br><span class="line">        numRows                 <span class="number">0</span></span><br><span class="line">        rawDataSize             <span class="number">0</span></span><br><span class="line">        totalSize               <span class="number">94</span></span><br><span class="line">        transient_lastDdlTime   <span class="number">1703147021</span></span><br><span class="line"></span><br><span class="line"># Storage Information</span><br><span class="line">SerDe Library:          org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line">InputFormat:            org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">OutputFormat:           org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">Compressed:             <span class="keyword">No</span></span><br><span class="line">Num Buckets:            <span class="number">-1</span></span><br><span class="line">Bucket Columns:         []</span><br><span class="line">Sort Columns:           []</span><br><span class="line">Storage <span class="keyword">Desc</span> Params:</span><br><span class="line">        field.delim             \t</span><br><span class="line">        serialization.format    \t</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.178</span> seconds, Fetched: <span class="number">38</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



<p>（3）创建二级分区表</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"># 创建二级分区表</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">create table</span> dept_par2(deptno <span class="type">int</span>, dname string, loc string) partitioned <span class="keyword">by</span> (<span class="keyword">day</span> string, <span class="keyword">hour</span> string) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.132</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br><span class="line"></span><br><span class="line"># 分别导入数据</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/opt/module/data/dept1.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> dept_par2 <span class="keyword">partition</span>(<span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;2023-12-21&#x27;</span>, <span class="keyword">hour</span><span class="operator">=</span><span class="string">&#x27;11&#x27;</span>);</span><br><span class="line">Loading data <span class="keyword">to</span> <span class="keyword">table</span> default.dept_par2 <span class="keyword">partition</span> (<span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span>, <span class="keyword">hour</span><span class="operator">=</span><span class="number">11</span>)</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.551</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/opt/module/data/dept2.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> dept_par2 <span class="keyword">partition</span>(<span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;2023-12-22&#x27;</span>, <span class="keyword">hour</span><span class="operator">=</span><span class="string">&#x27;12&#x27;</span>);</span><br><span class="line">Loading data <span class="keyword">to</span> <span class="keyword">table</span> default.dept_par2 <span class="keyword">partition</span> (<span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span>, <span class="keyword">hour</span><span class="operator">=</span><span class="number">12</span>)</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.546</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/opt/module/data/dept3.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> dept_par2 <span class="keyword">partition</span>(<span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;2023-12-23&#x27;</span>, <span class="keyword">hour</span><span class="operator">=</span><span class="string">&#x27;13&#x27;</span>);</span><br><span class="line">Loading data <span class="keyword">to</span> <span class="keyword">table</span> default.dept_par2 <span class="keyword">partition</span> (<span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-23</span>, <span class="keyword">hour</span><span class="operator">=</span><span class="number">13</span>)</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.558</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br><span class="line"></span><br><span class="line"># 查看数据</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> dept_par2;</span><br><span class="line">OK</span><br><span class="line">dept_par2.deptno        dept_par2.dname dept_par2.loc   dept_par2.day   dept_par2.hour</span><br><span class="line"><span class="number">10</span>      ACCOUNTING      <span class="number">1700</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-21</span>      <span class="number">11</span></span><br><span class="line"><span class="number">20</span>      RESEARCH        <span class="number">1800</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-21</span>      <span class="number">11</span></span><br><span class="line"><span class="number">30</span>      SALES   <span class="number">1900</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-22</span>      <span class="number">12</span></span><br><span class="line"><span class="number">40</span>      OPERATIONS      <span class="number">1700</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-22</span>      <span class="number">12</span></span><br><span class="line"><span class="number">50</span>      TEST    <span class="number">2000</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-23</span>      <span class="number">13</span></span><br><span class="line"><span class="number">60</span>      DEV     <span class="number">1900</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-23</span>      <span class="number">13</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.169</span> seconds, Fetched: <span class="number">6</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br><span class="line"></span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> dept_par2 <span class="keyword">where</span> <span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;2023-12-22&#x27;</span>;</span><br><span class="line">OK</span><br><span class="line">dept_par2.deptno        dept_par2.dname dept_par2.loc   dept_par2.day   dept_par2.hour</span><br><span class="line"><span class="number">30</span>      SALES   <span class="number">1900</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-22</span>      <span class="number">12</span></span><br><span class="line"><span class="number">40</span>      OPERATIONS      <span class="number">1700</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-22</span>      <span class="number">12</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.253</span> seconds, Fetched: <span class="number">2</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> dept_par2 <span class="keyword">where</span> <span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;2023-12-22&#x27;</span> <span class="keyword">and</span> <span class="keyword">hour</span><span class="operator">=</span><span class="string">&#x27;12&#x27;</span>;</span><br><span class="line">OK</span><br><span class="line">dept_par2.deptno        dept_par2.dname dept_par2.loc   dept_par2.day   dept_par2.hour</span><br><span class="line"><span class="number">30</span>      SALES   <span class="number">1900</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-22</span>      <span class="number">12</span></span><br><span class="line"><span class="number">40</span>      OPERATIONS      <span class="number">1700</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-22</span>      <span class="number">12</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.151</span> seconds, Fetched: <span class="number">2</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



<ol>
<li>把数据直接上传到分区目录上，让分区表和数据产生关联的三种方式</li>
</ol>
<p>1）方式一：上传数据后修复</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"># 上传数据</span><br><span class="line">[root<span class="variable">@hadoop301</span> data]# hdfs dfs <span class="operator">-</span>mkdir <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>dept_par<span class="operator">/</span><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-25</span></span><br><span class="line">SLF4J: Failed <span class="keyword">to</span> load class &quot;org.slf4j.impl.StaticLoggerBinder&quot;.</span><br><span class="line">SLF4J: Defaulting <span class="keyword">to</span> <span class="keyword">no</span><span class="operator">-</span>operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http:<span class="operator">/</span><span class="operator">/</span>www.slf4j.org<span class="operator">/</span>codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line">[root<span class="variable">@hadoop301</span> data]# hdfs dfs <span class="operator">-</span>put dept1.txt <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>dept_par<span class="operator">/</span><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-25</span></span><br><span class="line">SLF4J: Failed <span class="keyword">to</span> load class &quot;org.slf4j.impl.StaticLoggerBinder&quot;.</span><br><span class="line">SLF4J: Defaulting <span class="keyword">to</span> <span class="keyword">no</span><span class="operator">-</span>operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http:<span class="operator">/</span><span class="operator">/</span>www.slf4j.org<span class="operator">/</span>codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line">[root<span class="variable">@hadoop301</span> data]#</span><br><span class="line"></span><br><span class="line"># 查看数据发现没有刚上传的数据</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> dept_par;</span><br><span class="line">OK</span><br><span class="line">dept_par.deptno dept_par.dname  dept_par.loc    dept_par.day</span><br><span class="line"><span class="number">10</span>      ACCOUNTING      <span class="number">1700</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-21</span></span><br><span class="line"><span class="number">20</span>      RESEARCH        <span class="number">1800</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-21</span></span><br><span class="line"><span class="number">30</span>      SALES   <span class="number">1900</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-22</span></span><br><span class="line"><span class="number">40</span>      OPERATIONS      <span class="number">1700</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-22</span></span><br><span class="line"><span class="number">50</span>      TEST    <span class="number">2000</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-23</span></span><br><span class="line"><span class="number">60</span>      DEV     <span class="number">1900</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-23</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.307</span> seconds, Fetched: <span class="number">6</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br><span class="line"></span><br><span class="line"># 也没有看见刚上传的分区</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">show</span> partitions dept_par;</span><br><span class="line">OK</span><br><span class="line"><span class="keyword">partition</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-23</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-24</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.17</span> seconds, Fetched: <span class="number">4</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br><span class="line"></span><br><span class="line"># 执行修复命令</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> msck repair <span class="keyword">table</span> dept_par;</span><br><span class="line">OK</span><br><span class="line">Partitions <span class="keyword">not</span> <span class="keyword">in</span> metastore:    dept_par:<span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-25</span></span><br><span class="line">Repair: Added <span class="keyword">partition</span> <span class="keyword">to</span> metastore dept_par:<span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-25</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.182</span> seconds, Fetched: <span class="number">2</span> <span class="type">row</span>(s)</span><br><span class="line"></span><br><span class="line"># 再次查看数据</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> dept_par;</span><br><span class="line">OK</span><br><span class="line">dept_par.deptno dept_par.dname  dept_par.loc    dept_par.day</span><br><span class="line"><span class="number">10</span>      ACCOUNTING      <span class="number">1700</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-21</span></span><br><span class="line"><span class="number">20</span>      RESEARCH        <span class="number">1800</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-21</span></span><br><span class="line"><span class="number">30</span>      SALES   <span class="number">1900</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-22</span></span><br><span class="line"><span class="number">40</span>      OPERATIONS      <span class="number">1700</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-22</span></span><br><span class="line"><span class="number">50</span>      TEST    <span class="number">2000</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-23</span></span><br><span class="line"><span class="number">60</span>      DEV     <span class="number">1900</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-23</span></span><br><span class="line"><span class="number">10</span>      ACCOUNTING      <span class="number">1700</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-25</span></span><br><span class="line"><span class="number">20</span>      RESEARCH        <span class="number">1800</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-25</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.142</span> seconds, Fetched: <span class="number">8</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">show</span> partitions dept_par;</span><br><span class="line">OK</span><br><span class="line"><span class="keyword">partition</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-23</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-24</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-25</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.091</span> seconds, Fetched: <span class="number">5</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>

<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271707163.png" alt="image-20231221172309210"></p>
<p>2）上传后添加分区</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"># 上传数据</span><br><span class="line">[root<span class="variable">@hadoop301</span> data]# hdfs dfs <span class="operator">-</span>put dept1.txt <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>dept_par<span class="operator">/</span><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-25</span></span><br><span class="line">SLF4J: Failed <span class="keyword">to</span> load class &quot;org.slf4j.impl.StaticLoggerBinder&quot;.</span><br><span class="line">SLF4J: Defaulting <span class="keyword">to</span> <span class="keyword">no</span><span class="operator">-</span>operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http:<span class="operator">/</span><span class="operator">/</span>www.slf4j.org<span class="operator">/</span>codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line">[root<span class="variable">@hadoop301</span> data]# hdfs dfs <span class="operator">-</span>put dept1.txt <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>dept_par<span class="operator">/</span><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-26</span></span><br><span class="line">SLF4J: Failed <span class="keyword">to</span> load class &quot;org.slf4j.impl.StaticLoggerBinder&quot;.</span><br><span class="line">SLF4J: Defaulting <span class="keyword">to</span> <span class="keyword">no</span><span class="operator">-</span>operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http:<span class="operator">/</span><span class="operator">/</span>www.slf4j.org<span class="operator">/</span>codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line">[root<span class="variable">@hadoop301</span> data]#</span><br><span class="line"></span><br><span class="line"># 查看数据发现没有刚上传的数据</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> dept_par;</span><br><span class="line">OK</span><br><span class="line">dept_par.deptno dept_par.dname  dept_par.loc    dept_par.day</span><br><span class="line"><span class="number">10</span>      ACCOUNTING      <span class="number">1700</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-21</span></span><br><span class="line"><span class="number">20</span>      RESEARCH        <span class="number">1800</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-21</span></span><br><span class="line"><span class="number">30</span>      SALES   <span class="number">1900</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-22</span></span><br><span class="line"><span class="number">40</span>      OPERATIONS      <span class="number">1700</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-22</span></span><br><span class="line"><span class="number">50</span>      TEST    <span class="number">2000</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-23</span></span><br><span class="line"><span class="number">60</span>      DEV     <span class="number">1900</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-23</span></span><br><span class="line"><span class="number">10</span>      ACCOUNTING      <span class="number">1700</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-25</span></span><br><span class="line"><span class="number">20</span>      RESEARCH        <span class="number">1800</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-25</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.201</span> seconds, Fetched: <span class="number">8</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">show</span> partitions dept_par;</span><br><span class="line">OK</span><br><span class="line"><span class="keyword">partition</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-23</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-24</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-25</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.088</span> seconds, Fetched: <span class="number">5</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br><span class="line"></span><br><span class="line"># 添加分区</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">alter table</span> dept_par <span class="keyword">add</span> <span class="keyword">partition</span>(<span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;2023-12-26&#x27;</span>);</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.11</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br><span class="line"></span><br><span class="line"># 查看数据</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> dept_par;</span><br><span class="line">OK</span><br><span class="line">dept_par.deptno dept_par.dname  dept_par.loc    dept_par.day</span><br><span class="line"><span class="number">10</span>      ACCOUNTING      <span class="number">1700</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-21</span></span><br><span class="line"><span class="number">20</span>      RESEARCH        <span class="number">1800</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-21</span></span><br><span class="line"><span class="number">30</span>      SALES   <span class="number">1900</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-22</span></span><br><span class="line"><span class="number">40</span>      OPERATIONS      <span class="number">1700</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-22</span></span><br><span class="line"><span class="number">50</span>      TEST    <span class="number">2000</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-23</span></span><br><span class="line"><span class="number">60</span>      DEV     <span class="number">1900</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-23</span></span><br><span class="line"><span class="number">10</span>      ACCOUNTING      <span class="number">1700</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-25</span></span><br><span class="line"><span class="number">20</span>      RESEARCH        <span class="number">1800</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-25</span></span><br><span class="line"><span class="number">10</span>      ACCOUNTING      <span class="number">1700</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-26</span></span><br><span class="line"><span class="number">20</span>      RESEARCH        <span class="number">1800</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-26</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.2</span> seconds, Fetched: <span class="number">10</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">show</span> partitions dept_par;</span><br><span class="line">OK</span><br><span class="line"><span class="keyword">partition</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-23</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-24</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-25</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-26</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.109</span> seconds, Fetched: <span class="number">6</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



<p>3）创建文件夹后 load 数据到分区</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"># 创建目录</span><br><span class="line">[root<span class="variable">@hadoop301</span> data]# hdfs dfs <span class="operator">-</span>mkdir <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>dept_par<span class="operator">/</span><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-27</span></span><br><span class="line">SLF4J: Failed <span class="keyword">to</span> load class &quot;org.slf4j.impl.StaticLoggerBinder&quot;.</span><br><span class="line">SLF4J: Defaulting <span class="keyword">to</span> <span class="keyword">no</span><span class="operator">-</span>operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http:<span class="operator">/</span><span class="operator">/</span>www.slf4j.org<span class="operator">/</span>codes.html#StaticLoggerBinder <span class="keyword">for</span> further details.</span><br><span class="line">[root<span class="variable">@hadoop301</span> data]#</span><br><span class="line"></span><br><span class="line">#上传数据</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/opt/module/data/dept1.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> dept_par <span class="keyword">partition</span>(<span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;2023-12-27&#x27;</span>);</span><br><span class="line">Loading data <span class="keyword">to</span> <span class="keyword">table</span> default.dept_par <span class="keyword">partition</span> (<span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-27</span>)</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.849</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br><span class="line"></span><br><span class="line"># 查看数据</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> dept_par;</span><br><span class="line">OK</span><br><span class="line">dept_par.deptno dept_par.dname  dept_par.loc    dept_par.day</span><br><span class="line"><span class="number">10</span>      ACCOUNTING      <span class="number">1700</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-21</span></span><br><span class="line"><span class="number">20</span>      RESEARCH        <span class="number">1800</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-21</span></span><br><span class="line"><span class="number">30</span>      SALES   <span class="number">1900</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-22</span></span><br><span class="line"><span class="number">40</span>      OPERATIONS      <span class="number">1700</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-22</span></span><br><span class="line"><span class="number">50</span>      TEST    <span class="number">2000</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-23</span></span><br><span class="line"><span class="number">60</span>      DEV     <span class="number">1900</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-23</span></span><br><span class="line"><span class="number">10</span>      ACCOUNTING      <span class="number">1700</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-25</span></span><br><span class="line"><span class="number">20</span>      RESEARCH        <span class="number">1800</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-25</span></span><br><span class="line"><span class="number">10</span>      ACCOUNTING      <span class="number">1700</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-26</span></span><br><span class="line"><span class="number">20</span>      RESEARCH        <span class="number">1800</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-26</span></span><br><span class="line"><span class="number">10</span>      ACCOUNTING      <span class="number">1700</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-27</span></span><br><span class="line"><span class="number">20</span>      RESEARCH        <span class="number">1800</span>    <span class="number">2023</span><span class="number">-12</span><span class="number">-27</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.209</span> seconds, Fetched: <span class="number">12</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">show</span> partitions dept_par;</span><br><span class="line">OK</span><br><span class="line"><span class="keyword">partition</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-21</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-23</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-24</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-25</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-26</span></span><br><span class="line"><span class="keyword">day</span><span class="operator">=</span><span class="number">2023</span><span class="number">-12</span><span class="number">-27</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.104</span> seconds, Fetched: <span class="number">7</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



<p>（4）动态分区</p>
<ol>
<li>开启动态分区参数设置</li>
</ol>
<p>1）开启动态分区功能（默认 true ，开启）</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.exec.dynamic.partition=<span class="literal">true</span></span><br></pre></td></tr></table></figure>

<p>2）设置为非严格模式（动态分区的模式，默认strict，表示必须指定至少一个分区为静态分区，nonstrict模式表示允许所有的分区字段都可以使用动态分区。)</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">set</span> hive.exec.dynamic.partition.mode=nonstrict;</span><br></pre></td></tr></table></figure>

<p>3）在所有执行MR的节点上，最大一共可以创建多少个动态分区。默认1000</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.exec.max.dynamic.partitions=1000</span><br></pre></td></tr></table></figure>

<p>4）**在每个执行MR的节点上，最大可以创建多少个动态分区。**该参数需要根据实际的数据来设定。比如:源数据中包含了一年的数据，即 day字段有365 个值，那么该参数就需要设置成大于365，如果使用默认值100，则会报错。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.exec.max.dynamic.partitions.pernode=100</span><br></pre></td></tr></table></figure>

<p>5）整个MR Job 中，最大可以创建多少个HDFS 文件。默认100000</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.exec.max.created.files=100000</span><br></pre></td></tr></table></figure>

<p>6）当有空分区生成时，是否抛出异常。一般不需要设置。默认falsee</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.error.on.empty.partition=<span class="literal">false</span></span><br></pre></td></tr></table></figure>



<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这个为静态分区</span></span><br><span class="line">hive (default)&gt; create table dept_no_par(dname string, loc string) partitioned by (deptno int) row format delimited fieldt<span class="string">&#x27;;</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">Time taken: 0.256 seconds</span></span><br><span class="line"><span class="string">hive (default)&gt; insert into table dept_no_par partition(deptno=&#x27;</span>70<span class="string">&#x27;) select dname, loc from dept;</span></span><br><span class="line"><span class="string">Query ID = root_20231221180145_d095d411-7a37-4871-b5d8-84bf6c2e3d31</span></span><br><span class="line"><span class="string">Total jobs = 3</span></span><br><span class="line"><span class="string">Launching Job 1 out of 3</span></span><br><span class="line"><span class="string">Number of reduce tasks not specified. Estimated from input data size: 1</span></span><br><span class="line"><span class="string">In order to change the average load for a reducer (in bytes):</span></span><br><span class="line"><span class="string">  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;</span></span><br><span class="line"><span class="string">In order to limit the maximum number of reducers:</span></span><br><span class="line"><span class="string">  set hive.exec.reducers.max=&lt;number&gt;</span></span><br><span class="line"><span class="string">In order to set a constant number of reducers:</span></span><br><span class="line"><span class="string">  set mapreduce.job.reduces=&lt;number&gt;</span></span><br><span class="line"><span class="string">Starting Job = job_1703140954122_0012, Tracking URL = http://hadoop302:8088/proxy/application_1703140954122_0012/</span></span><br><span class="line"><span class="string">Kill Command = /opt/module/hadoop/bin/mapred job  -kill job_1703140954122_0012</span></span><br><span class="line"><span class="string">Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1</span></span><br><span class="line"><span class="string">2023-12-21 18:01:56,356 Stage-1 map = 0%,  reduce = 0%</span></span><br><span class="line"><span class="string">2023-12-21 18:02:18,082 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 4.26 sec</span></span><br><span class="line"><span class="string">2023-12-21 18:02:27,368 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 7.6 sec</span></span><br><span class="line"><span class="string">MapReduce Total cumulative CPU time: 7 seconds 600 msec</span></span><br><span class="line"><span class="string">Ended Job = job_1703140954122_0012</span></span><br><span class="line"><span class="string">Stage-4 is selected by condition resolver.</span></span><br><span class="line"><span class="string">Stage-3 is filtered out by condition resolver.</span></span><br><span class="line"><span class="string">Stage-5 is filtered out by condition resolver.</span></span><br><span class="line"><span class="string">Moving data to directory hdfs://hadoop301:8020/user/hive/warehouse/dept_no_par/deptno=70/.hive-staging_hive_2023-12-21_18-01-45_026_4413549038787609633-1/-ext-10000</span></span><br><span class="line"><span class="string">Loading data to table default.dept_no_par partition (deptno=70)</span></span><br><span class="line"><span class="string">MapReduce Jobs Launched:</span></span><br><span class="line"><span class="string">Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 7.6 sec   HDFS Read: 14309 HDFS Write: 346 SUCCESS</span></span><br><span class="line"><span class="string">Total MapReduce CPU Time Spent: 7 seconds 600 msec</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">_col0   _col1</span></span><br><span class="line"><span class="string">Time taken: 45.237 seconds</span></span><br><span class="line"><span class="string">hive (default)&gt;</span></span><br><span class="line"><span class="string">hive (default)&gt; select * from dept_no_par;</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">dept_no_par.dname       dept_no_par.loc dept_no_par.deptno</span></span><br><span class="line"><span class="string">ACCOUNTING      1700    70</span></span><br><span class="line"><span class="string">RESEARCH        1800    70</span></span><br><span class="line"><span class="string">SALES   1900    70</span></span><br><span class="line"><span class="string">OPERATIONS      1700    70</span></span><br><span class="line"><span class="string">Time taken: 0.24 seconds, Fetched: 4 row(s)</span></span><br><span class="line"><span class="string">hive (default)&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 改为动态分区</span></span><br><span class="line"><span class="string">hive (default)&gt; insert into table dept_no_par partition(deptno) select dname, loc, deptno from dept;</span></span><br><span class="line"><span class="string">FAILED: SemanticException [Error 10096]: Dynamic partition strict mode requires at least one static partition column. To turn this off set hive.exec.dynamic.partition.mode=nonstrict</span></span><br><span class="line"><span class="string">hive (default)&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 修改退出严格模式</span></span><br><span class="line"><span class="string">hive (default)&gt; set hive.exec.dynamic.partition.mode=nonstrict;</span></span><br><span class="line"><span class="string">hive (default)&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 修改成动态分区</span></span><br><span class="line"><span class="string">hive (default)&gt; insert into table dept_no_par partition(deptno) select dname, loc, deptno from dept;</span></span><br><span class="line"><span class="string">Query ID = root_20231221181339_5eb7bd8a-3cd3-4051-92a9-426ba8c2470c</span></span><br><span class="line"><span class="string">Total jobs = 3</span></span><br><span class="line"><span class="string">Launching Job 1 out of 3</span></span><br><span class="line"><span class="string">Number of reduce tasks not specified. Estimated from input data size: 1</span></span><br><span class="line"><span class="string">In order to change the average load for a reducer (in bytes):</span></span><br><span class="line"><span class="string">  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;</span></span><br><span class="line"><span class="string">In order to limit the maximum number of reducers:</span></span><br><span class="line"><span class="string">  set hive.exec.reducers.max=&lt;number&gt;</span></span><br><span class="line"><span class="string">In order to set a constant number of reducers:</span></span><br><span class="line"><span class="string">  set mapreduce.job.reduces=&lt;number&gt;</span></span><br><span class="line"><span class="string">Starting Job = job_1703140954122_0015, Tracking URL = http://hadoop302:8088/proxy/application_1703140954122_0015/</span></span><br><span class="line"><span class="string">Kill Command = /opt/module/hadoop/bin/mapred job  -kill job_1703140954122_0015</span></span><br><span class="line"><span class="string">Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1</span></span><br><span class="line"><span class="string">2023-12-21 18:13:47,757 Stage-1 map = 0%,  reduce = 0%</span></span><br><span class="line"><span class="string">2023-12-21 18:14:09,609 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 5.41 sec</span></span><br><span class="line"><span class="string">2023-12-21 18:14:23,024 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 8.48 sec</span></span><br><span class="line"><span class="string">MapReduce Total cumulative CPU time: 8 seconds 480 msec</span></span><br><span class="line"><span class="string">Ended Job = job_1703140954122_0015</span></span><br><span class="line"><span class="string">Stage-4 is selected by condition resolver.</span></span><br><span class="line"><span class="string">Stage-3 is filtered out by condition resolver.</span></span><br><span class="line"><span class="string">Stage-5 is filtered out by condition resolver.</span></span><br><span class="line"><span class="string">Moving data to directory hdfs://hadoop301:8020/user/hive/warehouse/dept_no_par/.hive-staging_hive_2023-12-21_18-13-39_151_1212070029676765042-1/-ext-10000</span></span><br><span class="line"><span class="string">Loading data to table default.dept_no_par partition (deptno=null)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">         Time taken to load dynamic partitions: 0.574 seconds</span></span><br><span class="line"><span class="string">         Time taken for adding to write entity : 0.0 seconds</span></span><br><span class="line"><span class="string">MapReduce Jobs Launched:</span></span><br><span class="line"><span class="string">Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 8.48 sec   HDFS Read: 14744 HDFS Write: 781 SUCCESS</span></span><br><span class="line"><span class="string">Total MapReduce CPU Time Spent: 8 seconds 480 msec</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">_col0   _col1   _col2</span></span><br><span class="line"><span class="string">Time taken: 46.932 seconds</span></span><br><span class="line"><span class="string">hive (default)&gt; select * from dept_no_par;</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">dept_no_par.dname       dept_no_par.loc dept_no_par.deptno</span></span><br><span class="line"><span class="string">ACCOUNTING      1700    10</span></span><br><span class="line"><span class="string">RESEARCH        1800    20</span></span><br><span class="line"><span class="string">SALES   1900    30</span></span><br><span class="line"><span class="string">OPERATIONS      1700    40</span></span><br><span class="line"><span class="string">ACCOUNTING      1700    70</span></span><br><span class="line"><span class="string">RESEARCH        1800    70</span></span><br><span class="line"><span class="string">SALES   1900    70</span></span><br><span class="line"><span class="string">OPERATIONS      1700    70</span></span><br><span class="line"><span class="string">Time taken: 0.149 seconds, Fetched: 8 row(s)</span></span><br><span class="line"><span class="string">hive (default)&gt;</span></span><br></pre></td></tr></table></figure>





<h4 id="十一、分桶表"><a href="#十一、分桶表" class="headerlink" title="十一、分桶表"></a>十一、分桶表</h4><p>​		分区提供一个隔离数据和优化查询的便利方式。不过，并非所有的数据集都可形成合理的分区。对于一张表或者分区，Hive可以进一步组织成桶，也就是更为细粒度的数据范围划分。</p>
<ul>
<li>分桶是将数据集分解成更容易管理的若干部分的另一个技术。</li>
<li><strong>分区针对的是数据的存储路径;分桶针对的是数据文件。</strong></li>
</ul>
<p>（1）准备数据并分发</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 data]# vim stu.txt</span><br><span class="line">[root@hadoop301 data]# <span class="built_in">cat</span> stu.txt</span><br><span class="line">1001    ss1</span><br><span class="line">1002    ss2</span><br><span class="line">1003    ss3</span><br><span class="line">1004    ss4</span><br><span class="line">1005    ss5</span><br><span class="line">1006    ss6</span><br><span class="line">1007    ss7</span><br><span class="line">1008    ss8</span><br><span class="line">1009    ss9</span><br><span class="line">10010   ss10</span><br><span class="line">10011   ss11</span><br><span class="line">10012   ss12</span><br><span class="line">10013   ss13</span><br><span class="line">10014   ss14</span><br><span class="line">10015   ss15</span><br><span class="line">10016   ss16</span><br><span class="line">[root@hadoop301 data]# xsync stu.txt</span><br><span class="line">==================== hadoop301 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line"></span><br><span class="line">sent 46 bytes  received 12 bytes  38.67 bytes/sec</span><br><span class="line">total size is 158  speedup is 2.72</span><br><span class="line">==================== hadoop302 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line">stu.txt</span><br><span class="line"></span><br><span class="line">sent 251 bytes  received 35 bytes  572.00 bytes/sec</span><br><span class="line">total size is 158  speedup is 0.55</span><br><span class="line">==================== hadoop303 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line">stu.txt</span><br><span class="line"></span><br><span class="line">sent 251 bytes  received 35 bytes  572.00 bytes/sec</span><br><span class="line">total size is 158  speedup is 0.55</span><br><span class="line">[root@hadoop301 data]#</span><br></pre></td></tr></table></figure>



<p>（2）创建分桶表</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; CREATE EXTERNAL TABLE stu_buck(<span class="built_in">id</span> int, name string) CLUSTERED BY(<span class="built_in">id</span>) INTO 4 BUCKETS ROW FORMAT DELIMITED FIELDS TERMINATED BY <span class="string">&quot;\t&quot;</span>;</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.085 seconds</span><br><span class="line">hive (default)&gt;</span><br></pre></td></tr></table></figure>





<p>（3）查看表结构</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; desc formatted stu_buck;</span><br><span class="line">OK</span><br><span class="line">col_name        data_type       comment</span><br><span class="line"><span class="comment"># col_name              data_type               comment</span></span><br><span class="line"><span class="built_in">id</span>                      int</span><br><span class="line">name                    string</span><br><span class="line"></span><br><span class="line"><span class="comment"># Detailed Table Information</span></span><br><span class="line">Database:               default</span><br><span class="line">OwnerType:              USER</span><br><span class="line">Owner:                  root</span><br><span class="line">CreateTime:             Fri Dec 22 11:12:34 CST 2023</span><br><span class="line">LastAccessTime:         UNKNOWN</span><br><span class="line">Retention:              0</span><br><span class="line">Location:               hdfs://hadoop301:8020/user/hive/warehouse/stu_buck</span><br><span class="line">Table Type:             EXTERNAL_TABLE</span><br><span class="line">Table Parameters:</span><br><span class="line">        COLUMN_STATS_ACCURATE   &#123;\&quot;BASIC_STATS\&quot;:\&quot;<span class="literal">true</span>\&quot;,\&quot;COLUMN_STATS\&quot;:&#123;\&quot;<span class="built_in">id</span>\&quot;:\&quot;<span class="literal">true</span>\&quot;,\&quot;name\&quot;:\&quot;<span class="literal">true</span>\&quot;&#125;&#125;</span><br><span class="line">        EXTERNAL                TRUE</span><br><span class="line">        bucketing_version       2</span><br><span class="line">        numFiles                4</span><br><span class="line">        numRows                 16</span><br><span class="line">        rawDataSize             142</span><br><span class="line">        totalSize               158</span><br><span class="line">        transient_lastDdlTime   1703214861</span><br><span class="line"></span><br><span class="line"><span class="comment"># Storage Information</span></span><br><span class="line">SerDe Library:          org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line">InputFormat:            org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">OutputFormat:           org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">Compressed:             No</span><br><span class="line">Num Buckets:            4</span><br><span class="line">Bucket Columns:         [<span class="built_in">id</span>]</span><br><span class="line">Sort Columns:           []</span><br><span class="line">Storage Desc Params:</span><br><span class="line">        field.delim             \t</span><br><span class="line">        serialization.format    \t</span><br><span class="line">Time taken: 0.063 seconds, Fetched: 34 row(s)</span><br><span class="line">hive (default)&gt;</span><br></pre></td></tr></table></figure>





<p>（4）导入数据到分桶表中， </p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> <span class="keyword">TABLE</span> stu_buck <span class="keyword">SELECT</span> <span class="operator">*</span>  <span class="keyword">FROM</span> stu_buck1;</span><br><span class="line">Query ID <span class="operator">=</span> root_20231222111312_0e72dc21<span class="operator">-</span>d1c4<span class="number">-4851</span><span class="number">-9</span>b10<span class="number">-372374</span>bbbf1a</span><br><span class="line">Total jobs <span class="operator">=</span> <span class="number">2</span></span><br><span class="line">Launching Job <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">2</span></span><br><span class="line">Number <span class="keyword">of</span> reduce tasks determined <span class="keyword">at</span> compile <span class="type">time</span>: <span class="number">4</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> limit the maximum number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.max<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">set</span> a constant number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line">Starting Job <span class="operator">=</span> job_1703212836900_0007, Tracking URL <span class="operator">=</span> http:<span class="operator">/</span><span class="operator">/</span>hadoop302:<span class="number">8088</span><span class="operator">/</span>proxy<span class="operator">/</span>application_1703212836900_0007<span class="operator">/</span></span><br><span class="line">Kill Command <span class="operator">=</span> <span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>hadoop<span class="operator">/</span>bin<span class="operator">/</span>mapred job  <span class="operator">-</span>kill job_1703212836900_0007</span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage<span class="number">-1</span>: number <span class="keyword">of</span> mappers: <span class="number">1</span>; number <span class="keyword">of</span> reducers: <span class="number">4</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span> <span class="number">11</span>:<span class="number">13</span>:<span class="number">21</span>,<span class="number">931</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span> <span class="number">11</span>:<span class="number">13</span>:<span class="number">28</span>,<span class="number">115</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>, Cumulative CPU <span class="number">2.43</span> sec</span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span> <span class="number">11</span>:<span class="number">13</span>:<span class="number">36</span>,<span class="number">457</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">25</span><span class="operator">%</span>, Cumulative CPU <span class="number">6.46</span> sec</span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span> <span class="number">11</span>:<span class="number">13</span>:<span class="number">43</span>,<span class="number">659</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">50</span><span class="operator">%</span>, Cumulative CPU <span class="number">10.55</span> sec</span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span> <span class="number">11</span>:<span class="number">13</span>:<span class="number">49</span>,<span class="number">819</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">75</span><span class="operator">%</span>, Cumulative CPU <span class="number">10.55</span> sec</span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span> <span class="number">11</span>:<span class="number">13</span>:<span class="number">51</span>,<span class="number">892</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>, Cumulative CPU <span class="number">13.79</span> sec</span><br><span class="line">MapReduce Total cumulative CPU <span class="type">time</span>: <span class="number">13</span> seconds <span class="number">790</span> msec</span><br><span class="line">Ended Job <span class="operator">=</span> job_1703212836900_0007</span><br><span class="line">Loading data <span class="keyword">to</span> <span class="keyword">table</span> default.stu_buck</span><br><span class="line">Launching Job <span class="number">2</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">2</span></span><br><span class="line">Number <span class="keyword">of</span> reduce tasks determined <span class="keyword">at</span> compile <span class="type">time</span>: <span class="number">1</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> limit the maximum number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.max<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">set</span> a constant number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line">Starting Job <span class="operator">=</span> job_1703212836900_0008, Tracking URL <span class="operator">=</span> http:<span class="operator">/</span><span class="operator">/</span>hadoop302:<span class="number">8088</span><span class="operator">/</span>proxy<span class="operator">/</span>application_1703212836900_0008<span class="operator">/</span></span><br><span class="line">Kill Command <span class="operator">=</span> <span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>hadoop<span class="operator">/</span>bin<span class="operator">/</span>mapred job  <span class="operator">-</span>kill job_1703212836900_0008</span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage<span class="number">-3</span>: number <span class="keyword">of</span> mappers: <span class="number">1</span>; number <span class="keyword">of</span> reducers: <span class="number">1</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span> <span class="number">11</span>:<span class="number">14</span>:<span class="number">06</span>,<span class="number">479</span> Stage<span class="number">-3</span> map <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span> <span class="number">11</span>:<span class="number">14</span>:<span class="number">12</span>,<span class="number">736</span> Stage<span class="number">-3</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>, Cumulative CPU <span class="number">4.81</span> sec</span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span> <span class="number">11</span>:<span class="number">14</span>:<span class="number">18</span>,<span class="number">947</span> Stage<span class="number">-3</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>, Cumulative CPU <span class="number">7.8</span> sec</span><br><span class="line">MapReduce Total cumulative CPU <span class="type">time</span>: <span class="number">7</span> seconds <span class="number">800</span> msec</span><br><span class="line">Ended Job <span class="operator">=</span> job_1703212836900_0008</span><br><span class="line">MapReduce Jobs Launched:</span><br><span class="line">Stage<span class="operator">-</span>Stage<span class="number">-1</span>: Map: <span class="number">1</span>  Reduce: <span class="number">4</span>   Cumulative CPU: <span class="number">13.79</span> sec   HDFS Read: <span class="number">32975</span> HDFS Write: <span class="number">1232</span> SUCCESS</span><br><span class="line">Stage<span class="operator">-</span>Stage<span class="number">-3</span>: Map: <span class="number">1</span>  Reduce: <span class="number">1</span>   Cumulative CPU: <span class="number">7.8</span> sec   HDFS Read: <span class="number">12152</span> HDFS Write: <span class="number">336</span> SUCCESS</span><br><span class="line">Total MapReduce CPU <span class="type">Time</span> Spent: <span class="number">21</span> seconds <span class="number">590</span> msec</span><br><span class="line">OK</span><br><span class="line">stu_buck1.id    stu_buck1.name</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">68.992</span> seconds</span><br></pre></td></tr></table></figure>

<p><img data-src="https://raw.githubusercontent.com/cisgu/typora-picture/master/img/202601271707600.png" alt="image-20231222111925911"></p>
<p>（5）分桶表操作需要注意的事项</p>
<ol>
<li><p>reduce的个数设置为-1,让Job自行决定需要用多少个reduce或者将reduce 的个数设置为大于等于分桶表的桶数</p>
</li>
<li><p>从hdfs中 load数据到分桶表中，避免本地文件找不到问题</p>
</li>
<li><p>不要使用本地模式</p>
</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data <span class="built_in">local</span> inpath <span class="string">&#x27;/opt/module/data/stu.txt&#x27;</span> into table stu_buck1;</span><br></pre></td></tr></table></figure>



<p>（6）抽样查询</p>
<p>对于非常大的数据集,有时用户需要使用的是一个具有代表性的查询结果而不是全部结果。Hive可以通过对表进行抽样来满足这个需求。</p>
<p>语法:TABLESAMPLE(BUCKET x OUT OF y)</p>
<p>查询表 stu_buck 中的数据</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> stu_buck <span class="keyword">tablesample</span>(bucket <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">4</span> <span class="keyword">on</span> id);</span><br><span class="line">OK</span><br><span class="line">stu_buck.id     stu_buck.name</span><br><span class="line"><span class="number">1004</span>    ss4</span><br><span class="line"><span class="number">1009</span>    ss9</span><br><span class="line"><span class="number">10010</span>   ss10</span><br><span class="line"><span class="number">1002</span>    ss2</span><br><span class="line"><span class="number">1003</span>    ss3</span><br><span class="line"><span class="number">10015</span>   ss15</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.207</span> seconds, Fetched: <span class="number">6</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>注意:x的值必须小于等于y的值</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> stu_buck <span class="keyword">tablesample</span>(bucket <span class="number">4</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">1</span> <span class="keyword">on</span> id);</span><br><span class="line">FAILED: SemanticException [Error <span class="number">10061</span>]: Numerator should <span class="keyword">not</span> be bigger than denominator <span class="keyword">in</span> sample clause <span class="keyword">for</span> <span class="keyword">table</span> stu_buck</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



<h4 id="十二、函数"><a href="#十二、函数" class="headerlink" title="十二、函数"></a>十二、函数</h4><p>（1）系统内置函数</p>
<ol>
<li>查看系统自带的函数</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">show</span> functions;</span><br><span class="line">OK</span><br><span class="line">tab_name</span><br><span class="line"><span class="operator">!</span></span><br><span class="line"><span class="operator">!=</span></span><br><span class="line">$sum0</span><br><span class="line"><span class="operator">%</span></span><br><span class="line"><span class="operator">&amp;</span></span><br><span class="line"><span class="operator">*</span></span><br><span class="line"><span class="operator">+</span></span><br><span class="line"><span class="operator">-</span></span><br><span class="line"><span class="operator">/</span></span><br><span class="line"><span class="operator">&lt;</span></span><br><span class="line"><span class="operator">&lt;=</span></span><br><span class="line"><span class="operator">&lt;=&gt;</span></span><br><span class="line"><span class="operator">&lt;&gt;</span></span><br><span class="line"><span class="operator">=</span></span><br><span class="line"><span class="operator">=</span><span class="operator">=</span></span><br><span class="line"><span class="operator">&gt;</span></span><br><span class="line"><span class="operator">&gt;=</span></span><br><span class="line"><span class="operator">^</span></span><br><span class="line">abs</span><br><span class="line">acos</span><br><span class="line">add_months</span><br><span class="line">aes_decrypt</span><br><span class="line">aes_encrypt</span><br><span class="line"><span class="keyword">and</span></span><br><span class="line"><span class="keyword">array</span></span><br><span class="line">array_contains</span><br><span class="line">ascii</span><br><span class="line">asin</span><br><span class="line">assert_true</span><br><span class="line">assert_true_oom</span><br><span class="line">atan</span><br><span class="line">avg</span><br><span class="line">base64</span><br><span class="line"><span class="keyword">between</span></span><br><span class="line">bin</span><br><span class="line">bloom_filter</span><br><span class="line">bround</span><br><span class="line">cardinality_violation</span><br><span class="line"><span class="keyword">case</span></span><br><span class="line">cbrt</span><br><span class="line">ceil</span><br><span class="line">ceiling</span><br><span class="line"><span class="keyword">char_length</span></span><br><span class="line"><span class="keyword">character_length</span></span><br><span class="line">chr</span><br><span class="line">coalesce</span><br><span class="line">collect_list</span><br><span class="line">collect_set</span><br><span class="line">compute_stats</span><br><span class="line">concat</span><br><span class="line">concat_ws</span><br><span class="line">context_ngrams</span><br><span class="line">conv</span><br><span class="line">corr</span><br><span class="line">cos</span><br><span class="line">count</span><br><span class="line">covar_pop</span><br><span class="line">covar_samp</span><br><span class="line">crc32</span><br><span class="line">create_union</span><br><span class="line">cume_dist</span><br><span class="line">current_authorizer</span><br><span class="line">current_database</span><br><span class="line"><span class="built_in">current_date</span></span><br><span class="line">current_groups</span><br><span class="line"><span class="built_in">current_timestamp</span></span><br><span class="line"><span class="built_in">current_user</span></span><br><span class="line">date_add</span><br><span class="line">date_format</span><br><span class="line">date_sub</span><br><span class="line">datediff</span><br><span class="line"><span class="keyword">day</span></span><br><span class="line">dayofmonth</span><br><span class="line">dayofweek</span><br><span class="line">decode</span><br><span class="line">degrees</span><br><span class="line">dense_rank</span><br><span class="line">div</span><br><span class="line">e</span><br><span class="line">elt</span><br><span class="line">encode</span><br><span class="line">enforce_constraint</span><br><span class="line">exp</span><br><span class="line">explode</span><br><span class="line">extract_union</span><br><span class="line">factorial</span><br><span class="line">field</span><br><span class="line">find_in_set</span><br><span class="line">first_value</span><br><span class="line">floor</span><br><span class="line">floor_day</span><br><span class="line">floor_hour</span><br><span class="line">floor_minute</span><br><span class="line">floor_month</span><br><span class="line">floor_quarter</span><br><span class="line">floor_second</span><br><span class="line">floor_week</span><br><span class="line">floor_year</span><br><span class="line">format_number</span><br><span class="line">from_unixtime</span><br><span class="line">from_utc_timestamp</span><br><span class="line">get_json_object</span><br><span class="line">get_splits</span><br><span class="line">greatest</span><br><span class="line"><span class="keyword">grouping</span></span><br><span class="line">hash</span><br><span class="line">hex</span><br><span class="line">histogram_numeric</span><br><span class="line"><span class="keyword">hour</span></span><br><span class="line">if</span><br><span class="line"><span class="keyword">in</span></span><br><span class="line">in_bloom_filter</span><br><span class="line">in_file</span><br><span class="line">index</span><br><span class="line">initcap</span><br><span class="line">inline</span><br><span class="line">instr</span><br><span class="line">internal_interval</span><br><span class="line">isfalse</span><br><span class="line">isnotfalse</span><br><span class="line">isnotnull</span><br><span class="line">isnottrue</span><br><span class="line">isnull</span><br><span class="line">istrue</span><br><span class="line">java_method</span><br><span class="line">json_tuple</span><br><span class="line">lag</span><br><span class="line">last_day</span><br><span class="line">last_value</span><br><span class="line">lcase</span><br><span class="line">lead</span><br><span class="line">least</span><br><span class="line">length</span><br><span class="line">levenshtein</span><br><span class="line"><span class="keyword">like</span></span><br><span class="line">likeall</span><br><span class="line">likeany</span><br><span class="line">ln</span><br><span class="line">locate</span><br><span class="line">log</span><br><span class="line">log10</span><br><span class="line">log2</span><br><span class="line">logged_in_user</span><br><span class="line">lower</span><br><span class="line">lpad</span><br><span class="line">ltrim</span><br><span class="line">map</span><br><span class="line">map_keys</span><br><span class="line">map_values</span><br><span class="line">mask</span><br><span class="line">mask_first_n</span><br><span class="line">mask_hash</span><br><span class="line">mask_last_n</span><br><span class="line">mask_show_first_n</span><br><span class="line">mask_show_last_n</span><br><span class="line">matchpath</span><br><span class="line">max</span><br><span class="line">md5</span><br><span class="line">min</span><br><span class="line"><span class="keyword">minute</span></span><br><span class="line">mod</span><br><span class="line"><span class="keyword">month</span></span><br><span class="line">months_between</span><br><span class="line">murmur_hash</span><br><span class="line">named_struct</span><br><span class="line">negative</span><br><span class="line">next_day</span><br><span class="line">ngrams</span><br><span class="line">noop</span><br><span class="line">noopstreaming</span><br><span class="line">noopwithmap</span><br><span class="line">noopwithmapstreaming</span><br><span class="line"><span class="keyword">not</span></span><br><span class="line">ntile</span><br><span class="line">nullif</span><br><span class="line">nvl</span><br><span class="line"><span class="keyword">octet_length</span></span><br><span class="line"><span class="keyword">or</span></span><br><span class="line">parse_url</span><br><span class="line">parse_url_tuple</span><br><span class="line">percent_rank</span><br><span class="line">percentile</span><br><span class="line">percentile_approx</span><br><span class="line">pi</span><br><span class="line">pmod</span><br><span class="line">posexplode</span><br><span class="line">positive</span><br><span class="line">pow</span><br><span class="line">power</span><br><span class="line">printf</span><br><span class="line">quarter</span><br><span class="line">radians</span><br><span class="line">rand</span><br><span class="line">rank</span><br><span class="line">reflect</span><br><span class="line">reflect2</span><br><span class="line">regexp</span><br><span class="line">regexp_extract</span><br><span class="line">regexp_replace</span><br><span class="line">regr_avgx</span><br><span class="line">regr_avgy</span><br><span class="line">regr_count</span><br><span class="line">regr_intercept</span><br><span class="line">regr_r2</span><br><span class="line">regr_slope</span><br><span class="line">regr_sxx</span><br><span class="line">regr_sxy</span><br><span class="line">regr_syy</span><br><span class="line">repeat</span><br><span class="line">replace</span><br><span class="line">replicate_rows</span><br><span class="line">restrict_information_schema</span><br><span class="line">reverse</span><br><span class="line">rlike</span><br><span class="line">round</span><br><span class="line">row_number</span><br><span class="line">rpad</span><br><span class="line">rtrim</span><br><span class="line"><span class="keyword">second</span></span><br><span class="line">sentences</span><br><span class="line">sha</span><br><span class="line">sha1</span><br><span class="line">sha2</span><br><span class="line">shiftleft</span><br><span class="line">shiftright</span><br><span class="line">shiftrightunsigned</span><br><span class="line">sign</span><br><span class="line">sin</span><br><span class="line">size</span><br><span class="line">sort_array</span><br><span class="line">sort_array_by</span><br><span class="line">soundex</span><br><span class="line">space</span><br><span class="line">split</span><br><span class="line">sq_count_check</span><br><span class="line">sqrt</span><br><span class="line">stack</span><br><span class="line">std</span><br><span class="line">stddev</span><br><span class="line">stddev_pop</span><br><span class="line">stddev_samp</span><br><span class="line">str_to_map</span><br><span class="line">struct</span><br><span class="line">substr</span><br><span class="line">substring</span><br><span class="line">substring_index</span><br><span class="line">sum</span><br><span class="line">tan</span><br><span class="line">to_date</span><br><span class="line">to_epoch_milli</span><br><span class="line">to_unix_timestamp</span><br><span class="line">to_utc_timestamp</span><br><span class="line">translate</span><br><span class="line">trim</span><br><span class="line">trunc</span><br><span class="line">ucase</span><br><span class="line">udftoboolean</span><br><span class="line">udftobyte</span><br><span class="line">udftodouble</span><br><span class="line">udftofloat</span><br><span class="line">udftointeger</span><br><span class="line">udftolong</span><br><span class="line">udftoshort</span><br><span class="line">udftostring</span><br><span class="line">unbase64</span><br><span class="line">unhex</span><br><span class="line">unix_timestamp</span><br><span class="line">upper</span><br><span class="line">uuid</span><br><span class="line">var_pop</span><br><span class="line">var_samp</span><br><span class="line">variance</span><br><span class="line">version</span><br><span class="line">weekofyear</span><br><span class="line"><span class="keyword">when</span></span><br><span class="line">width_bucket</span><br><span class="line">windowingtablefunction</span><br><span class="line">xpath</span><br><span class="line">xpath_boolean</span><br><span class="line">xpath_double</span><br><span class="line">xpath_float</span><br><span class="line">xpath_int</span><br><span class="line">xpath_long</span><br><span class="line">xpath_number</span><br><span class="line">xpath_short</span><br><span class="line">xpath_string</span><br><span class="line"><span class="keyword">year</span></span><br><span class="line"><span class="operator">|</span></span><br><span class="line"><span class="operator">~</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.678</span> seconds, Fetched: <span class="number">289</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



<ol start="2">
<li>显示自带函数的用法</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; desc <span class="keyword">function</span> upper;</span><br><span class="line">OK</span><br><span class="line">tab_name</span><br><span class="line">upper(str) - Returns str with all characters changed to uppercase</span><br><span class="line">Time taken: 0.024 seconds, Fetched: 1 row(s)</span><br><span class="line">hive (default)&gt;</span><br></pre></td></tr></table></figure>



<ol start="3">
<li>详细显示自带函数的用法</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; desc <span class="keyword">function</span> extended upper;</span><br><span class="line">OK</span><br><span class="line">tab_name</span><br><span class="line">upper(str) - Returns str with all characters changed to uppercase</span><br><span class="line">Synonyms: ucase</span><br><span class="line">Example:</span><br><span class="line">  &gt; SELECT upper(<span class="string">&#x27;Facebook&#x27;</span>) FROM src LIMIT 1;</span><br><span class="line">  <span class="string">&#x27;FACEBOOK&#x27;</span></span><br><span class="line">Function class:org.apache.hadoop.hive.ql.udf.generic.GenericUDFUpper</span><br><span class="line">Function <span class="built_in">type</span>:BUILTIN</span><br><span class="line">Time taken: 0.019 seconds, Fetched: 7 row(s)</span><br><span class="line">hive (default)&gt;</span><br></pre></td></tr></table></figure>

<p>UDF: 一进一出</p>
<p>UDAF: 多近一出</p>
<p>UDTF:一进多出</p>
<p>“一”  代表的是输入数据的行数</p>
<p>（2）常见的函数</p>
<ol>
<li>空字段赋值</li>
</ol>
<p>1）函数说明</p>
<p>​		NVL:给值为NULL的数据赋值，它的格式是NVL( value，default_value)。它的功能是如果value为NULL，则NVL函数返回default_value的值，否则返回value的值，如果两个参数都为NULL ，则返回NULL。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果员工的comm 为NULL，则用-1代替</span></span><br><span class="line">hive (default)&gt; <span class="keyword">select</span> <span class="built_in">comm</span>, nvl(<span class="built_in">comm</span>, -1) from emp;</span><br><span class="line">OK</span><br><span class="line"><span class="built_in">comm</span>    _c1</span><br><span class="line">NULL    -1.0</span><br><span class="line">300.0   300.0</span><br><span class="line">500.0   500.0</span><br><span class="line">NULL    -1.0</span><br><span class="line">1400.0  1400.0</span><br><span class="line">NULL    -1.0</span><br><span class="line">NULL    -1.0</span><br><span class="line">NULL    -1.0</span><br><span class="line">NULL    -1.0</span><br><span class="line">0.0     0.0</span><br><span class="line">NULL    -1.0</span><br><span class="line">NULL    -1.0</span><br><span class="line">NULL    -1.0</span><br><span class="line">NULL    -1.0</span><br><span class="line">Time taken: 2.696 seconds, Fetched: 14 row(s)</span><br><span class="line">hive (default)&gt;</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果员工的 comm NULL, 则用领导id代替</span></span><br><span class="line">hive (default)&gt; <span class="keyword">select</span> <span class="built_in">comm</span>, nvl(<span class="built_in">comm</span>, mgr) from emp;</span><br><span class="line">OK</span><br><span class="line"><span class="built_in">comm</span>    _c1</span><br><span class="line">NULL    7902.0</span><br><span class="line">300.0   300.0</span><br><span class="line">500.0   500.0</span><br><span class="line">NULL    7839.0</span><br><span class="line">1400.0  1400.0</span><br><span class="line">NULL    7839.0</span><br><span class="line">NULL    7829.0</span><br><span class="line">NULL    7566.0</span><br><span class="line">NULL    NULL</span><br><span class="line">0.0     0.0</span><br><span class="line">NULL    7788.0</span><br><span class="line">NULL    7698.0</span><br><span class="line">NULL    7566.0</span><br><span class="line">NULL    7782.0</span><br><span class="line">Time taken: 0.223 seconds, Fetched: 14 row(s)</span><br><span class="line">hive (default)&gt;</span><br></pre></td></tr></table></figure>



<p>（3）CASE WHEN THEN ELSEEND</p>
<p>1）数据准备</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 data]# vim emp_sex.txt</span><br><span class="line">[root@hadoop301 data]# <span class="built_in">cat</span> emp_sex.txt</span><br><span class="line">悟空    A       男</span><br><span class="line">大海    A       男</span><br><span class="line">宋宋    B       男</span><br><span class="line">凤姐    A       女</span><br><span class="line">婷姐    B       女</span><br><span class="line">婷婷    B       女</span><br><span class="line">[root@hadoop301 data]#</span><br></pre></td></tr></table></figure>



<p>2）创建emp_sex并导入数据</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">create table</span> emp_sex(name string, dept_id string, sex string) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">1.527</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/opt/module/data/emp_sex.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> emp_sex;</span><br><span class="line">Loading data <span class="keyword">to</span> <span class="keyword">table</span> default.emp_sex</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">1.516</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp_sex;</span><br><span class="line">OK</span><br><span class="line">emp_sex.name    emp_sex.dept_id emp_sex.sex</span><br><span class="line">悟空    A       男</span><br><span class="line">大海    A       男</span><br><span class="line">宋宋    B       男</span><br><span class="line">凤姐    A       女</span><br><span class="line">婷姐    B       女</span><br><span class="line">婷婷    B       女</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.195</span> seconds, Fetched: <span class="number">6</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"># 需求：求出不同部门男女个多少人？</span><br><span class="line"></span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> dept_id, <span class="built_in">sum</span>(<span class="keyword">case</span> sex <span class="keyword">when</span> <span class="string">&#x27;男&#x27;</span> <span class="keyword">then</span> <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">end</span>) <span class="keyword">as</span> maleCount, <span class="built_in">sum</span>(<span class="keyword">case</span> sex <span class="keyword">when</span> <span class="string">&#x27;女&#x27;</span> <span class="keyword">then</span> <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">end</span>) <span class="keyword">as</span> femaleCount <span class="keyword">from</span> emp_sex <span class="keyword">group</span> <span class="keyword">by</span> dept_id;</span><br><span class="line">Query ID <span class="operator">=</span> root_20231222152543_f463696b<span class="number">-9</span>ff4<span class="number">-4</span>cf9<span class="number">-99</span>ed<span class="operator">-</span>fb838f761082</span><br><span class="line">Total jobs <span class="operator">=</span> <span class="number">1</span></span><br><span class="line">Launching Job <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">1</span></span><br><span class="line">Number <span class="keyword">of</span> reduce tasks <span class="keyword">not</span> specified. Estimated <span class="keyword">from</span> input data size: <span class="number">1</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> limit the maximum number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.max<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">set</span> a constant number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line">Starting Job <span class="operator">=</span> job_1703225841549_0002, Tracking URL <span class="operator">=</span> http:<span class="operator">/</span><span class="operator">/</span>hadoop302:<span class="number">8088</span><span class="operator">/</span>proxy<span class="operator">/</span>application_1703225841549_0002<span class="operator">/</span></span><br><span class="line">Kill Command <span class="operator">=</span> <span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>hadoop<span class="operator">/</span>bin<span class="operator">/</span>mapred job  <span class="operator">-</span>kill job_1703225841549_0002</span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage<span class="number">-1</span>: number <span class="keyword">of</span> mappers: <span class="number">1</span>; number <span class="keyword">of</span> reducers: <span class="number">1</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span> <span class="number">15</span>:<span class="number">25</span>:<span class="number">53</span>,<span class="number">860</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span> <span class="number">15</span>:<span class="number">26</span>:<span class="number">08</span>,<span class="number">376</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>, Cumulative CPU <span class="number">4.67</span> sec</span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span> <span class="number">15</span>:<span class="number">26</span>:<span class="number">15</span>,<span class="number">666</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>, Cumulative CPU <span class="number">8.19</span> sec</span><br><span class="line">MapReduce Total cumulative CPU <span class="type">time</span>: <span class="number">8</span> seconds <span class="number">190</span> msec</span><br><span class="line">Ended Job <span class="operator">=</span> job_1703225841549_0002</span><br><span class="line">MapReduce Jobs Launched:</span><br><span class="line">Stage<span class="operator">-</span>Stage<span class="number">-1</span>: Map: <span class="number">1</span>  Reduce: <span class="number">1</span>   Cumulative CPU: <span class="number">8.19</span> sec   HDFS Read: <span class="number">15186</span> HDFS Write: <span class="number">123</span> SUCCESS</span><br><span class="line">Total MapReduce CPU <span class="type">Time</span> Spent: <span class="number">8</span> seconds <span class="number">190</span> msec</span><br><span class="line">OK</span><br><span class="line">dept_id malecount       femalecount</span><br><span class="line">A       <span class="number">2</span>       <span class="number">1</span></span><br><span class="line">B       <span class="number">1</span>       <span class="number">2</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">32.891</span> seconds, Fetched: <span class="number">2</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">或</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> dept_id, <span class="built_in">sum</span>(if(sex<span class="operator">=</span><span class="string">&#x27;男&#x27;</span>,<span class="number">1</span>,<span class="number">0</span>)) <span class="keyword">as</span> maleCount, <span class="built_in">sum</span>(if(sex<span class="operator">=</span><span class="string">&#x27;女&#x27;</span>,<span class="number">1</span>,<span class="number">0</span>)) <span class="keyword">as</span> femaleCount <span class="keyword">from</span> emp_sex <span class="keyword">group</span> byept_id;</span><br><span class="line">Query ID <span class="operator">=</span> root_20231222152953_a484d6e6<span class="number">-0</span>f57<span class="number">-49</span>f9<span class="number">-98</span>c8<span class="operator">-</span>c04acab2c9f0</span><br><span class="line">Total jobs <span class="operator">=</span> <span class="number">1</span></span><br><span class="line">Launching Job <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">1</span></span><br><span class="line">Number <span class="keyword">of</span> reduce tasks <span class="keyword">not</span> specified. Estimated <span class="keyword">from</span> input data size: <span class="number">1</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> limit the maximum number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.max<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">set</span> a constant number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line">Starting Job <span class="operator">=</span> job_1703225841549_0003, Tracking URL <span class="operator">=</span> http:<span class="operator">/</span><span class="operator">/</span>hadoop302:<span class="number">8088</span><span class="operator">/</span>proxy<span class="operator">/</span>application_1703225841549_0003<span class="operator">/</span></span><br><span class="line">Kill Command <span class="operator">=</span> <span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>hadoop<span class="operator">/</span>bin<span class="operator">/</span>mapred job  <span class="operator">-</span>kill job_1703225841549_0003</span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage<span class="number">-1</span>: number <span class="keyword">of</span> mappers: <span class="number">1</span>; number <span class="keyword">of</span> reducers: <span class="number">1</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span> <span class="number">15</span>:<span class="number">30</span>:<span class="number">02</span>,<span class="number">661</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span> <span class="number">15</span>:<span class="number">30</span>:<span class="number">10</span>,<span class="number">897</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>, Cumulative CPU <span class="number">2.88</span> sec</span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span> <span class="number">15</span>:<span class="number">30</span>:<span class="number">18</span>,<span class="number">105</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>, Cumulative CPU <span class="number">2.88</span> sec</span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span> <span class="number">15</span>:<span class="number">30</span>:<span class="number">19</span>,<span class="number">125</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>, Cumulative CPU <span class="number">2.88</span> sec</span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span> <span class="number">15</span>:<span class="number">30</span>:<span class="number">26</span>,<span class="number">347</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>, Cumulative CPU <span class="number">6.37</span> sec</span><br><span class="line">MapReduce Total cumulative CPU <span class="type">time</span>: <span class="number">6</span> seconds <span class="number">370</span> msec</span><br><span class="line">Ended Job <span class="operator">=</span> job_1703225841549_0003</span><br><span class="line">MapReduce Jobs Launched:</span><br><span class="line">Stage<span class="operator">-</span>Stage<span class="number">-1</span>: Map: <span class="number">1</span>  Reduce: <span class="number">1</span>   Cumulative CPU: <span class="number">6.37</span> sec   HDFS Read: <span class="number">15182</span> HDFS Write: <span class="number">123</span> SUCCESS</span><br><span class="line">Total MapReduce CPU <span class="type">Time</span> Spent: <span class="number">6</span> seconds <span class="number">370</span> msec</span><br><span class="line">OK</span><br><span class="line">dept_id malecount       femalecount</span><br><span class="line">A       <span class="number">2</span>       <span class="number">1</span></span><br><span class="line">B       <span class="number">1</span>       <span class="number">2</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">33.667</span> seconds, Fetched: <span class="number">2</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



<p>（4）行转列</p>
<p>​		CONCAT(string A&#x2F;col, string B&#x2F;col…):  返回输入字符串连接后的结果，支持任意个输入字符串;</p>
<p>​		CONCAT_ws(separator, str1, str2..):它是一个特殊形式的 CONCAT()。第一个参数剩余参数间的分隔符。分隔符可以是与剩余参数一样的字符串。如果分隔符是NULL，返回值也将为NULL。这个函数会跳过分隔符参数后的任何NULL 和空字符串。分隔符将被加到被连接的字符串之间；</p>
<p>​		注意:CONCAT_Ws must be “string or array<string><br>​		COLLECT_SET(col):函数只接受基本数据类型，它的主要作用是将某字段的值进行去重汇总，产生Array类型字段。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"># concat函数：</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> concat(<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;-&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;-&#x27;</span>,<span class="string">&#x27;c&#x27;</span>);</span><br><span class="line">OK</span><br><span class="line">_c0</span><br><span class="line">a<span class="operator">-</span>b<span class="operator">-</span>c</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.635</span> seconds, Fetched: <span class="number">1</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> dept;</span><br><span class="line">OK</span><br><span class="line">dept.deptno     dept.dname      dept.loc</span><br><span class="line"><span class="number">10</span>      ACCOUNTING      <span class="number">1700</span></span><br><span class="line"><span class="number">20</span>      RESEARCH        <span class="number">1800</span></span><br><span class="line"><span class="number">30</span>      SALES   <span class="number">1900</span></span><br><span class="line"><span class="number">40</span>      OPERATIONS      <span class="number">1700</span></span><br><span class="line"><span class="number">10</span>      ACCOUNTING      <span class="number">1700</span></span><br><span class="line"><span class="number">20</span>      RESEARCH        <span class="number">1800</span></span><br><span class="line"><span class="number">30</span>      SALES   <span class="number">1900</span></span><br><span class="line"><span class="number">40</span>      OPERATIONS      <span class="number">1700</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.258</span> seconds, Fetched: <span class="number">8</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> concat(deptno,<span class="string">&#x27;-&#x27;</span>,dname) <span class="keyword">from</span> dept;</span><br><span class="line">OK</span><br><span class="line">_c0</span><br><span class="line"><span class="number">10</span><span class="operator">-</span>ACCOUNTING</span><br><span class="line"><span class="number">20</span><span class="operator">-</span>RESEARCH</span><br><span class="line"><span class="number">30</span><span class="operator">-</span>SALES</span><br><span class="line"><span class="number">40</span><span class="operator">-</span>OPERATIONS</span><br><span class="line"><span class="number">10</span><span class="operator">-</span>ACCOUNTING</span><br><span class="line"><span class="number">20</span><span class="operator">-</span>RESEARCH</span><br><span class="line"><span class="number">30</span><span class="operator">-</span>SALES</span><br><span class="line"><span class="number">40</span><span class="operator">-</span>OPERATIONS</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.144</span> seconds, Fetched: <span class="number">8</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br><span class="line"></span><br><span class="line"># concat_ws函数：</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> concat_ws(<span class="string">&#x27;-&#x27;</span>,<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>);</span><br><span class="line">OK</span><br><span class="line">_c0</span><br><span class="line">a<span class="operator">-</span>b<span class="operator">-</span>c</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.218</span> seconds, Fetched: <span class="number">1</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br><span class="line"></span><br><span class="line"># COLLECT_LIST函数：</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student6;</span><br><span class="line">OK</span><br><span class="line">student6.id     student6.name</span><br><span class="line"><span class="number">20220006</span>         周莒</span><br><span class="line"><span class="number">20220007</span>         宋交</span><br><span class="line"><span class="number">20220001</span>         张三</span><br><span class="line"><span class="number">20220002</span>         李四</span><br><span class="line"><span class="number">20220003</span>         王五</span><br><span class="line"><span class="number">20220004</span>         马六</span><br><span class="line"><span class="number">20220005</span>         李八</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.161</span> seconds, Fetched: <span class="number">7</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> collect_list(id) <span class="keyword">from</span> student22;</span><br><span class="line">Query ID <span class="operator">=</span> root_20231222163113_2817259e<span class="number">-26</span>ea<span class="number">-466</span>b<span class="number">-900</span>c<span class="number">-46</span>ed3e423271</span><br><span class="line">Total jobs <span class="operator">=</span> <span class="number">1</span></span><br><span class="line">Launching Job <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">1</span></span><br><span class="line">Number <span class="keyword">of</span> reduce tasks determined <span class="keyword">at</span> compile <span class="type">time</span>: <span class="number">1</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> limit the maximum number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.max<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">set</span> a constant number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line">Starting Job <span class="operator">=</span> job_1703225841549_0004, Tracking URL <span class="operator">=</span> http:<span class="operator">/</span><span class="operator">/</span>hadoop302:<span class="number">8088</span><span class="operator">/</span>proxy<span class="operator">/</span>application_1703225841549_0004<span class="operator">/</span></span><br><span class="line">Kill Command <span class="operator">=</span> <span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>hadoop<span class="operator">/</span>bin<span class="operator">/</span>mapred job  <span class="operator">-</span>kill job_1703225841549_0004</span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage<span class="number">-1</span>: number <span class="keyword">of</span> mappers: <span class="number">1</span>; number <span class="keyword">of</span> reducers: <span class="number">1</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span> <span class="number">16</span>:<span class="number">31</span>:<span class="number">27</span>,<span class="number">577</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span> <span class="number">16</span>:<span class="number">31</span>:<span class="number">35</span>,<span class="number">931</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>, Cumulative CPU <span class="number">3.49</span> sec</span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span> <span class="number">16</span>:<span class="number">31</span>:<span class="number">49</span>,<span class="number">475</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>, Cumulative CPU <span class="number">6.06</span> sec</span><br><span class="line">MapReduce Total cumulative CPU <span class="type">time</span>: <span class="number">6</span> seconds <span class="number">60</span> msec</span><br><span class="line">Ended Job <span class="operator">=</span> job_1703225841549_0004</span><br><span class="line">MapReduce Jobs Launched:</span><br><span class="line">Stage<span class="operator">-</span>Stage<span class="number">-1</span>: Map: <span class="number">1</span>  Reduce: <span class="number">1</span>   Cumulative CPU: <span class="number">6.06</span> sec   HDFS Read: <span class="number">8276</span> HDFS Write: <span class="number">144</span> SUCCESS</span><br><span class="line">Total MapReduce CPU <span class="type">Time</span> Spent: <span class="number">6</span> seconds <span class="number">60</span> msec</span><br><span class="line">OK</span><br><span class="line">_c0</span><br><span class="line">[&quot;20220001&quot;,&quot;20220002&quot;,&quot;20220003&quot;,&quot;20220004&quot;,&quot;20220005&quot;]</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">37.643</span> seconds, Fetched: <span class="number">1</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># COLLECT_SET函数：</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> collect_set(id) <span class="keyword">from</span> student22;</span><br><span class="line">Query ID <span class="operator">=</span> root_20231222163320_8b3d8e9f<span class="number">-358</span>b<span class="number">-46</span>fe<span class="number">-8</span>d97<span class="number">-39</span>d7e8ee4dc8</span><br><span class="line">Total jobs <span class="operator">=</span> <span class="number">1</span></span><br><span class="line">Launching Job <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">1</span></span><br><span class="line">Number <span class="keyword">of</span> reduce tasks determined <span class="keyword">at</span> compile <span class="type">time</span>: <span class="number">1</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> limit the maximum number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.max<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">set</span> a constant number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line">Starting Job <span class="operator">=</span> job_1703225841549_0005, Tracking URL <span class="operator">=</span> http:<span class="operator">/</span><span class="operator">/</span>hadoop302:<span class="number">8088</span><span class="operator">/</span>proxy<span class="operator">/</span>application_1703225841549_0005<span class="operator">/</span></span><br><span class="line">Kill Command <span class="operator">=</span> <span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>hadoop<span class="operator">/</span>bin<span class="operator">/</span>mapred job  <span class="operator">-</span>kill job_1703225841549_0005</span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage<span class="number">-1</span>: number <span class="keyword">of</span> mappers: <span class="number">1</span>; number <span class="keyword">of</span> reducers: <span class="number">1</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span> <span class="number">16</span>:<span class="number">33</span>:<span class="number">31</span>,<span class="number">475</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span></span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span> <span class="number">16</span>:<span class="number">33</span>:<span class="number">38</span>,<span class="number">879</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>, Cumulative CPU <span class="number">1.65</span> sec</span><br><span class="line"><span class="number">2023</span><span class="number">-12</span><span class="number">-22</span> <span class="number">16</span>:<span class="number">33</span>:<span class="number">56</span>,<span class="number">388</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>, Cumulative CPU <span class="number">4.81</span> sec</span><br><span class="line">MapReduce Total cumulative CPU <span class="type">time</span>: <span class="number">4</span> seconds <span class="number">810</span> msec</span><br><span class="line">Ended Job <span class="operator">=</span> job_1703225841549_0005</span><br><span class="line">MapReduce Jobs Launched:</span><br><span class="line">Stage<span class="operator">-</span>Stage<span class="number">-1</span>: Map: <span class="number">1</span>  Reduce: <span class="number">1</span>   Cumulative CPU: <span class="number">4.81</span> sec   HDFS Read: <span class="number">8348</span> HDFS Write: <span class="number">144</span> SUCCESS</span><br><span class="line">Total MapReduce CPU <span class="type">Time</span> Spent: <span class="number">4</span> seconds <span class="number">810</span> msec</span><br><span class="line">OK</span><br><span class="line">_c0</span><br><span class="line">[&quot;20220001&quot;,&quot;20220002&quot;,&quot;20220003&quot;,&quot;20220004&quot;,&quot;20220005&quot;]</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">37.72</span> seconds, Fetched: <span class="number">1</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>



























































<p>五、HIveCLL命令的基本使用</p>
<ol>
<li>Help</li>
</ol>
<p>使用 <code>hive -H</code> 或者 <code>hive --help</code> 命令可以查看所有命令的帮助</p>
<ol start="2">
<li>交互式命令行</li>
</ol>
<p>直接使用 <code>Hive</code> 命令，不加任何参数，即可进入交互式命令行</p>
<ol start="3">
<li>执行SQL命令</li>
</ol>
<p>在不进入交互式命令行的情况下，可以使用 <code>hive -e </code> 执行 SQL 命令</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive -e <span class="string">&#x27;select * from emp&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>用于执行的 sql 脚本可以在本地文件系统，也可以在 HDFS 上</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 本地文件系统</span></span><br><span class="line">hive -f /usr/file/simple.sql;</span><br><span class="line"></span><br><span class="line"><span class="comment"># HDFS文件系统</span></span><br><span class="line">hive -f hdfs://hadoop001:8020/tmp/simple.sql;</span><br></pre></td></tr></table></figure>



<ol start="4">
<li>配置Hive变量</li>
</ol>
<p>可以使用 <code>--hiveconf</code> 设置 Hive 运行时的变量</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive -e <span class="string">&#x27;select * from emp&#x27;</span> \</span><br><span class="line">--hiveconf hive.exec.scratchdir=/tmp/hive_scratch  \</span><br><span class="line">--hiveconf mapred.reduce.tasks=4;</span><br></pre></td></tr></table></figure>



<ol start="5">
<li>配置文件启动</li>
</ol>
<p>使用 <code>-i</code> 可以在进入交互模式之前运行初始化脚本，相当于指定配置文件启动</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive -i /usr/file/hive-init.conf;</span><br></pre></td></tr></table></figure>

<p><code>hive-init.conf</code> 的内容如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">set</span> hive.exec.mode.local.auto = <span class="literal">true</span>;</span><br></pre></td></tr></table></figure>



<ol start="6">
<li>用户自定义变量</li>
</ol>
<p><code>--define &lt;key=value&gt; </code> 和 <code>--hivevar &lt;key=value&gt;  </code> 在功能上是等价的，都是用来实现自定义变量</p>
<p>定义变量：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive  --define  n=ename --hiveconf  --hivevar j=job;</span><br></pre></td></tr></table></figure>

<p>在查询中引用自定义变量：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 以下两条语句等价</span></span><br><span class="line">hive &gt; <span class="keyword">select</span> <span class="variable">$&#123;n&#125;</span> from emp;</span><br><span class="line">hive &gt;  <span class="keyword">select</span> <span class="variable">$&#123;hivevar:n&#125;</span> from emp;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以下两条语句等价</span></span><br><span class="line">hive &gt; <span class="keyword">select</span> <span class="variable">$&#123;j&#125;</span> from emp;</span><br><span class="line">hive &gt;  <span class="keyword">select</span> <span class="variable">$&#123;hivevar:j&#125;</span> from emp;</span><br></pre></td></tr></table></figure>





<p>六、Beeline命令的基本使用</p>
<ol>
<li>Beeline</li>
</ol>
<p>Beeline 拥有更多可使用参数，可以使用 <code>beeline --help</code> 查看</p>
<ol start="2">
<li>常用参数</li>
</ol>
<p>在 Hive CLI 中支持的参数，Beeline 都支持，常用的参数如下：</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><strong>-u <database URL></strong></td>
<td>数据库地址</td>
</tr>
<tr>
<td><strong>-n <username></strong></td>
<td>用户名</td>
</tr>
<tr>
<td><strong>-p <password></strong></td>
<td>密码</td>
</tr>
<tr>
<td><strong>-d <driver class></strong></td>
<td>驱动 (可选)</td>
</tr>
<tr>
<td><strong>-e <query></strong></td>
<td>执行 SQL 命令</td>
</tr>
<tr>
<td><strong>-f <file></strong></td>
<td>执行 SQL 脚本</td>
</tr>
<tr>
<td><strong>-i (or)–init <file or files></strong></td>
<td>在进入交互模式之前运行初始化脚本</td>
</tr>
<tr>
<td><strong>–property-file <file></strong></td>
<td>指定配置文件</td>
</tr>
<tr>
<td><strong>–hiveconf</strong> <em>property</em>*&#x3D;*<em>value</em></td>
<td>指定配置属性</td>
</tr>
<tr>
<td><strong>–hivevar</strong> <em>name</em>*&#x3D;*<em>value</em></td>
<td>用户自定义属性，在会话级别有效</td>
</tr>
</tbody></table>
<p>使用用户名和密码连接 Hive</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ beeline -u jdbc:hive2://localhost:10000  -n username -p password </span><br></pre></td></tr></table></figure>



<ol start="3">
<li>Hive配置</li>
</ol>
<p>可以通过三种方式对 Hive 的相关属性进行配置</p>
<p>1).配置文件</p>
<p>方式一为使用配置文件，使用配置文件指定的配置是永久有效的。Hive 有以下三个可选的配置文件：</p>
<ul>
<li>hive-site.xml ：Hive 的主要配置文件；</li>
<li>hivemetastore-site.xml： 关于元数据的配置；</li>
<li>hiveserver2-site.xml：关于 HiveServer2 的配置。</li>
</ul>
<p>示例如下,在 hive-site.xml 配置 <code>hive.exec.scratchdir</code>：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">   &lt;name&gt;hive.exec.scratchdir&lt;/name&gt;</span><br><span class="line">   &lt;value&gt;/tmp/mydir&lt;/value&gt;</span><br><span class="line">   &lt;description&gt;Scratch space <span class="keyword">for</span> Hive <span class="built_in">jobs</span>&lt;/description&gt;</span><br><span class="line"> &lt;/property&gt;</span><br></pre></td></tr></table></figure>



<p>2).hiveconf</p>
<p>方式二为在启动命令行 (Hive CLI &#x2F; Beeline) 的时候使用 <code>--hiveconf</code> 指定配置，这种方式指定的配置作用于整个 Session。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive --hiveconf hive.exec.scratchdir=/tmp/mydir</span><br></pre></td></tr></table></figure>



<p>3).set</p>
<p>方式三为在交互式环境下 (Hive CLI &#x2F; Beeline)，使用 set 命令指定。这种设置的作用范围也是 Session 级别的，配置对于执行该命令后的所有命令生效。set 兼具设置参数和查看参数的功能。如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">0: jdbc:hive2://hadoop001:10000&gt; <span class="built_in">set</span> hive.exec.scratchdir=/tmp/mydir;</span><br><span class="line">No rows affected (0.025 seconds)</span><br><span class="line">0: jdbc:hive2://hadoop001:10000&gt; <span class="built_in">set</span> hive.exec.scratchdir;</span><br><span class="line">+----------------------------------+--+</span><br><span class="line">|               <span class="built_in">set</span>                |</span><br><span class="line">+----------------------------------+--+</span><br><span class="line">| hive.exec.scratchdir=/tmp/mydir  |</span><br><span class="line">+---------------------------</span><br></pre></td></tr></table></figure>









<h3 id="Spark-基础"><a href="#Spark-基础" class="headerlink" title="Spark 基础"></a>Spark 基础</h3><h4 id="一、WordCount-功能实现"><a href="#一、WordCount-功能实现" class="headerlink" title="一、WordCount 功能实现"></a>一、WordCount 功能实现</h4><p>提前在pom.xml添加如下配置</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependencies&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;spark-core_2.12&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;3.0.0&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">&lt;/dependencies&gt;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> spark.wc</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">demo01</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//Application</span></span><br><span class="line">    <span class="comment">//Spark框架</span></span><br><span class="line">    <span class="comment">//TODO 建立和Spark框架的连接</span></span><br><span class="line">    <span class="comment">//JDBC：Connection</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> sparConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">&quot;local&quot;</span>).setAppName(<span class="string">&quot;WordCount&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(sparConf)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 执行业务操作</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1. 读取文件，获取一行一行的数据</span></span><br><span class="line">    <span class="comment">//    hello   world</span></span><br><span class="line">    <span class="keyword">val</span> lines: <span class="type">RDD</span>[<span class="type">String</span>] = sc.textFile(<span class="string">&quot;datas&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2. 将一行数据进行拆分，形成一个一个的单词（分词）</span></span><br><span class="line">    <span class="comment">//  扁平化：将整个拆分成个体的操作</span></span><br><span class="line">    <span class="comment">//    &quot;hello world&quot; =&gt; hello, world, hello, world</span></span><br><span class="line">    <span class="keyword">val</span> words: <span class="type">RDD</span>[<span class="type">String</span>] = lines.flatMap(_.split(<span class="string">&quot; &quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3. 将数据根据单词进行分组，便于统计</span></span><br><span class="line">    <span class="comment">//    (hello, hello, hello),  (world, world)</span></span><br><span class="line">    <span class="keyword">val</span> wordGroup: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Iterable</span>[<span class="type">String</span>])] = words.groupBy(word=&gt;word)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 4. 对分组后的数据进行转换</span></span><br><span class="line">    <span class="comment">//    (hello, hello, hello),  (world, world)</span></span><br><span class="line">    <span class="comment">//    (hello, 3),  (world, 2)</span></span><br><span class="line">    <span class="keyword">val</span> wordToCount: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordGroup.map &#123;</span><br><span class="line">      <span class="keyword">case</span> (word, list) =&gt;&#123;</span><br><span class="line">        (word, list.size)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 5. 将转换的结果采集到控制台打印出来</span></span><br><span class="line">    <span class="keyword">val</span> array: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordToCount.collect()</span><br><span class="line">    array.foreach(println)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 关闭连接</span></span><br><span class="line">    sc.stop()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> spark.wc</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">demo02</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//TODO 建立和Spark框架的连接</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> sparConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">&quot;local&quot;</span>).setAppName(<span class="string">&quot;WordCount&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(sparConf)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 执行业务操作</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> lines: <span class="type">RDD</span>[<span class="type">String</span>] = sc.textFile(<span class="string">&quot;datas&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> words: <span class="type">RDD</span>[<span class="type">String</span>] = lines.flatMap(_.split(<span class="string">&quot; &quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> wordToOne = words.map(</span><br><span class="line">      word =&gt; (word, <span class="number">1</span>)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> wordGroup: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Iterable</span>[(<span class="type">String</span>, <span class="type">Int</span>)])] = wordToOne.groupBy(</span><br><span class="line">      t =&gt; t._1</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> wordToCount = wordGroup.map &#123;</span><br><span class="line">      <span class="keyword">case</span> (word, list) =&gt;&#123;</span><br><span class="line">        list.reduce(</span><br><span class="line">          (t1, t2) =&gt; &#123;</span><br><span class="line">            (t1._1, t1._2 + t2._2)</span><br><span class="line">          &#125;</span><br><span class="line">        )</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> array: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordToCount.collect()</span><br><span class="line">    array.foreach(println)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 关闭连接</span></span><br><span class="line">    sc.stop()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> spark.wc</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">demo03</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//TODO 建立和Spark框架的连接</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> sparConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">&quot;local&quot;</span>).setAppName(<span class="string">&quot;WordCount&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(sparConf)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 执行业务操作</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> lines: <span class="type">RDD</span>[<span class="type">String</span>] = sc.textFile(<span class="string">&quot;datas&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> words: <span class="type">RDD</span>[<span class="type">String</span>] = lines.flatMap(_.split(<span class="string">&quot; &quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> wordToOne = words.map(</span><br><span class="line">      word =&gt; (word, <span class="number">1</span>)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Spark 框架提供了更多的功能，可以将分组和聚合使用一个方法实现</span></span><br><span class="line">    <span class="comment">// reduceByKey : 相同的Key的数据，可以对Value进行reduce聚合</span></span><br><span class="line"><span class="comment">//    wordToOne.reduceByKey((x, y) =&gt; &#123;x + y&#125;)</span></span><br><span class="line"><span class="comment">//    wordToOne.reduceByKey((x, y) =&gt; x + y)</span></span><br><span class="line">    <span class="keyword">val</span> wordToCount = wordToOne.reduceByKey(_+_)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> array: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordToCount.collect()</span><br><span class="line">    array.foreach(println)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 关闭连接</span></span><br><span class="line">    sc.stop()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="二、本地部署模式"><a href="#二、本地部署模式" class="headerlink" title="二、本地部署模式"></a>二、本地部署模式</h4><p>1). 上传相应spark压缩包并解压到对应目录</p>
<p>2). 重命名方便后面使用</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 module]# ll</span><br><span class="line">总用量 0</span><br><span class="line">drwxr-xr-x. 11 yun   yun   173 12月  7 10:31 hadoop</span><br><span class="line">drwxr-xr-x. 11 root  root  221 12月 11 15:04 hive</span><br><span class="line">drwxr-xr-x.  8 yun   yun   255 12月 20 2017 jdk</span><br><span class="line">drwxr-xr-x. 10 mysql mysql 141 12月  6 15:49 mysql</span><br><span class="line">drwxr-xr-x. 13 yun   yun   211 12月 12 09:12 spark</span><br></pre></td></tr></table></figure>

<p>3). 在 spark&#x2F;data&#x2F;下新建一个word.txt文件，并添加如下内容</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Hello Scala</span><br><span class="line">Hello Spark</span><br><span class="line">Hello Scala</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 data]# ll</span><br><span class="line">总用量 8</span><br><span class="line">drwxr-xr-x. 2 yun  yun    44 2月  22 2021 graphx</span><br><span class="line">drwxr-xr-x. 5 yun  yun  4096 2月  22 2021 mllib</span><br><span class="line">drwxr-xr-x. 2 yun  yun    27 2月  22 2021 streaming</span><br><span class="line">-rw-r--r--. 1 root root   37 12月 12 09:16 word.txt</span><br></pre></td></tr></table></figure>

<p>4). 进入spark</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root<span class="meta">@hadoop</span>301 spark]# bin/spark-shell</span><br><span class="line"><span class="number">23</span>/<span class="number">12</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">35</span>:<span class="number">18</span> <span class="type">WARN</span> <span class="type">NativeCodeLoader</span>: <span class="type">Unable</span> to load native-hadoop library <span class="keyword">for</span> your platform... using builtin-java classes where applicable</span><br><span class="line"><span class="type">Using</span> <span class="type">Spark</span>&#x27;s <span class="keyword">default</span> log4j profile: org/apache/spark/log4j-defaults.properties</span><br><span class="line"><span class="type">Setting</span> <span class="keyword">default</span> log level to <span class="string">&quot;WARN&quot;</span>.</span><br><span class="line"><span class="type">To</span> adjust logging level use sc.setLogLevel(newLevel). <span class="type">For</span> <span class="type">SparkR</span>, use setLogLevel(newLevel).</span><br><span class="line"><span class="number">23</span>/<span class="number">12</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">35</span>:<span class="number">32</span> <span class="type">WARN</span> <span class="type">Utils</span>: <span class="type">Service</span> &#x27;<span class="type">SparkUI</span>&#x27; could not bind on port <span class="number">4040.</span> <span class="type">Attempting</span> port <span class="number">4041.</span></span><br><span class="line"><span class="type">Spark</span> context <span class="type">Web</span> <span class="type">UI</span> available at http:<span class="comment">//hadoop301:4041</span></span><br><span class="line"><span class="type">Spark</span> context available as &#x27;sc&#x27; (master = local[*], app id = local<span class="number">-1702344932584</span>).</span><br><span class="line"><span class="type">Spark</span> session available as &#x27;spark&#x27;.</span><br><span class="line"><span class="type">Welcome</span> to</span><br><span class="line">      ____              __</span><br><span class="line">     / __/__  ___ _____/ /__</span><br><span class="line">    _\ \/ _ \/ _ `/ __/  &#x27;_/</span><br><span class="line">   /___/ .__/\_,_/_/ /_/\_\   version <span class="number">3.1</span><span class="number">.1</span></span><br><span class="line">      /_/</span><br><span class="line"></span><br><span class="line"><span class="type">Using</span> <span class="type">Scala</span> version <span class="number">2.12</span><span class="number">.10</span> (<span class="type">Java</span> <span class="type">HotSpot</span>(<span class="type">TM</span>) <span class="number">64</span>-<span class="type">Bit</span> <span class="type">Server</span> <span class="type">VM</span>, <span class="type">Java</span> <span class="number">1.8</span><span class="number">.0</span>_162)</span><br><span class="line"><span class="type">Type</span> in expressions to have them evaluated.</span><br><span class="line"><span class="type">Type</span> :help <span class="keyword">for</span> more information.</span><br></pre></td></tr></table></figure>

<p>5). 简单测试一下</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; sc.textFile(<span class="string">&quot;data/word.txt&quot;</span>).flatMap(_.split(<span class="string">&quot; &quot;</span>)).map((_,<span class="number">1</span>)).reduceByKey(_+_).col</span><br><span class="line">res0: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">Array</span>((<span class="type">Spark</span>,<span class="number">1</span>), (<span class="type">Hello</span>,<span class="number">3</span>), (<span class="type">Scala</span>,<span class="number">2</span>))</span><br></pre></td></tr></table></figure>

<p>6). 运行提交应用程序</p>
<p>内容如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit \</span><br><span class="line">--<span class="class"><span class="keyword">class</span> <span class="title">org</span>.<span class="title">apache</span>.<span class="title">spark</span>.<span class="title">examples</span>.<span class="title">SparkPi</span> <span class="title">\</span></span></span><br><span class="line">--master local[<span class="number">2</span>] \</span><br><span class="line">./examples/jars/spark-examples_2<span class="number">.12</span><span class="number">-3.1</span><span class="number">.1</span>.jar \</span><br><span class="line"><span class="number">10</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 spark]# bin/spark-submit \</span><br><span class="line">&gt; --class org.apache.spark.examples.SparkPi \</span><br><span class="line">&gt; --master <span class="built_in">local</span>[2] \</span><br><span class="line">&gt; ./examples/jars/spark-examples_2.12-3.1.1.jar \</span><br><span class="line">&gt; 10</span><br><span class="line">23/12/12 09:50:26 WARN NativeCodeLoader: Unable to load native-hadoop library                                                                   <span class="keyword">for</span> your platform... using builtin-java classes <span class="built_in">where</span> applicable</span><br><span class="line">Using Spark<span class="string">&#x27;s default log4j profile: org/apache/spark/log4j-defaults.properti                                                                  es</span></span><br><span class="line"><span class="string">23/12/12 09:50:26 INFO SparkContext: Running Spark version 3.1.1</span></span><br><span class="line"><span class="string">23/12/12 09:50:26 INFO ResourceUtils: =======================================                                                                  =======================</span></span><br><span class="line"><span class="string">23/12/12 09:50:26 INFO ResourceUtils: No custom resources configured for spar                                                                  k.driver.</span></span><br><span class="line"><span class="string">23/12/12 09:50:26 INFO ResourceUtils: =======================================                                                                  =======================</span></span><br><span class="line"><span class="string">23/12/12 09:50:26 INFO SparkContext: Submitted application: Spark Pi</span></span><br><span class="line"><span class="string">23/12/12 09:50:26 INFO ResourceProfile: Default ResourceProfile created, exec                                                                  utor resources: Map(cores -&gt; name: cores, amount: 1, script: , vendor: , memo                                                                  ry -&gt; name: memory, amount: 1024, script: , vendor: , offHeap -&gt; name: offHea                                                                  p, amount: 0, script: , vendor: ), task resources: Map(cpus -&gt; name: cpus, am                                                                  ount: 1.0)</span></span><br><span class="line"><span class="string">23/12/12 09:50:26 INFO ResourceProfile: Limiting resource is cpu</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">.......</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">23/12/12 09:50:33 INFO DAGScheduler: Job 0 finished: reduce at SparkPi.scala:                                                                  38, took 1.886176 s</span></span><br><span class="line"><span class="string">Pi is roughly 3.141411141411141</span></span><br><span class="line"><span class="string">23/12/12 09:50:33 INFO SparkUI: Stopped Spark web UI at http://hadoop301:4041</span></span><br><span class="line"><span class="string">23/12/12 09:50:33 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMaster                                                                  Endpoint stopped!</span></span><br><span class="line"><span class="string">23/12/12 09:50:33 INFO MemoryStore: MemoryStore cleared</span></span><br><span class="line"><span class="string">23/12/12 09:50:33 INFO BlockManager: BlockManager stopped</span></span><br><span class="line"><span class="string">23/12/12 09:50:33 INFO BlockManagerMaster: BlockManagerMaster stopped</span></span><br><span class="line"><span class="string">23/12/12 09:50:33 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoin                                                                  t: OutputCommitCoordinator stopped!</span></span><br><span class="line"><span class="string">23/12/12 09:50:33 INFO SparkContext: Successfully stopped SparkContext</span></span><br><span class="line"><span class="string">23/12/12 09:50:33 INFO ShutdownHookManager: Shutdown hook called</span></span><br><span class="line"><span class="string">23/12/12 09:50:33 INFO ShutdownHookManager: Deleting directory /tmp/spark-eaf                                                                  94632-dc33-48e3-9ce3-e86e591dcc24</span></span><br><span class="line"><span class="string">23/12/12 09:50:33 INFO ShutdownHookManager: Deleting directory /tmp/spark-630                                                                  537e8-aaf6-4e4b-8a77-4c73e457244c</span></span><br></pre></td></tr></table></figure>



<h4 id="三、独立部署模式-spark-standalone"><a href="#三、独立部署模式-spark-standalone" class="headerlink" title="三、独立部署模式(spark-standalone)"></a>三、独立部署模式(spark-standalone)</h4><p>1). 解压文件</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 software]# tar -zxvf spark-3.1.1-bin-hadoop3.2.tgz -C /opt/module</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 module]# <span class="built_in">mv</span> spark-3.1.1-bin-hadoop3.2/ spark-standalone</span><br><span class="line">[root@hadoop301 module]# ll</span><br><span class="line">总用量 0</span><br><span class="line">drwxr-xr-x. 11 yun   yun   173 12月  7 10:31 hadoop</span><br><span class="line">drwxr-xr-x. 11 root  root  221 12月 11 15:04 hive</span><br><span class="line">drwxr-xr-x.  8 yun   yun   255 12月 20 2017 jdk</span><br><span class="line">drwxr-xr-x. 10 mysql mysql 141 12月  6 15:49 mysql</span><br><span class="line">drwxr-xr-x. 13 yun   yun   211 12月 12 09:12 spark</span><br><span class="line">drwxr-xr-x. 13 yun   yun   211 2月  22 2021 spark-standalone</span><br></pre></td></tr></table></figure>



<p>2). 将 &#x2F;spark-standalone&#x2F;conf&#x2F; 的这个文件workers.template 重命名为slaves</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 module]# <span class="built_in">cd</span> spark-standalone/conf/</span><br><span class="line">[root@hadoop301 conf]# ll</span><br><span class="line">总用量 36</span><br><span class="line">-rw-r--r--. 1 yun yun 1105 2月  22 2021 fairscheduler.xml.template</span><br><span class="line">-rw-r--r--. 1 yun yun 2023 2月  22 2021 log4j.properties.template</span><br><span class="line">-rw-r--r--. 1 yun yun 9141 2月  22 2021 metrics.properties.template</span><br><span class="line">-rw-r--r--. 1 yun yun  865 2月  22 2021 slaves</span><br><span class="line">-rw-r--r--. 1 yun yun 1292 2月  22 2021 spark-defaults.conf.template</span><br><span class="line">-rwxr-xr-x. 1 yun yun 4428 2月  22 2021 spark-env.sh.template</span><br></pre></td></tr></table></figure>

<p>3). 修改slaves文件，添加work节点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop301</span><br><span class="line">hadoop302</span><br><span class="line">hadoop303</span><br></pre></td></tr></table></figure>

<p>4). 修改spark-env.sh.template文件名为spark-env.sh</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 conf]# <span class="built_in">mv</span> spark-env.sh.template spark-env.sh</span><br><span class="line">[root@hadoop301 conf]# ll</span><br><span class="line">总用量 36</span><br><span class="line">-rw-r--r--. 1 yun yun 1105 2月  22 2021 fairscheduler.xml.template</span><br><span class="line">-rw-r--r--. 1 yun yun 2023 2月  22 2021 log4j.properties.template</span><br><span class="line">-rw-r--r--. 1 yun yun 9141 2月  22 2021 metrics.properties.template</span><br><span class="line">-rw-r--r--. 1 yun yun  886 12月 12 10:02 slaves</span><br><span class="line">-rw-r--r--. 1 yun yun 1292 2月  22 2021 spark-defaults.conf.template</span><br><span class="line">-rwxr-xr-x. 1 yun yun 4428 2月  22 2021 spark-env.sh</span><br></pre></td></tr></table></figure>

<p>添加如下内容：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 conf]# vim spark-env.sh</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/module/jdk</span><br><span class="line">SPARK_MASTER_HOST=hadoop301</span><br><span class="line">SPARK_MASTER_PORT=7077</span><br></pre></td></tr></table></figure>



<p>4). 分发给hadoop302、hadoop303</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 module]# xsync spark-standalone/</span><br><span class="line">==================== hadoop301 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line"></span><br><span class="line">sent 39,530 bytes  received 167 bytes  79,394.00 bytes/sec</span><br><span class="line">total size is 254,312,335  speedup is 6,406.34</span><br><span class="line">==================== hadoop302 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line">spark-standalone/</span><br><span class="line">spark-standalone/LICENSE</span><br><span class="line">spark-standalone/NOTICE</span><br><span class="line">spark-standalone/README.md</span><br><span class="line">spark-standalone/RELEASE</span><br><span class="line"></span><br><span class="line">.......</span><br></pre></td></tr></table></figure>



<p>5). 启动集群</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 spark-standalone]# sbin/start-all.sh</span><br><span class="line">starting org.apache.spark.deploy.master.Master, logging to /opt/module/spark-standalone/logs/spark-root-org.apache.spark.deploy.master.Master-1-hadoop301.out</span><br><span class="line">hadoop303: starting org.apache.spark.deploy.worker.Worker, logging to /opt/module/spark-standalone/logs/spark-root-org.apache.spark.deploy.worker.Worker-1-hadoop303.out</span><br><span class="line">hadoop302: starting org.apache.spark.deploy.worker.Worker, logging to /opt/module/spark-standalone/logs/spark-root-org.apache.spark.deploy.worker.Worker-1-hadoop302.out</span><br><span class="line">hadoop301: starting org.apache.spark.deploy.worker.Worker, logging to /opt/module/spark-standalone/logs/spark-root-org.apache.spark.deploy.worker.Worker-1-hadoop301.out</span><br></pre></td></tr></table></figure>



<p>6). 查看三台服务器运行进程</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 spark-standalone]# jps</span><br><span class="line">2754 DataNode</span><br><span class="line">6035 Worker</span><br><span class="line">2596 NameNode</span><br><span class="line">5972 Master</span><br><span class="line">3097 NodeManager</span><br><span class="line">6155 Jps</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop302 conf]# jps</span><br><span class="line">3232 Worker</span><br><span class="line">3335 Jps</span><br><span class="line">2520 NodeManager</span><br><span class="line">2362 ResourceManager</span><br><span class="line">2159 DataNode</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop303 conf]# jps</span><br><span class="line">2272 SecondaryNameNode</span><br><span class="line">2864 Worker</span><br><span class="line">2967 Jps</span><br><span class="line">2153 DataNode</span><br><span class="line">2364 NodeManager</span><br></pre></td></tr></table></figure>



<p>7). 查看Master资源监控Web UI 界面 http&#x2F;&#x2F;hadoop301:8080</p>
<p><img data-src="E:/typora%E5%9B%BE%E7%89%87/image-20231212110957048.png" alt="image-20231212110957048"></p>
<p>8). 提交应用</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit \</span><br><span class="line">--class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master spark://hadoop301:7077 \</span><br><span class="line">./examples/jars/spark-examples_2.12-3.1.1.jar \</span><br><span class="line">10</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 spark-standalone]# bin/spark-submit \</span><br><span class="line">&gt; --class org.apache.spark.examples.SparkPi \</span><br><span class="line">&gt; --master spark://hadoop301:7077 \</span><br><span class="line">&gt; ./examples/jars/spark-examples_2.12-3.1.1.jar \</span><br><span class="line">&gt; 10</span><br><span class="line">23/12/12 11:11:42 WARN NativeCodeLoader: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using builtin-java classes <span class="built_in">where</span> applicable</span><br><span class="line">Using Spark<span class="string">&#x27;s default log4j profile: org/apache/spark/log4j-defaults.properties</span></span><br><span class="line"><span class="string">23/12/12 11:11:42 INFO SparkContext: Running Spark version 3.1.1</span></span><br><span class="line"><span class="string">23/12/12 11:11:42 INFO ResourceUtils: ==============================================================</span></span><br><span class="line"><span class="string">23/12/12 11:11:42 INFO ResourceUtils: No custom resources configured for spark.driver.</span></span><br><span class="line"><span class="string">23/12/12 11:11:42 INFO ResourceUtils: ==============================================================</span></span><br><span class="line"><span class="string">23/12/12 11:11:42 INFO SparkContext: Submitted application: Spark Pi</span></span><br><span class="line"><span class="string">23/12/12 11:11:43 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -&gt; name: cores, amount: 1, script: , vendor: , memory -&gt; name: memory, amount: 1024, script: , vendor: , offHeap -&gt; name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -&gt; name: cpus, amount: 1.0)</span></span><br><span class="line"><span class="string">23/12/12 11:11:43 INFO ResourceProfile: Limiting resource is cpu</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">.....</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">23/12/12 11:11:52 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job</span></span><br><span class="line"><span class="string">23/12/12 11:11:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished</span></span><br><span class="line"><span class="string">23/12/12 11:11:52 INFO DAGScheduler: Job 0 finished: reduce at SparkPi.scala:38, took 4.014818 s</span></span><br><span class="line"><span class="string">Pi is roughly 3.1443471443471442</span></span><br><span class="line"><span class="string">23/12/12 11:11:52 INFO SparkUI: Stopped Spark web UI at http://hadoop301:4040</span></span><br><span class="line"><span class="string">23/12/12 11:11:52 INFO StandaloneSchedulerBackend: Shutting down all executors</span></span><br><span class="line"><span class="string">23/12/12 11:11:52 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down</span></span><br><span class="line"><span class="string">23/12/12 11:11:52 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!</span></span><br><span class="line"><span class="string">23/12/12 11:11:52 INFO MemoryStore: MemoryStore cleared</span></span><br><span class="line"><span class="string">23/12/12 11:11:52 INFO BlockManager: BlockManager stopped</span></span><br><span class="line"><span class="string">23/12/12 11:11:52 INFO BlockManagerMaster: BlockManagerMaster stopped</span></span><br><span class="line"><span class="string">23/12/12 11:11:52 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!</span></span><br><span class="line"><span class="string">23/12/12 11:11:52 INFO SparkContext: Successfully stopped SparkContext</span></span><br><span class="line"><span class="string">23/12/12 11:11:52 INFO ShutdownHookManager: Shutdown hook called</span></span><br><span class="line"><span class="string">23/12/12 11:11:52 INFO ShutdownHookManager: Deleting directory /tmp/spark-03a8ac52-5651-4ac8-b21c-8e7dce714d76</span></span><br><span class="line"><span class="string">23/12/12 11:11:52 INFO ShutdownHookManager: Deleting directory /tmp/spark-cdcd1f1b-8c00-4911-ba0c-79a07391394d</span></span><br></pre></td></tr></table></figure>





<p>修改spark-defaults.conf.template文件名为spark-defaults.conf</p>
<p>修改spark-defaults.conf文件，配置日志存储路径</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark.eventLog.enabled            <span class="literal">true</span></span><br><span class="line">spark.eventLog.<span class="built_in">dir</span>                hdfs://hadoop301:8020/directory</span><br></pre></td></tr></table></figure>

<p>注意：需要启动hadoop集群，<strong>HDFS上的directory目录需要提前存在</strong></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 conf]# hdfs dfs -<span class="built_in">mkdir</span> /directory</span><br></pre></td></tr></table></figure>



<p>修改spark-env.sh文件，添加日志配置</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> SPARK_HISTORY_OPTS=<span class="string">&quot;  </span></span><br><span class="line"><span class="string">-Dspark.history.ui.port=18080</span></span><br><span class="line"><span class="string">-Dspark.history.fs.logDirectory=hdfs://hadoop301:8020/directory</span></span><br><span class="line"><span class="string">-Dspark.history.retainedApplications=30&quot;</span></span><br></pre></td></tr></table></figure>



<p>分发配置文件</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 spark-standalone]# xsync conf</span><br><span class="line">==================== hadoop301 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line"></span><br><span class="line">sent 252 bytes  received 17 bytes  179.33 bytes/sec</span><br><span class="line">total size is 19,229  speedup is 71.48</span><br><span class="line">==================== hadoop302 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line">conf/</span><br><span class="line">conf/spark-defaults.conf</span><br><span class="line">conf/spark-env.sh</span><br><span class="line"></span><br><span class="line">sent 2,239 bytes  received 100 bytes  1,559.33 bytes/sec</span><br><span class="line">total size is 19,229  speedup is 8.22</span><br><span class="line">==================== hadoop303 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line">conf/</span><br><span class="line">conf/spark-defaults.conf</span><br><span class="line">conf/spark-env.sh</span><br><span class="line"></span><br><span class="line">sent 2,239 bytes  received 100 bytes  4,678.00 bytes/sec</span><br><span class="line">total size is 19,229  speedup is 8.22</span><br></pre></td></tr></table></figure>



<p>重写启动集群和历史服务</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-all.sh</span><br><span class="line">sbin/start-history-server.sh</span><br></pre></td></tr></table></figure>



<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 spark-standalone]# sbin/start-all.sh</span><br><span class="line">starting org.apache.spark.deploy.master.Master, logging to /opt/module/spark-standalone/logs/spark-root-org.apache.spark.deploy.master.Master-1-hadoop301.out</span><br><span class="line">hadoop303: starting org.apache.spark.deploy.worker.Worker, logging to /opt/module/spark-standalone/logs/spark-root-org.apache.spark.deploy.worker.Worker-1-hadoop303.out</span><br><span class="line">hadoop302: starting org.apache.spark.deploy.worker.Worker, logging to /opt/module/spark-standalone/logs/spark-root-org.apache.spark.deploy.worker.Worker-1-hadoop302.out</span><br><span class="line">hadoop301: starting org.apache.spark.deploy.worker.Worker, logging to /opt/module/spark-standalone/logs/spark-root-org.apache.spark.deploy.worker.Worker-1-hadoop301.out</span><br><span class="line">[root@hadoop301 spark-standalone]# sbin/start-history-server.sh</span><br><span class="line">starting org.apache.spark.deploy.history.HistoryServer, logging to /opt/module/spark-standalone/logs/spark-root-org.apache.spark.deploy.history.HistoryServer-1-hadoop301.out</span><br></pre></td></tr></table></figure>



<p>重新执行任务</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit \</span><br><span class="line">--class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master spark://hadoop301:7077 \</span><br><span class="line">./examples/jars/spark-examples_2.12-3.1.1.jar \</span><br><span class="line">10</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 spark-standalone]# bin/spark-submit \</span><br><span class="line">&gt; --class org.apache.spark.examples.SparkPi \</span><br><span class="line">&gt; --master spark://hadoop301:7077 \</span><br><span class="line">&gt; ./examples/jars/spark-examples_2.12-3.1.1.jar \</span><br><span class="line">&gt; 10</span><br><span class="line">23/12/12 16:39:05 WARN NativeCodeLoader: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using builtin-java classes <span class="built_in">where</span> applicable</span><br><span class="line">Using Spark<span class="string">&#x27;s default log4j profile: org/apache/spark/log4j-defaults.properties</span></span><br><span class="line"><span class="string">23/12/12 16:39:05 INFO SparkContext: Running Spark version 3.1.1</span></span><br><span class="line"><span class="string">23/12/12 16:39:05 INFO ResourceUtils: ==============================================================</span></span><br><span class="line"><span class="string">23/12/12 16:39:05 INFO ResourceUtils: No custom resources configured for spark.driver.</span></span><br><span class="line"><span class="string">23/12/12 16:39:05 INFO ResourceUtils: ==============================================================</span></span><br><span class="line"><span class="string">23/12/12 16:39:05 INFO SparkContext: Submitted application: Spark Pi</span></span><br><span class="line"><span class="string">23/12/12 16:39:05 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -&gt; name: cores, amount: 1, script: , vendor: , memory -&gt; name: memory, amount: 1024, script: , vendor: , offHeap -&gt; name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -&gt; name: cpus, amount: 1.0)</span></span><br><span class="line"><span class="string">23/12/12 16:39:05 INFO ResourceProfile: Limiting resource is cpu</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">......</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">23/12/12 16:39:23 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job</span></span><br><span class="line"><span class="string">23/12/12 16:39:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished</span></span><br><span class="line"><span class="string">23/12/12 16:39:23 INFO DAGScheduler: Job 0 finished: reduce at SparkPi.scala:38, took 4.522823 s</span></span><br><span class="line"><span class="string">Pi is roughly 3.141043141043141</span></span><br><span class="line"><span class="string">23/12/12 16:39:23 INFO SparkUI: Stopped Spark web UI at http://hadoop301:4040</span></span><br><span class="line"><span class="string">23/12/12 16:39:23 INFO StandaloneSchedulerBackend: Shutting down all executors</span></span><br><span class="line"><span class="string">23/12/12 16:39:23 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down</span></span><br><span class="line"><span class="string">23/12/12 16:39:24 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!</span></span><br><span class="line"><span class="string">23/12/12 16:39:24 INFO MemoryStore: MemoryStore cleared</span></span><br><span class="line"><span class="string">23/12/12 16:39:24 INFO BlockManager: BlockManager stopped</span></span><br><span class="line"><span class="string">23/12/12 16:39:24 INFO BlockManagerMaster: BlockManagerMaster stopped</span></span><br><span class="line"><span class="string">23/12/12 16:39:24 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!</span></span><br><span class="line"><span class="string">23/12/12 16:39:24 INFO SparkContext: Successfully stopped SparkContext</span></span><br><span class="line"><span class="string">23/12/12 16:39:24 INFO ShutdownHookManager: Shutdown hook called</span></span><br><span class="line"><span class="string">23/12/12 16:39:24 INFO ShutdownHookManager: Deleting directory /tmp/spark-3aaec14f-7e43-4214-9e85-58d641e79b38</span></span><br><span class="line"><span class="string">23/12/12 16:39:24 INFO ShutdownHookManager: Deleting directory /tmp/spark-5b914f69-6e76-420b-92b7-c4e07295232b</span></span><br></pre></td></tr></table></figure>

<p>查看历史服务：cd </p>
<p><img data-src="E:/typora%E5%9B%BE%E7%89%87/image-20231212170908553.png" alt="image-20231212170908553"></p>
<p>9). 配置高可用</p>
<p>Zookeeper设置</p>
<ol>
<li>停止集群</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/stop-all.sh</span><br></pre></td></tr></table></figure>



<ol start="2">
<li>启动Zookeeper</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zkServer.sh start</span><br></pre></td></tr></table></figure>

<p>3个节点都要启动或使用</p>
<p>Zookeeper集群启动脚本</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zk.sh start</span><br></pre></td></tr></table></figure>

<p>Zookeeper集群停止脚本</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zk.sh stop</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 zookeeper]# zk.sh start</span><br><span class="line">---------- zookeeper hadoop301 启动 ------------</span><br><span class="line">Error: JAVA_HOME is not <span class="built_in">set</span> and java could not be found <span class="keyword">in</span> PATH.</span><br><span class="line">---------- zookeeper hadoop302 启动 ------------</span><br><span class="line">Error: JAVA_HOME is not <span class="built_in">set</span> and java could not be found <span class="keyword">in</span> PATH.</span><br><span class="line">---------- zookeeper hadoop303 启动 ------------</span><br><span class="line">Error: JAVA_HOME is not <span class="built_in">set</span> and java could not be found <span class="keyword">in</span> PATH.</span><br></pre></td></tr></table></figure>



<ol start="3">
<li>修改spark-env.sh，如何如下</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">注释这两行</span><br><span class="line"><span class="comment"># SPARK_MASTER_HOST=hadoop301</span></span><br><span class="line"><span class="comment"># SPARK_MASTER_PORT=7077</span></span><br><span class="line"></span><br><span class="line">添加</span><br><span class="line">SPARK_MASTER_WEBUI_PORT=8989</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> SPART_DAEMON_JAVA_OPTS=<span class="string">&quot;</span></span><br><span class="line"><span class="string">-Dspark.deploy.recoveryMode=ZOOKEEPER</span></span><br><span class="line"><span class="string">-Dspark.deploy.zookeeper.url=hadoop301,hadoop302,hadoop303</span></span><br><span class="line"><span class="string">-Dspark.deploy.zookeeper.dir=/spark&quot;</span></span><br></pre></td></tr></table></figure>

<p>分发….</p>
<ol start="4">
<li>启动集群</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-all.sh</span><br></pre></td></tr></table></figure>

<p>查看： <a target="_blank" rel="noopener" href="http://hadoop301:8989/">http://hadoop301:8989</a></p>
<p><img data-src="E:/typora%E5%9B%BE%E7%89%87/image-20231213154113647.png" alt="image-20231213154113647"></p>
<ol start="5">
<li>启动hadoop302的单独Master节点，此时Master状态处于备用状态</li>
</ol>
<p>查看： <a target="_blank" rel="noopener" href="http://hadoop302:8989/">http://hadoop302:8989</a></p>
<p><img data-src="E:/typora%E5%9B%BE%E7%89%87/image-20231213154533997.png" alt="image-20231213154533997"></p>
<ol start="6">
<li>提交应用到高可用集群</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit \</span><br><span class="line">--class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master spark://hadoop301:7077,hadoop302:7077 \</span><br><span class="line">./examples/jars/spark-examples_2.12-3.1.1.jar \</span><br><span class="line">10</span><br></pre></td></tr></table></figure>



<ol start="7">
<li>停止hadoop的Master资源监控进程</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 spark-standalone]# jps</span><br><span class="line">3408 QuorumPeerMain</span><br><span class="line">3888 NameNode</span><br><span class="line">7825 Jps</span><br><span class="line">4393 NodeManager</span><br><span class="line">7225 Worker</span><br><span class="line">6188 HistoryServer</span><br><span class="line">4045 DataNode</span><br><span class="line">7151 Master</span><br><span class="line">[root@hadoop301 spark-standalone]# <span class="built_in">kill</span> -9 7151</span><br><span class="line">[root@hadoop301 spark-standalone]# jps</span><br><span class="line">3408 QuorumPeerMain</span><br><span class="line">3888 NameNode</span><br><span class="line">4393 NodeManager</span><br><span class="line">7225 Worker</span><br><span class="line">6188 HistoryServer</span><br><span class="line">4045 DataNode</span><br><span class="line">7854 Jps</span><br></pre></td></tr></table></figure>

<p><img data-src="E:/typora%E5%9B%BE%E7%89%87/image-20231213155518859.png" alt="image-20231213155518859"></p>
<h4 id="四、Yarn模式"><a href="#四、Yarn模式" class="headerlink" title="四、Yarn模式"></a>四、Yarn模式</h4><p>1). 解压文件，并重命名放置再指定位置</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 software]# tar -zxvf spark-3.1.1-bin-hadoop3.2.tgz -C /opt/module/</span><br><span class="line">.....</span><br><span class="line"></span><br><span class="line">[root@hadoop301 module]# <span class="built_in">mv</span> spark-3.1.1-bin-hadoop3.2/ spark-yarn</span><br><span class="line">[root@hadoop301 module]# ll</span><br><span class="line">总用量 0</span><br><span class="line">drwxr-xr-x. 11 yun   yun   173 12月  7 10:31 hadoop</span><br><span class="line">drwxr-xr-x. 11 yun   yun   221 12月 11 15:04 hive</span><br><span class="line">drwxr-xr-x.  8 yun   yun   255 12月 20 2017 jdk</span><br><span class="line">drwxr-xr-x. 10 mysql mysql 141 12月  6 15:49 mysql</span><br><span class="line">drwxr-xr-x. 13 yun   yun   211 12月 12 09:12 spark</span><br><span class="line">drwxr-xr-x. 15 yun   yun   235 12月 12 15:25 spark-standalone</span><br><span class="line">drwxr-xr-x. 13 yun   yun   211 2月  22 2021 spark-yarn</span><br><span class="line">drwxr-xr-x.  8 root  root  160 12月 13 15:03 zookeeper</span><br></pre></td></tr></table></figure>



<p>2).修改配置文件</p>
<p>修改hadoop配置文件&#x2F;opt&#x2F;module&#x2F;hadoop&#x2F;etc&#x2F;hadoop&#x2F;yarn-site.xml，并分发</p>
<p><img data-src="E:/typora%E5%9B%BE%E7%89%87/image-20231213160855000.png" alt="image-20231213160855000"></p>
<p>3).修改conf&#x2F;spark-env.sh ，添加JAVA_HOME和YARN_CONF_DIR配置</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 conf]# ll</span><br><span class="line">总用量 36</span><br><span class="line">-rw-r--r--. 1 yun yun 1105 2月  22 2021 fairscheduler.xml.template</span><br><span class="line">-rw-r--r--. 1 yun yun 2023 2月  22 2021 log4j.properties.template</span><br><span class="line">-rw-r--r--. 1 yun yun 9141 2月  22 2021 metrics.properties.template</span><br><span class="line">-rw-r--r--. 1 yun yun 1292 2月  22 2021 spark-defaults.conf.template</span><br><span class="line">-rwxr-xr-x. 1 yun yun 4428 2月  22 2021 spark-env.sh.template</span><br><span class="line">-rw-r--r--. 1 yun yun  865 2月  22 2021 workers.template</span><br><span class="line">[root@hadoop301 conf]# <span class="built_in">mv</span> spark-env.sh.template spark-env.sh</span><br><span class="line">[root@hadoop301 conf]# vim spark-env.sh</span><br></pre></td></tr></table></figure>

<p>添加内容如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/module/jdk</span><br><span class="line">YARN_CONF_DIR=/opt/module/hadoop/etc/hadoop</span><br></pre></td></tr></table></figure>



<p>4).启动HDFS以及YARN集群</p>
<p>5).提交应用</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit \</span><br><span class="line">--class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master yarn \</span><br><span class="line">--deploy-mode cluster \</span><br><span class="line">./examples/jars/spark-examples_2.12-3.1.1.jar \</span><br><span class="line">10</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 spark-yarn]# bin/spark-submit \</span><br><span class="line">&gt; --class org.apache.spark.examples.SparkPi \</span><br><span class="line">&gt; --master yarn \</span><br><span class="line">&gt; --deploy-mode cluster \</span><br><span class="line">&gt; ./examples/jars/spark-examples_2.12-3.1.1.jar \</span><br><span class="line">&gt; 10</span><br><span class="line">2023-12-13 16:19:45,899 WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using builtin-java classes <span class="built_in">where</span> applicable</span><br><span class="line">2023-12-13 16:19:46,041 INFO client.RMProxy: Connecting to ResourceManager at hadoop302/192.168.137.137:8032</span><br><span class="line"></span><br><span class="line">......</span><br><span class="line"></span><br><span class="line">2023-12-13 16:20:38,182 INFO yarn.Client: Application report <span class="keyword">for</span> application_1702451653078_0001 (state: RUNNING)</span><br><span class="line">2023-12-13 16:20:39,185 INFO yarn.Client: Application report <span class="keyword">for</span> application_1702451653078_0001 (state: FINISHED)</span><br><span class="line">2023-12-13 16:20:39,186 INFO yarn.Client:</span><br><span class="line">         client token: N/A</span><br><span class="line">         diagnostics: N/A</span><br><span class="line">         ApplicationMaster host: hadoop302</span><br><span class="line">         ApplicationMaster RPC port: 42631</span><br><span class="line">         queue: default</span><br><span class="line">         start <span class="keyword">time</span>: 1702455600467</span><br><span class="line">         final status: SUCCEEDED</span><br><span class="line">         tracking URL: http://hadoop302:8088/proxy/application_1702451653078_0001/</span><br><span class="line">         user: root</span><br><span class="line">2023-12-13 16:20:39,216 INFO util.ShutdownHookManager: Shutdown hook called</span><br><span class="line">2023-12-13 16:20:39,216 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-566fedcb-c4d9-44e9-b06b-c304d10eec03</span><br><span class="line">2023-12-13 16:20:39,229 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-12d7b76e-9d46-4f6f-ac04-edbde3f7869a</span><br></pre></td></tr></table></figure>

<p>查看 <a target="_blank" rel="noopener" href="http://hadoop302:8088/">http://hadoop302:8088</a> 页面，点击History，查看历史页面</p>
<p><img data-src="E:/typora%E5%9B%BE%E7%89%87/image-20231213162533931.png" alt="image-20231213162533931"></p>
<p>6).配置历史服务器</p>
<ol>
<li>修改spark-defaults.conf.template文件名为spark-defaults.conf</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 conf]# <span class="built_in">mv</span> spark-defaults.conf.template spark-defaults.conf</span><br><span class="line">[root@hadoop301 conf]# ll</span><br><span class="line">总用量 36</span><br><span class="line">-rw-r--r--. 1 yun yun 1105 2月  22 2021 fairscheduler.xml.template</span><br><span class="line">-rw-r--r--. 1 yun yun 2023 2月  22 2021 log4j.properties.template</span><br><span class="line">-rw-r--r--. 1 yun yun 9141 2月  22 2021 metrics.properties.template</span><br><span class="line">-rw-r--r--. 1 yun yun 1292 2月  22 2021 spark-defaults.conf</span><br><span class="line">-rwxr-xr-x. 1 yun yun 4505 12月 13 16:15 spark-env.sh</span><br><span class="line">-rw-r--r--. 1 yun yun  865 2月  22 2021 workers.template</span><br></pre></td></tr></table></figure>



<ol start="2">
<li>修改spark-defaults.conf文件，配置日志路径</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark.eventLog.enabled             <span class="literal">true</span></span><br><span class="line">spark.eventLog.<span class="built_in">dir</span>                 hdfs://hadoop301:8020/directory</span><br></pre></td></tr></table></figure>

<p>注意：需要启动hadoop集群，<strong>HDFS上的目录需要提前存在</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 spark-yarn]# hdfs dfs -mkdir /directory</span><br></pre></td></tr></table></figure>



<ol start="3">
<li>修改spark.env.sh文件，添加日志配置</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> SPARK_HISTORY_OPTS=<span class="string">&quot;</span></span><br><span class="line"><span class="string">-Dspark.history.ui.port=18080</span></span><br><span class="line"><span class="string">-Dspark.history.fs.logDirectory=hdfs://hadoop301:8020/directory</span></span><br><span class="line"><span class="string">-Dspark.history.retainedApplications=30&quot;</span></span><br></pre></td></tr></table></figure>



<ol start="4">
<li>分发配置文件</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 spark-yarn]# xsync conf</span><br><span class="line">==================== hadoop301 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line"></span><br><span class="line">sent 257 bytes  received 17 bytes  548.00 bytes/sec</span><br><span class="line">total size is 19,281  speedup is 70.37</span><br><span class="line">==================== hadoop302 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line">conf/</span><br><span class="line">conf/fairscheduler.xml.template</span><br><span class="line">conf/log4j.properties.template</span><br><span class="line">conf/metrics.properties.template</span><br><span class="line">conf/spark-defaults.conf</span><br><span class="line">conf/spark-env.sh</span><br><span class="line">conf/workers.template</span><br><span class="line"></span><br><span class="line">sent 19,799 bytes  received 134 bytes  39,866.00 bytes/sec</span><br><span class="line">total size is 19,281  speedup is 0.97</span><br><span class="line">==================== hadoop303 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line">conf/</span><br><span class="line">conf/fairscheduler.xml.template</span><br><span class="line">conf/log4j.properties.template</span><br><span class="line">conf/metrics.properties.template</span><br><span class="line">conf/spark-defaults.conf</span><br><span class="line">conf/spark-env.sh</span><br><span class="line">conf/workers.template</span><br><span class="line"></span><br><span class="line">sent 19,799 bytes  received 134 bytes  13,288.67 bytes/sec</span><br><span class="line">total size is 19,281  speedup is 0.97</span><br></pre></td></tr></table></figure>



<ol start="5">
<li>修改spark-defaults.conf</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark.yarn.historyServer.address=hadoop301:18080</span><br><span class="line">spark.history.ui.port=18080</span><br></pre></td></tr></table></figure>



<ol start="6">
<li>启动历史服务</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-history-server.sh</span><br></pre></td></tr></table></figure>



<ol start="7">
<li>重新提交应用</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit \</span><br><span class="line">--class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master yarn \</span><br><span class="line">--deploy-mode client \</span><br><span class="line">./examples/jars/spark-examples_2.12-3.1.1.jar \</span><br><span class="line">10</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop301 spark-yarn]# bin/spark-submit \</span><br><span class="line">&gt; --class org.apache.spark.examples.SparkPi \</span><br><span class="line">&gt; --master yarn \</span><br><span class="line">&gt; --deploy-mode client \</span><br><span class="line">&gt; ./examples/jars/spark-examples_2.12-3.1.1.jar \</span><br><span class="line">&gt; 10</span><br><span class="line">2023-12-13 16:49:44,349 WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class="keyword">for</span> y                                                                      our platform... using builtin-java classes <span class="built_in">where</span> applicable</span><br><span class="line">2023-12-13 16:49:44,790 INFO spark.SparkContext: Running Spark version 3.1.1</span><br><span class="line">2023-12-13 16:49:44,872 INFO resource.ResourceUtils: =========================================                                                                      =====================</span><br><span class="line">2023-12-13 16:49:44,873 INFO resource.ResourceUtils: No custom resources configured <span class="keyword">for</span> spark.                                                                      driver.</span><br><span class="line">2023-12-13 16:49:44,873 INFO resource.ResourceUtils: =========================================                                                                      =====================</span><br><span class="line">2023-12-13 16:49:44,874 INFO spark.SparkContext: Submitted application: Spark Pi</span><br><span class="line">2023-12-13 16:49:44,939 INFO resource.ResourceProfile: Default ResourceProfile created, execut                                                                      or resources: Map(cores -&gt; name: cores, amount: 1, script: , vendor: , memory -&gt; name: memory,                                                                       amount: 1024, script: , vendor: , offHeap -&gt; name: offHeap, amount: 0, script: , vendor: ), t                                                                      ask resources: Map(cpus -&gt; name: cpus, amount: 1.0)</span><br><span class="line">2023-12-13 16:49:44,961 INFO resource.ResourceProfile: Limiting resource is cpus at 1 tasks pe                                                                      r executor</span><br><span class="line">2023-12-13 16:49:44,992 INFO resource.ResourceProfileManager: Added ResourceProfile <span class="built_in">id</span>: 0</span><br><span class="line"></span><br><span class="line">......</span><br><span class="line"></span><br><span class="line">2023-12-13 16:50:47,759 INFO scheduler.DAGScheduler: Job 0 finished: reduce at SparkPi.scala:3                                                                      8, took 20.828142 s</span><br><span class="line">Pi is roughly 3.139227139227139</span><br><span class="line">2023-12-13 16:50:47,885 INFO server.AbstractConnector: Stopped Spark@6e9c413e&#123;HTTP/1.1, (http/                                                                      1.1)&#125;&#123;0.0.0.0:4040&#125;</span><br><span class="line">2023-12-13 16:50:47,900 INFO ui.SparkUI: Stopped Spark web UI at http://hadoop301:4040</span><br><span class="line">2023-12-13 16:50:47,909 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread</span><br><span class="line">2023-12-13 16:50:47,998 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors</span><br><span class="line">2023-12-13 16:50:47,999 INFO cluster.YarnSchedulerBackend<span class="variable">$YarnDriverEndpoint</span>: Asking each <span class="built_in">exec</span>                                                                      utor to shut down</span><br><span class="line">2023-12-13 16:50:48,037 INFO cluster.YarnClientSchedulerBackend: YARN client scheduler backend                                                                       Stopped</span><br><span class="line">2023-12-13 16:50:48,440 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpo                                                                      int stopped!</span><br><span class="line">2023-12-13 16:50:48,511 INFO memory.MemoryStore: MemoryStore cleared</span><br><span class="line">2023-12-13 16:50:48,511 INFO storage.BlockManager: BlockManager stopped</span><br><span class="line">2023-12-13 16:50:48,543 INFO storage.BlockManagerMaster: BlockManagerMaster stopped</span><br><span class="line">2023-12-13 16:50:48,550 INFO scheduler.OutputCommitCoordinator<span class="variable">$OutputCommitCoordinatorEndpoint</span>                                                                      : OutputCommitCoordinator stopped!</span><br><span class="line">2023-12-13 16:50:48,644 INFO spark.SparkContext: Successfully stopped SparkContext</span><br><span class="line">2023-12-13 16:50:48,654 INFO util.ShutdownHookManager: Shutdown hook called</span><br><span class="line">2023-12-13 16:50:48,689 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-646e1f5a-                                                                      38b0-46f9-948c-af2f753731d7</span><br><span class="line">2023-12-13 16:50:48,738 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-5d835f52-                                                                      96f8-4b11-82bd-e5cfad7e0a80</span><br></pre></td></tr></table></figure>



<ol start="8">
<li>Web 页面查看日志：<a target="_blank" rel="noopener" href="http://hadoop302:8088/">http://hadoop302:8088</a></li>
</ol>
<p><img data-src="E:/typora%E5%9B%BE%E7%89%87/image-20231213165525855.png" alt="image-20231213165525855"></p>
<h4 id="五、Windows模式"><a href="#五、Windows模式" class="headerlink" title="五、Windows模式"></a>五、Windows模式</h4><p>1). 解压文件</p>
<p>将文件spark-3.1.1-bin-hadoop3.2.tgz解压到无中文五空格的路径中</p>
<p>2).启动本地环境</p>
<ol>
<li>执行解压文件路径下bin目录中的spark-shell.com文件，启动Spark本地环境</li>
</ol>
<p><img data-src="E:/typora%E5%9B%BE%E7%89%87/image-20231213171654405.png" alt="image-20231213171654405"></p>
<ol start="2">
<li>在bin目录中创建input目录，并添加word.txt文件，在命令行中输入脚本代码</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Hello World</span><br><span class="line">Hello Spark</span><br></pre></td></tr></table></figure>



<ol start="3">
<li>在 终端输入如下命令</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sc.textFile(<span class="string">&quot;input/word.txt&quot;</span>).flatMap(_.<span class="built_in">split</span>(<span class="string">&quot;,&quot;</span>)).map((_,<span class="number">1</span>)).reduceByKey(_+_).collect</span><br></pre></td></tr></table></figure>

<p><img data-src="E:/typora%E5%9B%BE%E7%89%87/image-20231213173500001.png" alt="image-20231213173500001"></p>
<p>可以打开UI页面看一下</p>
<p><img data-src="E:/typora%E5%9B%BE%E7%89%87/image-20231213173825783.png" alt="image-20231213173825783"></p>
<p>3).命令行提交应用</p>
<p>在DOS命令行窗口中执行提交命令</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-submit --class org.apache.spark.examples.SparkPi --master local[2] ../examples/jars/spark-examples_2.12-3.1.1.jar 10</span><br></pre></td></tr></table></figure>



<p><img data-src="E:/typora%E5%9B%BE%E7%89%87/image-20231213174537566.png" alt="image-20231213174537566"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-submit --class org.apache.spark.examples.SparkPi --master local[2] ../examples/jars/spark-examples_2.12-3.1.1.jar 10</span><br></pre></td></tr></table></figure>





<h4 id="六、Spark核心编程"><a href="#六、Spark核心编程" class="headerlink" title="六、Spark核心编程"></a>六、Spark核心编程</h4><p>1). 数据接收与发送（分布式框架）</p>
<p><strong>Executor：</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> spark.test</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.<span class="type">InputStream</span></span><br><span class="line"><span class="keyword">import</span> java.net.&#123;<span class="type">ServerSocket</span>, <span class="type">Socket</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Executor</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 启动服务器，接收数据</span></span><br><span class="line">    <span class="keyword">val</span> server = <span class="keyword">new</span> <span class="type">ServerSocket</span>(<span class="number">9999</span>)</span><br><span class="line">    println(<span class="string">&quot;服务器启动，等待接收数据&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 等待客户端的连接</span></span><br><span class="line">    <span class="keyword">val</span> client: <span class="type">Socket</span> = server.accept()</span><br><span class="line">    <span class="keyword">val</span> in: <span class="type">InputStream</span> = client.getInputStream</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> i: <span class="type">Int</span> = in.read()</span><br><span class="line">    println(<span class="string">&quot;接收到客户端发送的数据：&quot;</span> + i)</span><br><span class="line">    in.close()</span><br><span class="line">    client.close()</span><br><span class="line">    server.close()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>先运行Executor</p>
<img data-src="E:/typora%E5%9B%BE%E7%89%87/image-20231214083253778.png" alt="image-20231214083253778" style="zoom:50%;" />

<p><strong>Driver：</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> spark.test</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.net.<span class="type">Socket</span></span><br><span class="line"><span class="keyword">import</span> java.io.<span class="type">OutputStream</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Driver</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// 连接服务器</span></span><br><span class="line">    <span class="keyword">val</span> client = <span class="keyword">new</span> <span class="type">Socket</span>(<span class="string">&quot;localhost&quot;</span>, <span class="number">9999</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> out: <span class="type">OutputStream</span> = client.getOutputStream</span><br><span class="line">    out.write(<span class="number">2</span>)</span><br><span class="line">    out.flush()</span><br><span class="line">    out.close()</span><br><span class="line"></span><br><span class="line">    client.close()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>再运行Driver</p>
<img data-src="E:/typora%E5%9B%BE%E7%89%87/image-20231214083353078.png" alt="image-20231214083353078" style="zoom:50%;" />



<p>2). 数据接收与发送（分布式框架计算）</p>
<p><strong>Task：</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> spark.test</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Task</span> <span class="keyword">extends</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> datas = <span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//  val logic = ( num:Int )=&gt;&#123; num*2 &#125;</span></span><br><span class="line">  <span class="keyword">val</span> logic : (<span class="type">Int</span>)=&gt;<span class="type">Int</span> = _ * <span class="number">2</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 计算</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">compute</span></span>() =&#123;</span><br><span class="line">    datas.map(logic)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><strong>Executor：</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> spark.test</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.&#123;<span class="type">InputStream</span>, <span class="type">ObjectInputStream</span>&#125;</span><br><span class="line"><span class="keyword">import</span> java.net.&#123;<span class="type">ServerSocket</span>, <span class="type">Socket</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Executor</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 启动服务器，接收数据</span></span><br><span class="line">    <span class="keyword">val</span> server = <span class="keyword">new</span> <span class="type">ServerSocket</span>(<span class="number">9999</span>)</span><br><span class="line">    println(<span class="string">&quot;服务器启动，等待接收数据&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 等待客户端的连接</span></span><br><span class="line">    <span class="keyword">val</span> client: <span class="type">Socket</span> = server.accept()</span><br><span class="line">    <span class="keyword">val</span> in: <span class="type">InputStream</span> = client.getInputStream</span><br><span class="line">    <span class="keyword">val</span> objIn = <span class="keyword">new</span> <span class="type">ObjectInputStream</span>(in)</span><br><span class="line">    <span class="keyword">val</span> task: <span class="type">Task</span> = objIn.readObject().asInstanceOf[<span class="type">Task</span>]</span><br><span class="line">    <span class="keyword">val</span> ints: <span class="type">List</span>[<span class="type">Int</span>] = task.compute()</span><br><span class="line"></span><br><span class="line">    println(<span class="string">&quot;计算节点计算的结果为：&quot;</span> + ints)</span><br><span class="line">    objIn.close()</span><br><span class="line">    client.close()</span><br><span class="line">    server.close()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>先启动Executor</p>
<img data-src="E:/typora%E5%9B%BE%E7%89%87/image-20231214085834628.png" alt="image-20231214085834628" style="zoom:50%;" />



<p><strong>Driver：</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> spark.test</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.net.<span class="type">Socket</span></span><br><span class="line"><span class="keyword">import</span> java.io.&#123;<span class="type">ObjectOutputStream</span>, <span class="type">OutputStream</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Driver</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// 连接服务器</span></span><br><span class="line">    <span class="keyword">val</span> client = <span class="keyword">new</span> <span class="type">Socket</span>(<span class="string">&quot;localhost&quot;</span>, <span class="number">9999</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> out: <span class="type">OutputStream</span> = client.getOutputStream</span><br><span class="line">    <span class="keyword">val</span> objOut = <span class="keyword">new</span> <span class="type">ObjectOutputStream</span>(out)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> task = <span class="keyword">new</span> <span class="type">Task</span>()</span><br><span class="line">    objOut.writeObject(task)</span><br><span class="line">    objOut.flush()</span><br><span class="line">    objOut.close()</span><br><span class="line">    client.close()</span><br><span class="line">    println(<span class="string">&quot;客户端数据发送完毕&quot;</span>)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>再启动Driver</p>
<img data-src="E:/typora%E5%9B%BE%E7%89%87/image-20231214085907092.png" alt="image-20231214085907092" style="zoom:50%;" />

<img data-src="E:/typora%E5%9B%BE%E7%89%87/image-20231214085922852.png" alt="image-20231214085922852" style="zoom:50%;" />



<p>3).数据接收与发送（分布式框架发布计算）</p>
<p><strong>Task：</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> spark.test</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Task</span> <span class="keyword">extends</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> datas = <span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//  val logic = ( num:Int )=&gt;&#123; num*2 &#125;</span></span><br><span class="line">  <span class="keyword">val</span> logic : (<span class="type">Int</span>)=&gt;<span class="type">Int</span> = _ * <span class="number">2</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>SubTask：</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> spark.test</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SubTask</span> <span class="keyword">extends</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">  <span class="keyword">var</span> datas :  <span class="type">List</span>[<span class="type">Int</span>] = _</span><br><span class="line"></span><br><span class="line">  <span class="keyword">var</span> logic : (<span class="type">Int</span>)=&gt;<span class="type">Int</span> = _</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 计算</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">compute</span></span>() =&#123;</span><br><span class="line">    datas.map(logic)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><strong>Executor：</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> spark.test</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.&#123;<span class="type">InputStream</span>, <span class="type">ObjectInputStream</span>&#125;</span><br><span class="line"><span class="keyword">import</span> java.net.&#123;<span class="type">ServerSocket</span>, <span class="type">Socket</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Executor</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 启动服务器，接收数据</span></span><br><span class="line">    <span class="keyword">val</span> server = <span class="keyword">new</span> <span class="type">ServerSocket</span>(<span class="number">9999</span>)</span><br><span class="line">    println(<span class="string">&quot;服务器启动，等待接收数据&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 等待客户端的连接</span></span><br><span class="line">    <span class="keyword">val</span> client: <span class="type">Socket</span> = server.accept()</span><br><span class="line">    <span class="keyword">val</span> in: <span class="type">InputStream</span> = client.getInputStream</span><br><span class="line">    <span class="keyword">val</span> objIn = <span class="keyword">new</span> <span class="type">ObjectInputStream</span>(in)</span><br><span class="line">    <span class="keyword">val</span> task: <span class="type">SubTask</span> = objIn.readObject().asInstanceOf[<span class="type">SubTask</span>]</span><br><span class="line">    <span class="keyword">val</span> ints: <span class="type">List</span>[<span class="type">Int</span>] = task.compute()</span><br><span class="line"></span><br><span class="line">    println(<span class="string">&quot;计算节点[9999]计算的结果为：&quot;</span> + ints)</span><br><span class="line">    objIn.close()</span><br><span class="line">    client.close()</span><br><span class="line">    server.close()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>启动结果：</p>
<img data-src="E:/typora%E5%9B%BE%E7%89%87/image-20231214092354917.png" alt="image-20231214092354917" style="zoom:50%;" />

<p><strong>Executor2：</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> spark.test</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.&#123;<span class="type">InputStream</span>, <span class="type">ObjectInputStream</span>&#125;</span><br><span class="line"><span class="keyword">import</span> java.net.&#123;<span class="type">ServerSocket</span>, <span class="type">Socket</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Executor2</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 启动服务器，接收数据</span></span><br><span class="line">    <span class="keyword">val</span> server = <span class="keyword">new</span> <span class="type">ServerSocket</span>(<span class="number">8888</span>)</span><br><span class="line">    println(<span class="string">&quot;服务器启动，等待接收数据&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 等待客户端的连接</span></span><br><span class="line">    <span class="keyword">val</span> client: <span class="type">Socket</span> = server.accept()</span><br><span class="line">    <span class="keyword">val</span> in: <span class="type">InputStream</span> = client.getInputStream</span><br><span class="line">    <span class="keyword">val</span> objIn = <span class="keyword">new</span> <span class="type">ObjectInputStream</span>(in)</span><br><span class="line">    <span class="keyword">val</span> task: <span class="type">SubTask</span> = objIn.readObject().asInstanceOf[<span class="type">SubTask</span>]</span><br><span class="line">    <span class="keyword">val</span> ints: <span class="type">List</span>[<span class="type">Int</span>] = task.compute()</span><br><span class="line"></span><br><span class="line">    println(<span class="string">&quot;计算节点[8888]计算的结果为：&quot;</span> + ints)</span><br><span class="line">    objIn.close()</span><br><span class="line">    client.close()</span><br><span class="line">    server.close()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>启动结果：</p>
<img data-src="E:/typora%E5%9B%BE%E7%89%87/image-20231214092419564.png" alt="image-20231214092419564" style="zoom:50%;" />

<p><strong>Driver：</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> spark.test</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.net.<span class="type">Socket</span></span><br><span class="line"><span class="keyword">import</span> java.io.&#123;<span class="type">ObjectOutputStream</span>, <span class="type">OutputStream</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Driver</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// 连接服务器</span></span><br><span class="line">    <span class="keyword">val</span> client1 = <span class="keyword">new</span> <span class="type">Socket</span>(<span class="string">&quot;localhost&quot;</span>, <span class="number">9999</span>)</span><br><span class="line">    <span class="keyword">val</span> client2 = <span class="keyword">new</span> <span class="type">Socket</span>(<span class="string">&quot;localhost&quot;</span>, <span class="number">8888</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> task = <span class="keyword">new</span> <span class="type">Task</span>()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> out1: <span class="type">OutputStream</span> = client1.getOutputStream</span><br><span class="line">    <span class="keyword">val</span> objOut1 = <span class="keyword">new</span> <span class="type">ObjectOutputStream</span>(out1)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> subTask = <span class="keyword">new</span> <span class="type">SubTask</span>()</span><br><span class="line">    subTask.logic = task.logic</span><br><span class="line">    subTask.datas = task.datas.take(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    objOut1.writeObject(subTask)</span><br><span class="line">    objOut1.flush()</span><br><span class="line">    objOut1.close()</span><br><span class="line">    client1.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> out2: <span class="type">OutputStream</span> = client2.getOutputStream</span><br><span class="line">    <span class="keyword">val</span> objOut2 = <span class="keyword">new</span> <span class="type">ObjectOutputStream</span>(out2)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> subTask1 = <span class="keyword">new</span> <span class="type">SubTask</span>()</span><br><span class="line">    subTask1.logic = task.logic</span><br><span class="line">    subTask1.datas = task.datas.takeRight(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    objOut2.writeObject(subTask1)</span><br><span class="line">    objOut2.flush()</span><br><span class="line">    objOut2.close()</span><br><span class="line">    client2.close()</span><br><span class="line">    println(<span class="string">&quot;客户端数据发送完毕&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>启动结果：</p>
<img data-src="E:/typora%E5%9B%BE%E7%89%87/image-20231214092448067.png" alt="image-20231214092448067" style="zoom:50%;" />

<img data-src="E:/typora%E5%9B%BE%E7%89%87/image-20231214092503853.png" alt="image-20231214092503853" style="zoom:50%;" />

<img data-src="E:/typora%E5%9B%BE%E7%89%87/image-20231214092523751.png" alt="image-20231214092523751" style="zoom:50%;" />





<h4 id="七、弹性分布式数据集（RDD）"><a href="#七、弹性分布式数据集（RDD）" class="headerlink" title="七、弹性分布式数据集（RDD）"></a>七、弹性分布式数据集（RDD）</h4><p>1). 什么是RDD</p>
<p>​      RDD (Resilient Distributed Dataset）叫做弹性分布式数据集，是Spark中最基本的<strong>数据处理模型</strong>。代码中是一个抽象类，它代表一个弹性的、不可变、可分区、里面的元素可并行计算的集合。</p>
<p>RDD的数据处理类似于Java中的IO流，也有装饰者设计模式。</p>
<p>RDD的数据只有在调用collect方法时，才会真正执行业务逻辑操作。之前的封装都是功能的扩展。</p>
<p>RDD是不保存数据的，但是IO可以临时保存一部分数据。</p>
<p>2).RDD的创建</p>
<ol>
<li>从集合（内存）中创建RDD</li>
</ol>
<p>从集合中创建RDD, Spark主要提供了两个方法: parallelize和makeRDD</p>
<p><strong>rdd_Memory：</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> spark.rdd</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">rdd_Memory</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 准备环境</span></span><br><span class="line">    <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;RDD&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(sparkConf)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 创建RDD</span></span><br><span class="line">    <span class="comment">// 从内存中创建RDD，将内存中集合的数据作为处理的数据源</span></span><br><span class="line">    <span class="keyword">val</span> seq = <span class="type">Seq</span>[<span class="type">Int</span>](elems = <span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// parallelize : 并行</span></span><br><span class="line"><span class="comment">//    val rdd: RDD[Int] =  sc.parallelize(seq)</span></span><br><span class="line">    <span class="comment">// makeRDD 方法在底层实现时其实就是调用了rdd对象的parallelize方法。</span></span><br><span class="line">    <span class="keyword">val</span> rdd: <span class="type">RDD</span>[<span class="type">Int</span>] = sc.makeRDD(seq)</span><br><span class="line"></span><br><span class="line">    rdd.collect().foreach(println)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 关闭环境</span></span><br><span class="line">    sc.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<ol start="2">
<li>从外部存储（文件）中创建RDD</li>
</ol>
<p><strong>rdd_File：</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> spark.rdd</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">rdd_File</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 准备环境</span></span><br><span class="line">    <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;RDD&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(sparkConf)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 创建RDD</span></span><br><span class="line">    <span class="comment">// 从文件中创建RDD，将文件中的数据作为处理的数据源</span></span><br><span class="line">    <span class="comment">// path 路径默认以当前环境的根路径为基准。可以写绝对路径，也可以写相对路径</span></span><br><span class="line"><span class="comment">//    sc.textFile(&quot;E:\\spack-study\\datas\\1.txt&quot;)</span></span><br><span class="line">    <span class="comment">// path路径可以是文件的具体路径，也可以是目录名称</span></span><br><span class="line"><span class="comment">//     val rdd: RDD[String] = sc.textFile(&quot;datas/1.txt&quot;)</span></span><br><span class="line">    <span class="comment">// path路径可以是文件的具体路径，也可以是目录名称</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    val rdd = sc.textFile(&quot;datas&quot;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// path 路径还可以使用通配符*</span></span><br><span class="line">    <span class="keyword">val</span> rdd = sc.textFile(<span class="string">&quot;datas/1*.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//path还可以是分布式存储系统路径：HDFS</span></span><br><span class="line"></span><br><span class="line">    rdd.collect().foreach(println)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 关闭环境</span></span><br><span class="line">    sc.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><strong>rdd_File1：</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> spark.rdd</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">rdd_File1</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 准备环境</span></span><br><span class="line">    <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;RDD&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(sparkConf)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 创建RDD</span></span><br><span class="line">    <span class="comment">// 从文件中创建RDD，将文件中的数据作为处理的数据源</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// textFile : 以行为单位来读取数据，读取的数据都是字符串</span></span><br><span class="line">    <span class="comment">// wholeTextFiles ：以文件为单位读取数据</span></span><br><span class="line">    <span class="comment">// 读取的结果表示为元组，第一个元素表示路径，第二个元素表示文件内容</span></span><br><span class="line">    <span class="keyword">val</span> rdd = sc.wholeTextFiles(<span class="string">&quot;datas/*.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    rdd.collect().foreach(println)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 关闭环境</span></span><br><span class="line">    sc.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<ol start="3">
<li>RDD的并行度</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> spark.rdd</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">rdd_Memory_Par</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 准备环境</span></span><br><span class="line">    <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;RDD&quot;</span>)</span><br><span class="line">    sparkConf.set(<span class="string">&quot;spark.default.parallelism&quot;</span>, <span class="string">&quot;5&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(sparkConf)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 创建RDD</span></span><br><span class="line">    <span class="comment">// RDD的并行度 &amp; 分区</span></span><br><span class="line">    <span class="comment">// makeRDD方法可以传递第二个参数，这个参数表示分区的数量</span></span><br><span class="line">    <span class="comment">// 第二个参数可以不传递的，那么makeRDD 方法会使用默认值： defaultParallelism(默认的并行度)</span></span><br><span class="line"><span class="comment">//    val rdd = sc.makeRDD(List(1,2,3,4),2)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//scheduler. conf. getInt (&quot;spark.default.parallelism &quot;,， totalCores)</span></span><br><span class="line">    <span class="comment">//spark在默认情况下，从配置对象中获取配置参数: spark. default.parallelism</span></span><br><span class="line">    <span class="comment">//如果获取不到，那么使用totalCores属性，这个属性取值为当前环境的最大可用核数</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> rdd = sc.makeRDD(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将处理的数据保存成分区文件</span></span><br><span class="line">    rdd.saveAsTextFile(<span class="string">&quot;output&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 关闭环境</span></span><br><span class="line">    sc.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



















































<h3 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h3><p><strong>4 常用命令</strong></p>
<p><strong>4.1 docker 进程</strong></p>
<p>docer 进程启动、停止、重启等三种 常见操作</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">service docker start   <span class="comment"># 启动docker</span></span><br><span class="line">service docker stop    <span class="comment"># 关机docker</span></span><br><span class="line">service docker restart <span class="comment"># 重启docker</span></span><br></pre></td></tr></table></figure>

<p><strong>4.2 镜像操作</strong></p>
<p>镜像是容器执行的前提条件，一般需要掌握命令注意有<strong>搜索</strong>、<strong>下载</strong>、<strong>删除</strong>、<strong>创建</strong>。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker images      <span class="comment"># 镜像列表</span></span><br><span class="line">docker search xxx  <span class="comment"># 检索镜像, 从镜像仓库中检索</span></span><br><span class="line">docker pull xxx    <span class="comment"># 下载镜像</span></span><br><span class="line">docker rmi xxx     <span class="comment"># 删除镜像</span></span><br></pre></td></tr></table></figure>

<p><strong>4.3 容器操作</strong></p>
<p>容器的各种操作主要包括，启动、关闭、重启和日志查询。</p>
<p><strong>4.3.1 容器创建 ：run</strong></p>
<p>加载镜像，创建容器run 后面可以跟很多的参数，比如容器暴露端口指定，存储映射，权限等等，由于参数过多，下面只给出几个不同的例子，来具体的演示参数可以怎么加</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">docker run</span><br><span class="line">         -i              # 打开 STDIN，用于控制台交互</span><br><span class="line">         -t              # 支持终端登录</span><br><span class="line">         -d              # 要求容器后台运行，默认前台 前三个标签可连写为itd</span><br><span class="line">         -v              # 挂载数据卷</span><br><span class="line">         --name=dc_nm    # 指定容器名</span><br><span class="line">         -p 8080:80      # 暴露容器端口 80，并与宿主机端口 8080 绑定  </span><br><span class="line">         centos:latest   # 镜像名:版本</span><br></pre></td></tr></table></figure>



<p><strong>4.3.2 基本操作:</strong></p>
<p>容器基本操作主要包括启动、停止、重启、删除</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker ps -a                       <span class="comment"># 查看容器列表， 列出所有的容器</span></span><br><span class="line">docker <span class="built_in">exec</span> -it <span class="string">&quot;ct_id&quot;</span> /bin/bash  <span class="comment"># 进入容器,ct_id是容器id</span></span><br><span class="line">docker start xxx                   <span class="comment"># xxx可以是容器名，也可以是容器id</span></span><br><span class="line">docker stop xxx                    <span class="comment"># 关闭容器</span></span><br><span class="line">docker restart xxx                 <span class="comment"># 重启</span></span><br><span class="line">docker <span class="built_in">rm</span> xxx                      <span class="comment"># 删除</span></span><br></pre></td></tr></table></figure>

<p>从宿主机复制文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">cp</span> 宿主机文件路径 容器<span class="built_in">id</span>:/home/your_path</span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;jdbc:mysql://hadoop301:3306/hive3?createDatabaseIfNotExist=true&amp;amp;useSSL=false&amp;amp;useUnicode=true&amp;amp;characterEncoding=UTF-8&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"> </span><br><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"> </span><br><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;root&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"> </span><br><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;root&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"> </span><br><span class="line">&lt;!-- H2S运行绑定host--&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;hive.server2.thrift.bind.host&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;hadoop301&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"> </span><br><span class="line">&lt;!-- 远程模式部署metastore metastore地址--&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;hive.metastore.uris&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;thrift://hadoop301:9083&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"> </span><br><span class="line">&lt;!-- 关闭元数据存储授权--&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;hive.metastore.event.db.notification.api.auth&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;false&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;     </span><br></pre></td></tr></table></figure>







<p>以下是一个示例的Scala代码，可用于将MySQL的shtd_store库中的数据抽取到Hive的ods库中。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SparkSession</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">DataExtraction</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> spark = <span class="type">SparkSession</span>.builder()</span><br><span class="line">      .appName(<span class="string">&quot;DataExtraction&quot;</span>)</span><br><span class="line">      .enableHiveSupport()</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 设置分区字段值</span></span><br><span class="line">    <span class="keyword">val</span> partitionValue = java.time.<span class="type">LocalDate</span>.now.minusDays(<span class="number">1</span>).format(java.time.format.<span class="type">DateTimeFormatter</span>.ofPattern(<span class="string">&quot;yyyyMMdd&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 抽取Table1的全量数据，并添加静态分区</span></span><br><span class="line">    <span class="keyword">val</span> table1DF = spark.read.format(<span class="string">&quot;jdbc&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;url&quot;</span>, <span class="string">&quot;jdbc:mysql://localhost:3306/shtd_store&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;driver&quot;</span>, <span class="string">&quot;com.mysql.jdbc.Driver&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;dbtable&quot;</span>, <span class="string">&quot;Table1&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;user&quot;</span>, <span class="string">&quot;mysql_username&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;password&quot;</span>, <span class="string">&quot;mysql_password&quot;</span>)</span><br><span class="line">      .load()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> table1WithPartitionDF = table1DF.withColumn(<span class="string">&quot;partition_col&quot;</span>, lit(partitionValue))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将数据保存到Hive表中</span></span><br><span class="line">    table1WithPartitionDF.write.format(<span class="string">&quot;hive&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;table&quot;</span>, <span class="string">&quot;ods.table1&quot;</span>)</span><br><span class="line">      .mode(<span class="string">&quot;overwrite&quot;</span>)</span><br><span class="line">      .save()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 显示分区信息</span></span><br><span class="line">    spark.sql(<span class="string">&quot;SHOW PARTITIONS ods.table1&quot;</span>).show()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>使用Maven创建项目：</p>
<ol>
<li>确保你已经安装了Maven。</li>
<li>在项目的根目录下创建一个Maven项目。可以使用命令<code>mvn archetype:generate</code>并选择适合的Maven项目模板。</li>
<li>在生成的项目中，将<code>DataExtraction.scala</code>文件复制到源代码目录中（默认为<code>src/main/scala</code>）。</li>
<li>在项目的根目录中打开终端或命令提示符，运行<code>mvn package</code>命令来打包项目。</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.spark.sql.SparkSession</span><br><span class="line">import org.apache.spark.sql.functions.&#123;lit, current_date, date_format&#125;</span><br><span class="line"></span><br><span class="line">object DataExtraction &#123;</span><br><span class="line">  def main(args: Array[String]): Unit = &#123;</span><br><span class="line">    val spark = SparkSession.builder()</span><br><span class="line">      .appName(<span class="string">&quot;DataExtraction&quot;</span>)</span><br><span class="line">      .enableHiveSupport()</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    // 全量抽取 Table1 的数据到 DataFrame</span><br><span class="line">    val table1DF = spark.read.format(<span class="string">&quot;jdbc&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;url&quot;</span>, <span class="string">&quot;jdbc:mysql://bigdata1:3306/hadoopdb01&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;driver&quot;</span>, <span class="string">&quot;com.mysql.jdbc.Driver&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;dbtable&quot;</span>, <span class="string">&quot;base_region&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;user&quot;</span>, <span class="string">&quot;root&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;password&quot;</span>, <span class="string">&quot;123456&quot;</span>)</span><br><span class="line">      .load()</span><br><span class="line"></span><br><span class="line">    // 添加静态分区字段，分区值为当前比赛日的前一天日期</span><br><span class="line">    val partitionValue = current_date().minus(1).cast(<span class="string">&quot;string&quot;</span>)</span><br><span class="line">    val table1WithPartitionDF = table1DF.withColumn(<span class="string">&quot;partition_date&quot;</span>, lit(partitionValue))</span><br><span class="line"></span><br><span class="line">    // 将数据写入 Hive 表 table1，并覆盖已存在的分区</span><br><span class="line">    table1WithPartitionDF.write.format(<span class="string">&quot;hive&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;table&quot;</span>, <span class="string">&quot;ods.table1&quot;</span>)</span><br><span class="line">      .mode(<span class="string">&quot;overwrite&quot;</span>)</span><br><span class="line">      .save()</span><br><span class="line"></span><br><span class="line">    // 在 Hive CLI 中执行 show partitions 命令</span><br><span class="line">    // show partitions ods.table1;</span><br><span class="line"></span><br><span class="line">    // 复制并粘贴 show partitions 的结果截图至报告中</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">./spark-submit  --class DataExtraction   /opt/module/spark-3.1.1-yarn/data/sparkexamples-1.0-SNAPSHOT.jar</span><br><span class="line"></span><br><span class="line">spark-submit --master spark://bigdata1:7077 --class test.DataExtraction sparkexamples.jar</span><br><span class="line"></span><br><span class="line">spark-submit --master spark://bigdata1:7077 --class test.DataExtraction --executor-memory 2g --total-executor-cores 4 /opt/sparkexamples.jar</span><br><span class="line"></span><br><span class="line">spark-submit --class test.SparkExample --master yarn --deploy-mode cluster sparkexamples.jar</span><br><span class="line"></span><br><span class="line">spark-submit --class numtest.demo01 --master spark://bigdata1:7077 --executor-memory 2g --total-executor-cores 4   /opt/gu.jar </span><br><span class="line"></span><br><span class="line">spark-submit --class test.SparkExample --master yarn --deploy-mode cluster /opt/sparkexamples.jar</span><br></pre></td></tr></table></figure>



<p><img data-src="E:/typora%E5%9B%BE%E7%89%87/image-20231225215043624.png" alt="image-20231225215043624"></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">spark-submit --class test.DataExtraction --master yarn --deploy-mode cluster /opt/sparkexamples.jar</span><br><span class="line"></span><br><span class="line">spark-submit --class test.InsertDataToHive --master yarn --deploy-mode client /opt/sparkexamples.jar</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">val pushDownQuery = <span class="string">&quot;select * from city limit 10&quot;</span></span><br><span class="line">val jdbcDF = spark.read</span><br><span class="line">  .format(<span class="string">&quot;jdbc&quot;</span>)</span><br><span class="line">  .option(<span class="string">&quot;url&quot;</span>, <span class="string">&quot;jdbc:mysql://hadoop301/world&quot;</span>)</span><br><span class="line">  .option(<span class="string">&quot;driver&quot;</span>, <span class="string">&quot;com.mysql.jdbc.Driver&quot;</span>)</span><br><span class="line">  .option(<span class="string">&quot;user&quot;</span>, <span class="string">&quot;root&quot;</span>)</span><br><span class="line">  .option(<span class="string">&quot;password&quot;</span>, <span class="string">&quot;123456&quot;</span>)</span><br><span class="line">  .option(<span class="string">&quot;dbtable&quot;</span>, city)</span><br><span class="line">  .load()</span><br><span class="line">jdbcDF.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>







<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">spark-submit --master yarn --class test.InsertDataToHive --deploy-mode client /opt/sparkexamples.jar</span><br><span class="line"></span><br><span class="line">spark-submit --master spark://bigdata1:7077 --class test.DataExtraction sparkexamples.jar</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">spark-submin --master spark://bigdate1:7077 --class test.table1 /opt/dd.jar</span><br><span class="line"></span><br><span class="line">spark-submin --master spark://bigdate1:7077 --class test.d /opt/ss.jar</span><br><span class="line"></span><br><span class="line">spark-submin --master spark://bigdate:7077 --class test.djj /opt/ss.jar</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">spark-submin --master spark://bigdate1:7077 --class tes </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">spark-submin --master yarn --class --deploy-mode client  /op</span><br><span class="line">spark-submin --master yarn --class --deploy-mode deploy-mode client client client /op</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">spark-submin --master yarn --class --deploy-mode client /</span><br><span class="line">--deploy-mode client</span><br><span class="line">--deploy-mode client</span><br><span class="line">--deploy-mode client</span><br><span class="line"></span><br><span class="line">--deploy-mode client</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--deploy-mode client</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--deploy-mode client</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">spark-subin -cmaster yarn --class tekkk  --deploy-mode client /op</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">spark-subin --master yarn --class tes  --deploy-mode client /op</span><br><span class="line"></span><br><span class="line">spark-subin --master yarn --class --deploy-mode clie</span><br></pre></td></tr></table></figure>


    </div>

    
    
    
      


    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/hadoop/" rel="tag"># hadoop</a>
              <a href="/tags/scala/" rel="tag"># scala</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2024-06-06-data-utilization.html" rel="prev" title="数据运用与分析">
                  <i class="fa fa-chevron-left"></i> 数据运用与分析
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>






    
  <div class="comments" id="disqus_thread">
    <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
  </div>
  
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2026</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Cisgu</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">593k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">8:59</span>
  </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
  <script src="https://cdn.jsdelivr.net/npm/lozad@1.16.0/dist/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous" defer></script>
<script src="/js/comments.js" defer></script><script src="/js/utils.js" defer></script><script src="/js/next-boot.js" defer></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.5.0/dist/search.js" integrity="sha256-xFC6PJ82SL9b3WkGjFavNiA9gm5z6UBxWPiu4CYjptg=" crossorigin="anonymous" defer></script>
<script src="/js/third-party/search/local-search.js" defer></script>




  <script src="/js/third-party/pace.js" defer></script>

  




<script class="next-config" data-name="disqus" type="application/json">{"enable":true,"shortname":"muzi","count":true,"i18n":{"disqus":"disqus"}}</script>
<script src="/js/third-party/comments/disqus.js" defer></script>

</body>
</html>
